[0m04:07:22.591184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10791f260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093a0f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093a0b00>]}


============================== 04:07:22.597573 | 9cd73eaf-08f0-4375-be4a-a49072418480 ==============================
[0m04:07:22.597573 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:07:22.597897 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'indirect_selection': 'eager', 'version_check': 'True', 'partial_parse': 'True', 'quiet': 'False', 'no_print': 'None', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error': 'None', 'write_json': 'True', 'empty': 'None', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt debug', 'log_cache_events': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'static_parser': 'True'}
[0m04:07:22.602740 [info ] [MainThread]: dbt version: 1.10.13
[0m04:07:22.602932 [info ] [MainThread]: python version: 3.12.12
[0m04:07:22.603080 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:07:22.603221 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:07:22.604054 [info ] [MainThread]: target not specified in profile 'type', using 'default'
[0m04:07:22.604345 [info ] [MainThread]: target not specified in profile 'host', using 'default'
[0m04:07:22.604610 [error] [MainThread]: Encountered an error:
argument of type 'int' is not iterable
[0m04:07:22.605580 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/main.py", line 420, in debug
    results = task.run()
              ^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/debug.py", line 114, in run
    load_profile_status: SubtaskStatus = self._load_profile()
                                         ^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/debug.py", line 205, in _load_profile
    profile: Profile = Profile.render(
                       ^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 402, in render
    return cls.from_raw_profiles(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 368, in from_raw_profiles
    return cls.from_raw_profile_info(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 314, in from_raw_profile_info
    target_name, profile_data = cls.render_profile(
                                ^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 273, in render_profile
    elif "target" in raw_profile:
         ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'int' is not iterable

[0m04:07:22.720075 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.17592192, "process_in_blocks": "0", "process_kernel_time": 0.120137, "process_mem_max_rss": "113049600", "process_out_blocks": "0", "process_user_time": 0.828379}
[0m04:07:22.720430 [debug] [MainThread]: Command `dbt debug` failed at 04:07:22.720375 after 0.18 seconds
[0m04:07:22.720633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093a0dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091512e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10930ddf0>]}
[0m04:07:22.720829 [debug] [MainThread]: Flushing usage events
[0m04:07:23.266660 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:07:46.963472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d78980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046ff590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068f5220>]}


============================== 04:07:46.965903 | b251a2c9-c182-441e-b4d2-11b71be4b41a ==============================
[0m04:07:46.965903 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:07:46.966254 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'log_format': 'default', 'use_colors': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'warn_error': 'None', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'debug': 'False', 'target_path': 'None', 'printer_width': '80', 'fail_fast': 'False', 'partial_parse': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project'}
[0m04:07:46.971967 [info ] [MainThread]: dbt version: 1.10.13
[0m04:07:46.972223 [info ] [MainThread]: python version: 3.12.12
[0m04:07:46.972376 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:07:46.972522 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:07:46.973228 [info ] [MainThread]: target not specified in profile 'type', using 'default'
[0m04:07:46.973487 [info ] [MainThread]: target not specified in profile 'host', using 'default'
[0m04:07:46.973718 [error] [MainThread]: Encountered an error:
argument of type 'int' is not iterable
[0m04:07:46.974558 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/main.py", line 420, in debug
    results = task.run()
              ^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/debug.py", line 114, in run
    load_profile_status: SubtaskStatus = self._load_profile()
                                         ^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/debug.py", line 205, in _load_profile
    profile: Profile = Profile.render(
                       ^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 402, in render
    return cls.from_raw_profiles(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 368, in from_raw_profiles
    return cls.from_raw_profile_info(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 314, in from_raw_profile_info
    target_name, profile_data = cls.render_profile(
                                ^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 273, in render_profile
    elif "target" in raw_profile:
         ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'int' is not iterable

[0m04:07:46.976186 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.047934376, "process_in_blocks": "0", "process_kernel_time": 0.087436, "process_mem_max_rss": "106971136", "process_out_blocks": "0", "process_user_time": 0.700834}
[0m04:07:46.976485 [debug] [MainThread]: Command `dbt debug` failed at 04:07:46.976433 after 0.05 seconds
[0m04:07:46.976684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f6dfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f0ef60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f0ede0>]}
[0m04:07:46.976912 [debug] [MainThread]: Flushing usage events
[0m04:07:47.562883 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:09:07.486256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10503a4b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c1e630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f18770>]}


============================== 04:09:07.489009 | c9e642bb-3b4b-4d76-acd8-bf859470d631 ==============================
[0m04:09:07.489009 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:09:07.489373 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'empty': 'None', 'target_path': 'None', 'use_colors': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'quiet': 'False', 'debug': 'False', 'fail_fast': 'False', 'version_check': 'True', 'write_json': 'True', 'introspect': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_format': 'default', 'warn_error': 'None'}
[0m04:09:07.494802 [info ] [MainThread]: dbt version: 1.10.13
[0m04:09:07.494989 [info ] [MainThread]: python version: 3.12.12
[0m04:09:07.495131 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:09:07.495268 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:09:07.498013 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'CLICKHOUSE_USER'
[0m04:09:07.499365 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.050758168, "process_in_blocks": "0", "process_kernel_time": 0.09559, "process_mem_max_rss": "107806720", "process_out_blocks": "0", "process_user_time": 0.697482}
[0m04:09:07.499631 [debug] [MainThread]: Command `dbt debug` failed at 04:09:07.499584 after 0.05 seconds
[0m04:09:07.499821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105171f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cec200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b12bd0>]}
[0m04:09:07.500008 [debug] [MainThread]: Flushing usage events
[0m04:09:08.091602 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:10:21.151133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b7f920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a31340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fbf920>]}


============================== 04:10:21.153535 | f1be4f76-fef1-430f-8688-4cef5bcae528 ==============================
[0m04:10:21.153535 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:10:21.153877 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'write_json': 'True', 'invocation_command': 'dbt debug', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'introspect': 'True', 'log_format': 'default', 'log_cache_events': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_colors': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'fail_fast': 'False', 'printer_width': '80', 'target_path': 'None', 'debug': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error': 'None'}
[0m04:10:21.158882 [info ] [MainThread]: dbt version: 1.10.13
[0m04:10:21.159096 [info ] [MainThread]: python version: 3.12.12
[0m04:10:21.159250 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:10:21.159390 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:10:21.162454 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'CLICKHOUSE_USER'
[0m04:10:21.163942 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.048605207, "process_in_blocks": "0", "process_kernel_time": 0.099443, "process_mem_max_rss": "106512384", "process_out_blocks": "0", "process_user_time": 0.698393}
[0m04:10:21.164238 [debug] [MainThread]: Command `dbt debug` failed at 04:10:21.164187 after 0.05 seconds
[0m04:10:21.164429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a75ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11244d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e4d700>]}
[0m04:10:21.164626 [debug] [MainThread]: Flushing usage events
[0m04:10:21.583599 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:13:05.234712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e7f830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11023ac60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104321e0>]}


============================== 04:13:05.237262 | 3d488704-0cba-4b9e-a07b-aa0d349af00f ==============================
[0m04:13:05.237262 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:13:05.237600 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'invocation_command': 'dbt debug', 'log_format': 'default', 'quiet': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'static_parser': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'empty': 'None', 'cache_selected_only': 'False', 'use_colors': 'True', 'debug': 'False', 'write_json': 'True', 'warn_error': 'None'}
[0m04:13:05.242711 [info ] [MainThread]: dbt version: 1.10.13
[0m04:13:05.242935 [info ] [MainThread]: python version: 3.12.12
[0m04:13:05.243097 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:13:05.243251 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:13:05.279183 [info ] [MainThread]: Using profiles dir at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project
[0m04:13:05.279495 [info ] [MainThread]: Using profiles.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/profiles.yml
[0m04:13:05.279648 [info ] [MainThread]: Using dbt_project.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/dbt_project.yml
[0m04:13:05.279938 [info ] [MainThread]: adapter type: clickhouse
[0m04:13:05.280077 [info ] [MainThread]: adapter version: 1.9.5
[0m04:13:05.281702 [info ] [MainThread]: Configuration:
[0m04:13:05.281877 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:13:05.282012 [info ] [MainThread]:   dbt_project.yml file [[31mERROR invalid[0m]
[0m04:13:05.282174 [info ] [MainThread]: Required dependencies:
[0m04:13:05.282350 [debug] [MainThread]: Executing "git --help"
[0m04:13:05.299549 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:13:05.300087 [debug] [MainThread]: STDERR: "b''"
[0m04:13:05.300286 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:13:05.300471 [info ] [MainThread]: Connection:
[0m04:13:05.300646 [info ] [MainThread]:   driver: None
[0m04:13:05.300788 [info ] [MainThread]:   host: localhost
[0m04:13:05.300923 [info ] [MainThread]:   port: 8124
[0m04:13:05.301051 [info ] [MainThread]:   user: qi
[0m04:13:05.301181 [info ] [MainThread]:   schema: default
[0m04:13:05.301317 [info ] [MainThread]:   retries: 1
[0m04:13:05.301442 [info ] [MainThread]:   cluster: None
[0m04:13:05.301572 [info ] [MainThread]:   database_engine: None
[0m04:13:05.301708 [info ] [MainThread]:   cluster_mode: False
[0m04:13:05.301825 [info ] [MainThread]:   secure: False
[0m04:13:05.301943 [info ] [MainThread]:   verify: True
[0m04:13:05.302063 [info ] [MainThread]:   client_cert: None
[0m04:13:05.302183 [info ] [MainThread]:   client_cert_key: None
[0m04:13:05.302311 [info ] [MainThread]:   connect_timeout: 10
[0m04:13:05.302426 [info ] [MainThread]:   send_receive_timeout: 300
[0m04:13:05.302543 [info ] [MainThread]:   sync_request_timeout: 5
[0m04:13:05.302660 [info ] [MainThread]:   compress_block_size: 1048576
[0m04:13:05.302778 [info ] [MainThread]:   compression: 
[0m04:13:05.302909 [info ] [MainThread]:   check_exchange: True
[0m04:13:05.303023 [info ] [MainThread]:   custom_settings: None
[0m04:13:05.303140 [info ] [MainThread]:   use_lw_deletes: False
[0m04:13:05.303255 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m04:13:05.303372 [info ] [MainThread]:   tcp_keepalive: False
[0m04:13:05.303771 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m04:13:05.367552 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m04:13:05.367997 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:13:11.445015 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m04:13:11.446942 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:13:11.455176 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:13:11.455452 [info ] [MainThread]: [31m1 check failed:[0m
[0m04:13:11.455636 [info ] [MainThread]: Project loading failed for the following reason:
Runtime Error
  Required "name" field not present in project

Error encountered in /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/dbt_project.yml


[0m04:13:11.458177 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 6.2596097, "process_in_blocks": "0", "process_kernel_time": 0.234971, "process_mem_max_rss": "157794304", "process_out_blocks": "0", "process_user_time": 1.138061}
[0m04:13:11.458501 [debug] [MainThread]: Command `dbt debug` failed at 04:13:11.458441 after 6.26 seconds
[0m04:13:11.458715 [debug] [MainThread]: Connection 'debug' was left open.
[0m04:13:11.458889 [debug] [MainThread]: On debug: Close
[0m04:13:11.459127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104f5e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e7d760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e7d700>]}
[0m04:13:11.459393 [debug] [MainThread]: Flushing usage events
[0m04:13:12.079455 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:15:01.053264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf3a4b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf3ac60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c130980>]}


============================== 04:15:01.056006 | 6775a7f6-5a7e-4708-ad4b-dee1f20e84e8 ==============================
[0m04:15:01.056006 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:15:01.056336 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'fail_fast': 'False', 'empty': 'None', 'no_print': 'None', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'use_colors': 'True', 'write_json': 'True', 'warn_error': 'None', 'target_path': 'None', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m04:15:01.061262 [info ] [MainThread]: dbt version: 1.10.13
[0m04:15:01.061451 [info ] [MainThread]: python version: 3.12.12
[0m04:15:01.061596 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:15:01.061737 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:15:01.094431 [info ] [MainThread]: Using profiles dir at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project
[0m04:15:01.094728 [info ] [MainThread]: Using profiles.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/profiles.yml
[0m04:15:01.094882 [info ] [MainThread]: Using dbt_project.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/dbt_project.yml
[0m04:15:01.095149 [info ] [MainThread]: adapter type: clickhouse
[0m04:15:01.095296 [info ] [MainThread]: adapter version: 1.9.5
[0m04:15:01.143822 [info ] [MainThread]: Configuration:
[0m04:15:01.144135 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:15:01.144289 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m04:15:01.144424 [info ] [MainThread]: Required dependencies:
[0m04:15:01.144632 [debug] [MainThread]: Executing "git --help"
[0m04:15:01.160662 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:15:01.161227 [debug] [MainThread]: STDERR: "b''"
[0m04:15:01.161431 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:15:01.161609 [info ] [MainThread]: Connection:
[0m04:15:01.161790 [info ] [MainThread]:   driver: None
[0m04:15:01.161921 [info ] [MainThread]:   host: localhost
[0m04:15:01.162045 [info ] [MainThread]:   port: 8124
[0m04:15:01.162166 [info ] [MainThread]:   user: qi
[0m04:15:01.162285 [info ] [MainThread]:   schema: default
[0m04:15:01.162406 [info ] [MainThread]:   retries: 1
[0m04:15:01.162528 [info ] [MainThread]:   cluster: None
[0m04:15:01.162645 [info ] [MainThread]:   database_engine: None
[0m04:15:01.162764 [info ] [MainThread]:   cluster_mode: False
[0m04:15:01.162883 [info ] [MainThread]:   secure: False
[0m04:15:01.163003 [info ] [MainThread]:   verify: True
[0m04:15:01.163126 [info ] [MainThread]:   client_cert: None
[0m04:15:01.163242 [info ] [MainThread]:   client_cert_key: None
[0m04:15:01.163362 [info ] [MainThread]:   connect_timeout: 10
[0m04:15:01.163478 [info ] [MainThread]:   send_receive_timeout: 300
[0m04:15:01.163596 [info ] [MainThread]:   sync_request_timeout: 5
[0m04:15:01.163713 [info ] [MainThread]:   compress_block_size: 1048576
[0m04:15:01.163831 [info ] [MainThread]:   compression: 
[0m04:15:01.163951 [info ] [MainThread]:   check_exchange: True
[0m04:15:01.164068 [info ] [MainThread]:   custom_settings: None
[0m04:15:01.164188 [info ] [MainThread]:   use_lw_deletes: False
[0m04:15:01.164305 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m04:15:01.164425 [info ] [MainThread]:   tcp_keepalive: False
[0m04:15:01.164775 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m04:15:01.226656 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m04:15:01.227065 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:15:01.509842 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m04:15:01.511602 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:15:01.519650 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:15:01.519916 [info ] [MainThread]: [32mAll checks passed![0m
[0m04:15:01.522379 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.5043327, "process_in_blocks": "0", "process_kernel_time": 0.185228, "process_mem_max_rss": "158384128", "process_out_blocks": "0", "process_user_time": 1.038287}
[0m04:15:01.522753 [debug] [MainThread]: Command `dbt debug` succeeded at 04:15:01.522689 after 0.50 seconds
[0m04:15:01.522943 [debug] [MainThread]: Connection 'debug' was left open.
[0m04:15:01.523107 [debug] [MainThread]: On debug: Close
[0m04:15:01.523393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8f9820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c459940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9f8590>]}
[0m04:15:01.523653 [debug] [MainThread]: Flushing usage events
[0m04:15:02.176815 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:15:16.322956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082243e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10905bb00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108353260>]}


============================== 04:15:16.325474 | ea107799-e309-4d2d-9e1b-2c466e56ddbd ==============================
[0m04:15:16.325474 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:15:16.325810 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'invocation_command': 'dbt debug', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'no_print': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'empty': 'None', 'printer_width': '80', 'warn_error': 'None', 'log_format': 'default', 'debug': 'False', 'quiet': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'fail_fast': 'False'}
[0m04:15:16.330500 [info ] [MainThread]: dbt version: 1.10.13
[0m04:15:16.330691 [info ] [MainThread]: python version: 3.12.12
[0m04:15:16.330837 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:15:16.330976 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:15:16.363815 [info ] [MainThread]: Using profiles dir at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project
[0m04:15:16.364101 [info ] [MainThread]: Using profiles.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/profiles.yml
[0m04:15:16.364257 [info ] [MainThread]: Using dbt_project.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/dbt_project.yml
[0m04:15:16.364524 [info ] [MainThread]: adapter type: clickhouse
[0m04:15:16.364674 [info ] [MainThread]: adapter version: 1.9.5
[0m04:15:16.414694 [info ] [MainThread]: Configuration:
[0m04:15:16.414988 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:15:16.415139 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m04:15:16.415281 [info ] [MainThread]: Required dependencies:
[0m04:15:16.415497 [debug] [MainThread]: Executing "git --help"
[0m04:15:16.431303 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:15:16.431865 [debug] [MainThread]: STDERR: "b''"
[0m04:15:16.432068 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:15:16.432241 [info ] [MainThread]: Connection:
[0m04:15:16.432413 [info ] [MainThread]:   driver: None
[0m04:15:16.432547 [info ] [MainThread]:   host: localhost
[0m04:15:16.432679 [info ] [MainThread]:   port: 8124
[0m04:15:16.432806 [info ] [MainThread]:   user: qi
[0m04:15:16.432937 [info ] [MainThread]:   schema: default
[0m04:15:16.433062 [info ] [MainThread]:   retries: 1
[0m04:15:16.433192 [info ] [MainThread]:   cluster: None
[0m04:15:16.433318 [info ] [MainThread]:   database_engine: None
[0m04:15:16.433446 [info ] [MainThread]:   cluster_mode: False
[0m04:15:16.433572 [info ] [MainThread]:   secure: False
[0m04:15:16.433695 [info ] [MainThread]:   verify: True
[0m04:15:16.433984 [info ] [MainThread]:   client_cert: None
[0m04:15:16.434171 [info ] [MainThread]:   client_cert_key: None
[0m04:15:16.434314 [info ] [MainThread]:   connect_timeout: 10
[0m04:15:16.434444 [info ] [MainThread]:   send_receive_timeout: 300
[0m04:15:16.434571 [info ] [MainThread]:   sync_request_timeout: 5
[0m04:15:16.434696 [info ] [MainThread]:   compress_block_size: 1048576
[0m04:15:16.434821 [info ] [MainThread]:   compression: 
[0m04:15:16.434944 [info ] [MainThread]:   check_exchange: True
[0m04:15:16.435065 [info ] [MainThread]:   custom_settings: None
[0m04:15:16.435184 [info ] [MainThread]:   use_lw_deletes: False
[0m04:15:16.435304 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m04:15:16.435425 [info ] [MainThread]:   tcp_keepalive: False
[0m04:15:16.435852 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m04:15:16.497406 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m04:15:16.497839 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:15:16.764955 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m04:15:16.766646 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:15:16.774291 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:15:16.774547 [info ] [MainThread]: [32mAll checks passed![0m
[0m04:15:16.776806 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.48962462, "process_in_blocks": "0", "process_kernel_time": 0.16188, "process_mem_max_rss": "159285248", "process_out_blocks": "0", "process_user_time": 1.020862}
[0m04:15:16.777088 [debug] [MainThread]: Command `dbt debug` succeeded at 04:15:16.777037 after 0.49 seconds
[0m04:15:16.777293 [debug] [MainThread]: Connection 'debug' was left open.
[0m04:15:16.777572 [debug] [MainThread]: On debug: Close
[0m04:15:16.777851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b54f470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfb2cc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb00620>]}
[0m04:15:16.778084 [debug] [MainThread]: Flushing usage events
[0m04:15:17.381336 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:17:41.162439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10600fb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107176660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071760f0>]}


============================== 04:17:41.164943 | cce55ca9-b2b8-459e-8b4e-9763430d845f ==============================
[0m04:17:41.164943 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:17:41.165275 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'no_print': 'None', 'debug': 'False', 'invocation_command': 'dbt run', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'empty': 'False', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default'}
[0m04:17:41.252601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f7a2a0>]}
[0m04:17:41.282111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10630a540>]}
[0m04:17:41.282614 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m04:17:41.348203 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m04:17:41.348705 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m04:17:41.348911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073b8d10>]}
[0m04:17:41.998360 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m04:17:42.001309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073acf50>]}
[0m04:17:42.040428 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m04:17:42.041523 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m04:17:42.052463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072cc4d0>]}
[0m04:17:42.052737 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m04:17:42.052922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107113bf0>]}
[0m04:17:42.053793 [info ] [MainThread]: 
[0m04:17:42.053975 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:17:42.054118 [info ] [MainThread]: 
[0m04:17:42.054370 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m04:17:42.057230 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:17:42.062676 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:17:42.346863 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:17:42.348658 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:17:42.356955 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m04:17:42.357263 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m04:17:42.361326 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m04:17:42.364021 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:17:42.365062 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m04:17:42.368311 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m04:17:42.376328 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m04:17:42.377220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107927ad0>]}
[0m04:17:42.380226 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m04:17:42.380531 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m04:17:42.380766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m04:17:42.380944 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m04:17:42.384534 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m04:17:42.385109 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m04:17:42.395935 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m04:17:42.411071 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.daily_prices
          )
        
        ...
[0m04:17:42.414377 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.daily_prices
          )
        
        
[0m04:17:42.418743 [debug] [Thread-1 (]: Database Error in model daily_prices (models/market/daily_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 557 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.419638 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107efbe90>]}
[0m04:17:42.420004 [error] [Thread-1 (]: 1 of 4 ERROR creating sql table model `default_market`.`daily_prices` .......... [[31mERROR[0m in 0.04s]
[0m04:17:42.420310 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m04:17:42.420502 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m04:17:42.420730 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m04:17:42.420954 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m04:17:42.421134 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m04:17:42.422115 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m04:17:42.422411 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.daily_prices' to be skipped because of status 'error'.  Reason: Database Error in model daily_prices (models/market/daily_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 557 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124).
[0m04:17:42.423305 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m04:17:42.424484 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m04:17:42.425085 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.monthly_prices
          )
        
        ...
[0m04:17:42.427108 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.monthly_prices
          )
        
        
[0m04:17:42.429714 [debug] [Thread-1 (]: Database Error in model monthly_prices (models/market/monthly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 563 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.430022 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa01310>]}
[0m04:17:42.430363 [error] [Thread-1 (]: 2 of 4 ERROR creating sql table model `default_market`.`monthly_prices` ........ [[31mERROR[0m in 0.01s]
[0m04:17:42.430664 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m04:17:42.430867 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m04:17:42.431108 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.monthly_prices' to be skipped because of status 'error'.  Reason: Database Error in model monthly_prices (models/market/monthly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 563 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124).
[0m04:17:42.431363 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m04:17:42.431653 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m04:17:42.431830 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m04:17:42.433012 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m04:17:42.433514 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m04:17:42.434714 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m04:17:42.435383 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.quarterly_prices
          )
        
        ...
[0m04:17:42.437420 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.quarterly_prices
          )
        
        
[0m04:17:42.440262 [debug] [Thread-1 (]: Database Error in model quarterly_prices (models/market/quarterly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 569 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.440635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9f3080>]}
[0m04:17:42.440995 [error] [Thread-1 (]: 3 of 4 ERROR creating sql table model `default_market`.`quarterly_prices` ...... [[31mERROR[0m in 0.01s]
[0m04:17:42.441521 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m04:17:42.441822 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m04:17:42.442171 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.quarterly_prices' to be skipped because of status 'error'.  Reason: Database Error in model quarterly_prices (models/market/quarterly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 569 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124).
[0m04:17:42.442708 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m04:17:42.443099 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m04:17:42.443394 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m04:17:42.444633 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m04:17:42.445166 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m04:17:42.446400 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m04:17:42.447053 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.weekly_prices
          )
        
        ...
[0m04:17:42.449170 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.weekly_prices
          )
        
        
[0m04:17:42.452014 [debug] [Thread-1 (]: Database Error in model weekly_prices (models/market/weekly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 560 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.452357 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aab3920>]}
[0m04:17:42.452734 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model `default_market`.`weekly_prices` ......... [[31mERROR[0m in 0.01s]
[0m04:17:42.453201 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m04:17:42.453506 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.weekly_prices' to be skipped because of status 'error'.  Reason: Database Error in model weekly_prices (models/market/weekly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 560 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124).
[0m04:17:42.454331 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:17:42.454563 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m04:17:42.454763 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m04:17:42.455013 [info ] [MainThread]: 
[0m04:17:42.455179 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.40 seconds (0.40s).
[0m04:17:42.455694 [debug] [MainThread]: Command end result
[0m04:17:42.469124 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m04:17:42.470465 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m04:17:42.473609 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m04:17:42.473785 [info ] [MainThread]: 
[0m04:17:42.473974 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m04:17:42.474141 [info ] [MainThread]: 
[0m04:17:42.474340 [error] [MainThread]: [31mFailure in model daily_prices (models/market/daily_prices.sql)[0m
[0m04:17:42.474532 [error] [MainThread]:   Database Error in model daily_prices (models/market/daily_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 557 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.474692 [info ] [MainThread]: 
[0m04:17:42.474860 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/market/daily_prices.sql
[0m04:17:42.475001 [info ] [MainThread]: 
[0m04:17:42.475171 [error] [MainThread]: [31mFailure in model monthly_prices (models/market/monthly_prices.sql)[0m
[0m04:17:42.475348 [error] [MainThread]:   Database Error in model monthly_prices (models/market/monthly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 563 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.475493 [info ] [MainThread]: 
[0m04:17:42.475652 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/market/monthly_prices.sql
[0m04:17:42.475783 [info ] [MainThread]: 
[0m04:17:42.475945 [error] [MainThread]: [31mFailure in model quarterly_prices (models/market/quarterly_prices.sql)[0m
[0m04:17:42.476113 [error] [MainThread]:   Database Error in model quarterly_prices (models/market/quarterly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 569 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.476253 [info ] [MainThread]: 
[0m04:17:42.476410 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/market/quarterly_prices.sql
[0m04:17:42.476543 [info ] [MainThread]: 
[0m04:17:42.476703 [error] [MainThread]: [31mFailure in model weekly_prices (models/market/weekly_prices.sql)[0m
[0m04:17:42.476872 [error] [MainThread]:   Database Error in model weekly_prices (models/market/weekly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 560 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.477010 [info ] [MainThread]: 
[0m04:17:42.477161 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/market/weekly_prices.sql
[0m04:17:42.477288 [info ] [MainThread]: 
[0m04:17:42.477443 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 NO-OP=0 TOTAL=4
[0m04:17:42.479763 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.3532338, "process_in_blocks": "0", "process_kernel_time": 0.200707, "process_mem_max_rss": "170328064", "process_out_blocks": "0", "process_user_time": 1.868252}
[0m04:17:42.480182 [debug] [MainThread]: Command `dbt run` failed at 04:17:42.480136 after 1.35 seconds
[0m04:17:42.480417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071133e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078bbd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108331610>]}
[0m04:17:42.480607 [debug] [MainThread]: Flushing usage events
[0m04:17:43.126162 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:35:36.056253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109377bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096666c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109666180>]}


============================== 11:35:36.059607 | d9e844e0-2113-48e6-a6ca-278776d966d1 ==============================
[0m11:35:36.059607 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:35:36.059960 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'target_path': 'None', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'quiet': 'False', 'invocation_command': 'dbt run', 'static_parser': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'printer_width': '80', 'write_json': 'True', 'debug': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_experimental_parser': 'False', 'no_print': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'log_format': 'default', 'use_colors': 'True', 'indirect_selection': 'eager', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False'}
[0m11:35:36.155243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c22690>]}
[0m11:35:36.184787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10969b830>]}
[0m11:35:36.185369 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:35:36.253227 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:35:36.315296 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m11:35:36.315658 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/weekly_prices.sql
[0m11:35:36.315875 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/monthly_prices.sql
[0m11:35:36.316084 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/daily_prices.sql
[0m11:35:36.316286 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/quarterly_prices.sql
[0m11:35:36.526956 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m11:35:36.530226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cd0590>]}
[0m11:35:36.568042 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:35:36.569914 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:35:36.581961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a7f020>]}
[0m11:35:36.582256 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:35:36.582455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109eea060>]}
[0m11:35:36.583460 [info ] [MainThread]: 
[0m11:35:36.583676 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:35:36.583830 [info ] [MainThread]: 
[0m11:35:36.584113 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:35:36.587356 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:35:36.592883 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:37.034546 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:35:37.036440 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.047989 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default_market)
[0m11:35:37.051680 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:35:37.055709 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.056517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098446e0>]}
[0m11:35:37.058128 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:35:37.058410 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:35:37.058636 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:35:37.058816 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:35:37.063278 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:35:37.063810 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:35:37.074398 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:35:37.090489 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:35:37.096046 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:35:37.105095 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:35:37.107977 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.110119 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:35:37.110830 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:35:37.113383 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.124184 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fdd160>]}
[0m11:35:37.124551 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.07s]
[0m11:35:37.124881 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:35:37.125084 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:35:37.125317 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:35:37.125529 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:35:37.125700 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:35:37.126731 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:35:37.127169 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:35:37.128386 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:35:37.129007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:35:37.134354 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:35:37.136033 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:35:37.138247 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.139450 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:35:37.139943 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:35:37.142598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.143823 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097ecda0>]}
[0m11:35:37.144188 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:35:37.144472 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:35:37.144661 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:35:37.144994 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:35:37.145288 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:35:37.145479 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:35:37.147466 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:35:37.147914 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:35:37.149107 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:35:37.149740 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:35:37.157490 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:35:37.159264 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:35:37.161757 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.163086 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:35:37.163609 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:35:37.166006 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.166998 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cfd8410>]}
[0m11:35:37.167317 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:35:37.167581 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:35:37.167765 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:35:37.168143 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:35:37.168505 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:35:37.168702 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:35:37.169892 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:35:37.170345 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:35:37.171551 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:35:37.172202 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:35:37.177312 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.179050 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:35:37.181801 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.183155 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:35:37.183683 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:35:37.186226 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.187323 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cec2870>]}
[0m11:35:37.187674 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:35:37.187960 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:35:37.188544 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:35:37.188732 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:35:37.188894 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:35:37.189126 [info ] [MainThread]: 
[0m11:35:37.189296 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.61 seconds (0.61s).
[0m11:35:37.189786 [debug] [MainThread]: Command end result
[0m11:35:37.202920 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:35:37.204005 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:35:37.207153 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:35:37.207332 [info ] [MainThread]: 
[0m11:35:37.207526 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:35:37.207678 [info ] [MainThread]: 
[0m11:35:37.207847 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:35:37.210746 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1947646, "process_in_blocks": "0", "process_kernel_time": 0.256685, "process_mem_max_rss": "169902080", "process_out_blocks": "0", "process_user_time": 1.52261}
[0m11:35:37.211014 [debug] [MainThread]: Command `dbt run` succeeded at 11:35:37.210967 after 1.20 seconds
[0m11:35:37.211216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096665d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093771d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d534a0>]}
[0m11:35:37.211408 [debug] [MainThread]: Flushing usage events
[0m11:35:37.735516 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:41:46.143651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a1970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1e570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1e000>]}


============================== 11:41:46.146895 | 44423d54-f36c-496a-a0d1-33df90e28ea0 ==============================
[0m11:41:46.146895 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:41:46.147249 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'debug': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'introspect': 'True', 'partial_parse': 'True', 'static_parser': 'True', 'warn_error': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'invocation_command': 'dbt run --full-refresh', 'fail_fast': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'write_json': 'True', 'log_format': 'default', 'use_colors': 'True'}
[0m11:41:46.241983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1d970>]}
[0m11:41:46.272152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064f6240>]}
[0m11:41:46.273136 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:41:46.343223 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:41:46.406977 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:41:46.407255 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:41:46.410558 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
[0m11:41:46.428622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074db500>]}
[0m11:41:46.465975 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:41:46.467229 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:41:46.478680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107738ad0>]}
[0m11:41:46.478962 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:41:46.479145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741ce90>]}
[0m11:41:46.480107 [info ] [MainThread]: 
[0m11:41:46.480306 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:41:46.480453 [info ] [MainThread]: 
[0m11:41:46.480712 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:41:46.483741 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:41:46.490683 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:41:46.826293 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:41:46.828157 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.837910 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m11:41:46.838269 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m11:41:46.842539 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m11:41:46.845047 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.846100 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m11:41:46.849362 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:41:46.852126 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.852926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a000770>]}
[0m11:41:46.854388 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:41:46.854680 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:41:46.854912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:41:46.855094 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:41:46.858652 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:41:46.859114 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:41:46.870707 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:41:46.886336 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:41:46.891051 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.900362 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:41:46.903316 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.905593 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:41:46.906125 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:41:46.908877 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.919815 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104799130>]}
[0m11:41:46.920215 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.06s]
[0m11:41:46.920520 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:41:46.920730 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:41:46.920960 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:41:46.921174 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:41:46.921421 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:41:46.922600 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:41:46.923027 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:41:46.924232 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:41:46.924878 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:41:46.931462 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:41:46.933107 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:41:46.935485 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.936700 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:41:46.937180 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:41:46.939879 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.941008 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d099280>]}
[0m11:41:46.941352 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:41:46.941677 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:41:46.942050 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:41:46.942418 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:41:46.942741 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:41:46.942951 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:41:46.944138 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:41:46.944582 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:41:46.945761 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:41:46.946378 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:41:46.952777 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:41:46.955371 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:41:46.957812 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.959057 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:41:46.959521 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:41:46.962127 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.963240 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0c6a20>]}
[0m11:41:46.963603 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:41:46.963890 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:41:46.964092 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:41:46.964370 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:41:46.964637 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:41:46.964833 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:41:46.965987 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:41:46.966424 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:41:46.967648 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:41:46.968293 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:41:46.976618 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:41:46.978407 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:41:46.981004 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.982153 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:41:46.982664 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:41:46.985102 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.986165 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c783440>]}
[0m11:41:46.986504 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:41:46.986777 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:41:46.987370 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:41:46.987526 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:41:46.987679 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:41:46.987911 [info ] [MainThread]: 
[0m11:41:46.988063 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m11:41:46.988540 [debug] [MainThread]: Command end result
[0m11:41:47.001254 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:41:47.002375 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:41:47.005499 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:41:47.005690 [info ] [MainThread]: 
[0m11:41:47.005884 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:41:47.006038 [info ] [MainThread]: 
[0m11:41:47.006204 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:41:47.008647 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.90499693, "process_in_blocks": "0", "process_kernel_time": 0.220099, "process_mem_max_rss": "165134336", "process_out_blocks": "0", "process_user_time": 1.332627}
[0m11:41:47.008916 [debug] [MainThread]: Command `dbt run` succeeded at 11:41:47.008874 after 0.91 seconds
[0m11:41:47.009124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10611edb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741d2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071d74a0>]}
[0m11:41:47.009320 [debug] [MainThread]: Flushing usage events
[0m11:41:47.573415 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:45:26.995745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bd41d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce65a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce6060>]}


============================== 11:45:26.998747 | 744d8abe-ebde-4f6b-971c-9018fa0fa188 ==============================
[0m11:45:26.998747 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:45:26.999080 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'empty': 'False', 'log_format': 'default', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'target_path': 'None', 'quiet': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'invocation_command': 'dbt run --full-refresh', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'introspect': 'True', 'partial_parse': 'True', 'no_print': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project'}
[0m11:45:27.091803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cc4140>]}
[0m11:45:27.122771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10855e780>]}
[0m11:45:27.123824 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:45:27.190620 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:45:27.234435 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:45:27.234730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109196ea0>]}
[0m11:45:27.884670 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m11:45:27.887534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109369a60>]}
[0m11:45:27.924306 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:45:27.925445 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:45:27.936509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca1b20>]}
[0m11:45:27.936775 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:45:27.936957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109369b50>]}
[0m11:45:27.937853 [info ] [MainThread]: 
[0m11:45:27.938041 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:45:27.938191 [info ] [MainThread]: 
[0m11:45:27.938445 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:45:27.941456 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:45:27.946995 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:45:28.275036 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:45:28.276863 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.287203 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_)
[0m11:45:28.287549 [debug] [ThreadPool]: Creating schema "schema: "default_"
"
[0m11:45:28.291560 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_"} */
create database if not exists `default_`
        
  
        
  ...
[0m11:45:28.293945 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.294992 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_, now list__default_)
[0m11:45:28.298337 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_'
      

  ...
[0m11:45:28.304093 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.305098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094bf6b0>]}
[0m11:45:28.307065 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:45:28.307381 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_`.`daily_prices` ......................... [RUN]
[0m11:45:28.307625 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_, now model.qi_dbt_project.daily_prices)
[0m11:45:28.307804 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:45:28.311438 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:45:28.311879 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:45:28.322545 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:45:28.337832 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:45:28.345043 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.354578 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_'
      
    
    order by position
  ...
[0m11:45:28.360409 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.362723 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:45:28.363231 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:45:28.367292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.379426 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9288c0>]}
[0m11:45:28.379896 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_`.`daily_prices` .................... [[32mOK[0m in 0.07s]
[0m11:45:28.380234 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:45:28.380469 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:45:28.380767 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_`.`monthly_prices` ....................... [RUN]
[0m11:45:28.381004 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:45:28.381193 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:45:28.383291 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:45:28.383711 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:45:28.384957 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:45:28.385631 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:45:28.395252 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.397087 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_'
      
    
    order by position
  ...
[0m11:45:28.399653 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.400810 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:45:28.401236 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:45:28.404117 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.405378 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c254cb0>]}
[0m11:45:28.405775 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_`.`monthly_prices` .................. [[32mOK[0m in 0.02s]
[0m11:45:28.406081 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:45:28.406297 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:45:28.406561 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_`.`quarterly_prices` ..................... [RUN]
[0m11:45:28.406774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:45:28.406943 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:45:28.408163 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:45:28.408534 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:45:28.409701 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:45:28.410406 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:45:28.415594 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.417317 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_'
      
    
    order by position
  ...
[0m11:45:28.420068 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.421188 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:45:28.421636 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:45:28.424336 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.425450 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c24e390>]}
[0m11:45:28.425797 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_`.`quarterly_prices` ................ [[32mOK[0m in 0.02s]
[0m11:45:28.426069 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:45:28.426257 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:45:28.426594 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_`.`weekly_prices` ........................ [RUN]
[0m11:45:28.426953 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:45:28.427159 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:45:28.428414 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:45:28.428849 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:45:28.430038 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:45:28.430774 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:45:28.436075 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.438039 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_'
      
    
    order by position
  ...
[0m11:45:28.440833 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.442237 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:45:28.442762 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:45:28.445587 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.446781 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2d0da0>]}
[0m11:45:28.447166 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_`.`weekly_prices` ................... [[32mOK[0m in 0.02s]
[0m11:45:28.447458 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:45:28.448128 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:45:28.448332 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:45:28.448498 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:45:28.448767 [info ] [MainThread]: 
[0m11:45:28.448951 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m11:45:28.449476 [debug] [MainThread]: Command end result
[0m11:45:28.463541 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:45:28.464699 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:45:28.468277 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:45:28.468513 [info ] [MainThread]: 
[0m11:45:28.468711 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:45:28.468869 [info ] [MainThread]: 
[0m11:45:28.469037 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:45:28.471504 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.513519, "process_in_blocks": "0", "process_kernel_time": 0.231999, "process_mem_max_rss": "170098688", "process_out_blocks": "0", "process_user_time": 1.964992}
[0m11:45:28.471744 [debug] [MainThread]: Command `dbt run` succeeded at 11:45:28.471702 after 1.51 seconds
[0m11:45:28.471934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce6330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109375340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093763c0>]}
[0m11:45:28.472114 [debug] [MainThread]: Flushing usage events
[0m11:45:28.934601 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:47:42.249879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e52330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8e540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8dee0>]}


============================== 11:47:42.253011 | 761ca6ac-137a-4541-a3f1-acad3e674270 ==============================
[0m11:47:42.253011 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:47:42.253377 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'debug': 'False', 'version_check': 'True', 'empty': 'False', 'target_path': 'None', 'static_parser': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'introspect': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'write_json': 'True', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run --full-refresh', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'printer_width': '80'}
[0m11:47:42.348067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10713af60>]}
[0m11:47:42.380546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058c20f0>]}
[0m11:47:42.381663 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:47:42.450359 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:47:42.497020 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:47:42.497371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10690d5b0>]}
[0m11:47:43.165519 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
[0m11:47:43.168441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f498e0>]}
[0m11:47:43.204616 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:47:43.205775 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:47:43.216621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107752960>]}
[0m11:47:43.216897 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:47:43.217081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077602f0>]}
[0m11:47:43.217961 [info ] [MainThread]: 
[0m11:47:43.218150 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:47:43.218293 [info ] [MainThread]: 
[0m11:47:43.218541 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:47:43.221553 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:47:43.226562 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:47:43.556379 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:47:43.558177 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.568335 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m11:47:43.568643 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m11:47:43.572680 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m11:47:43.574965 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.576004 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m11:47:43.579351 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:47:43.584637 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:47:43.585494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ca420>]}
[0m11:47:43.587691 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:47:43.588032 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:47:43.588293 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:47:43.588478 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:47:43.592127 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:47:43.592576 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:47:43.603088 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:47:43.618805 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:47:43.627643 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:47:43.637110 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:47:43.639902 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.642091 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:47:43.642627 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:47:43.645304 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.656935 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104900da0>]}
[0m11:47:43.657371 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.07s]
[0m11:47:43.657687 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:47:43.657909 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:47:43.658157 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:47:43.658445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:47:43.658626 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:47:43.660553 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:47:43.661030 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:47:43.662208 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:47:43.662840 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:47:43.667673 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.669557 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:47:43.672194 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.673349 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:47:43.673811 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:47:43.676599 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.677989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bff680>]}
[0m11:47:43.678393 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:47:43.678688 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:47:43.678901 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:47:43.679182 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:47:43.679423 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:47:43.679613 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:47:43.680894 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:47:43.681362 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:47:43.682653 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:47:43.683315 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:47:43.689191 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:47:43.690956 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:47:43.693566 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.694769 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:47:43.695257 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:47:43.697902 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.698975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4c5dc0>]}
[0m11:47:43.699305 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:47:43.699571 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:47:43.699755 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:47:43.700091 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:47:43.700417 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:47:43.700625 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:47:43.701858 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:47:43.702318 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:47:43.703615 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:47:43.704333 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:47:43.709787 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:47:43.711528 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:47:43.713945 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.715024 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:47:43.715481 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:47:43.718147 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.719358 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b43fda0>]}
[0m11:47:43.719701 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:47:43.719988 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:47:43.720589 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:47:43.720775 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:47:43.720929 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:47:43.721164 [info ] [MainThread]: 
[0m11:47:43.721322 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.50 seconds (0.50s).
[0m11:47:43.721792 [debug] [MainThread]: Command end result
[0m11:47:43.735126 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:47:43.736214 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:47:43.739333 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:47:43.739523 [info ] [MainThread]: 
[0m11:47:43.739722 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:47:43.739875 [info ] [MainThread]: 
[0m11:47:43.740035 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:47:43.742771 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.5320599, "process_in_blocks": "0", "process_kernel_time": 0.222844, "process_mem_max_rss": "169885696", "process_out_blocks": "0", "process_user_time": 1.948479}
[0m11:47:43.743110 [debug] [MainThread]: Command `dbt run` succeeded at 11:47:43.743064 after 1.53 seconds
[0m11:47:43.743314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8e450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8e3f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10751fad0>]}
[0m11:47:43.743510 [debug] [MainThread]: Flushing usage events
[0m11:47:44.208391 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:48:24.170580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086004a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67a570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67a030>]}


============================== 11:48:24.173065 | 41f289a2-a322-40fe-b8c1-273507295a03 ==============================
[0m11:48:24.173065 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:48:24.173399 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'target_path': 'None', 'fail_fast': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_format': 'default', 'quiet': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'invocation_command': 'dbt run --full-refresh', 'version_check': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error': 'None', 'empty': 'False', 'static_parser': 'True', 'no_print': 'None', 'use_colors': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'partial_parse': 'True', 'printer_width': '80'}
[0m11:48:24.258962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7bb9b0>]}
[0m11:48:24.288912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6a8d70>]}
[0m11:48:24.289384 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:48:24.353689 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:48:24.405140 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:48:24.405375 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:48:24.408465 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m11:48:24.425738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abc77a0>]}
[0m11:48:24.461614 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:48:24.462804 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:48:24.470016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae38ef0>]}
[0m11:48:24.470291 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:48:24.470465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8d7500>]}
[0m11:48:24.471342 [info ] [MainThread]: 
[0m11:48:24.471532 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:48:24.471679 [info ] [MainThread]: 
[0m11:48:24.471938 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:48:24.474837 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:48:24.480736 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:48:24.764903 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:48:24.766660 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.774363 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m11:48:24.774698 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m11:48:24.778924 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m11:48:24.781429 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.782498 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m11:48:24.785810 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:48:24.788523 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.789365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8578c0>]}
[0m11:48:24.790765 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:48:24.791066 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:48:24.791301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:48:24.791486 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:48:24.795048 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:48:24.795509 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:48:24.807258 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:48:24.822216 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:48:24.830389 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:48:24.839618 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:48:24.844513 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.846970 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:48:24.847526 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:48:24.852412 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.863444 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e85280>]}
[0m11:48:24.863821 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.07s]
[0m11:48:24.864120 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:48:24.864323 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:48:24.864550 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:48:24.864821 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:48:24.865043 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:48:24.866182 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:48:24.866588 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:48:24.867730 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:48:24.868369 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:48:24.879612 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:48:24.881420 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:48:24.883794 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.885015 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:48:24.885545 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:48:24.888130 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.889284 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1183956d0>]}
[0m11:48:24.889630 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:48:24.889973 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:48:24.890191 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:48:24.890446 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:48:24.890652 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:48:24.890829 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:48:24.891966 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:48:24.892336 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:48:24.893511 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:48:24.894163 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:48:24.901344 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:48:24.903863 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:48:24.906301 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.907462 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:48:24.907917 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:48:24.910819 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.912028 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1183c3590>]}
[0m11:48:24.912378 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:48:24.912659 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:48:24.912861 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:48:24.913101 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:48:24.913296 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:48:24.913461 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:48:24.914582 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:48:24.914985 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:48:24.916155 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:48:24.916777 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:48:24.924533 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:48:24.926352 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:48:24.928925 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.930161 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:48:24.930726 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:48:24.933161 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.934263 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118347890>]}
[0m11:48:24.934604 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:48:24.934885 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:48:24.935525 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:48:24.935720 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:48:24.935888 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:48:24.936137 [info ] [MainThread]: 
[0m11:48:24.936304 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m11:48:24.936808 [debug] [MainThread]: Command end result
[0m11:48:24.950000 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:48:24.951097 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:48:24.954229 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:48:24.954412 [info ] [MainThread]: 
[0m11:48:24.954601 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:48:24.954749 [info ] [MainThread]: 
[0m11:48:24.954909 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:48:24.957127 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8221957, "process_in_blocks": "0", "process_kernel_time": 0.201959, "process_mem_max_rss": "165806080", "process_out_blocks": "0", "process_user_time": 1.299101}
[0m11:48:24.957392 [debug] [MainThread]: Command `dbt run` succeeded at 11:48:24.957346 after 0.82 seconds
[0m11:48:24.957588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67a420>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a278b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c3aba0>]}
[0m11:48:24.957781 [debug] [MainThread]: Flushing usage events
[0m11:48:25.373877 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:51:15.731020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10225d160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106472480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106471e20>]}


============================== 11:51:15.733419 | 5db0157a-41a3-4545-9122-6b9e1decf29b ==============================
[0m11:51:15.733419 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:51:15.733766 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'fail_fast': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'target_path': 'None', 'log_format': 'default', 'empty': 'False', 'partial_parse': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --full-refresh', 'version_check': 'True', 'printer_width': '80', 'no_print': 'None', 'quiet': 'False', 'use_colors': 'True', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m11:51:15.819301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5db0157a-41a3-4545-9122-6b9e1decf29b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10656c800>]}
[0m11:51:15.848454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5db0157a-41a3-4545-9122-6b9e1decf29b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10225d160>]}
[0m11:51:15.848920 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:51:15.913224 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:51:15.964701 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:51:15.964996 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://macros/naming.sql
[0m11:51:15.966564 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:51:16.572277 [error] [MainThread]: Encountered an error:
can not serialize 'Undefined' object
[0m11:51:16.574480 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 272, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 303, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 373, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 350, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 389, in wrapper
    setup_manifest(ctx, write=write, write_perf_info=write_perf_info)
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 416, in setup_manifest
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 2123, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 320, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 518, in load
    self.write_manifest_for_partial_parse()
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 826, in write_manifest_for_partial_parse
    manifest_msgpack = self.manifest.to_msgpack(extended_mashumaro_encoder)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 3, in __mashumaro_to_msgpack__
  File "<string>", line 91, in __mashumaro_to_msgpack__
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 141, in extended_mashumaro_encoder
    return msgpack.packb(data, default=extended_msgpack_encoder, use_bin_type=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/msgpack/__init__.py", line 36, in packb
    return Packer(**kwargs).pack(o)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "msgpack/_packer.pyx", line 279, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 276, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 270, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 257, in msgpack._cmsgpack.Packer._pack_inner
TypeError: can not serialize 'Undefined' object

[0m11:51:16.576388 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.8818909, "process_in_blocks": "0", "process_kernel_time": 0.138178, "process_mem_max_rss": "122454016", "process_out_blocks": "0", "process_user_time": 1.493102}
[0m11:51:16.576840 [debug] [MainThread]: Command `dbt run` failed at 11:51:16.576684 after 0.88 seconds
[0m11:51:16.577124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053900e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106542840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10644a510>]}
[0m11:51:16.577342 [debug] [MainThread]: Flushing usage events
[0m11:51:17.079221 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:51:38.430235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e6cc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f765a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f76060>]}


============================== 11:51:38.432938 | 14ec5218-e80b-4590-a2b5-9a8d7ffbd81f ==============================
[0m11:51:38.432938 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:51:38.433286 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'static_parser': 'True', 'log_cache_events': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'introspect': 'True', 'warn_error': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'indirect_selection': 'eager', 'write_json': 'True', 'empty': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'target_path': 'None', 'printer_width': '80', 'fail_fast': 'False', 'quiet': 'False', 'invocation_command': 'dbt run --full-refresh'}
[0m11:51:38.522972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c188c0>]}
[0m11:51:38.554684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff3710>]}
[0m11:51:38.555225 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:51:38.622874 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:51:38.677149 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:51:38.677512 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://macros/naming.sql
[0m11:51:38.711117 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m11:51:38.714097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110429850>]}
[0m11:51:38.751485 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:51:38.752795 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:51:38.760636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11048b200>]}
[0m11:51:38.760938 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:51:38.761119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110068830>]}
[0m11:51:38.762057 [info ] [MainThread]: 
[0m11:51:38.762265 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:51:38.762419 [info ] [MainThread]: 
[0m11:51:38.762694 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:51:38.766288 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:51:38.772637 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:51:39.050760 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:51:39.052538 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.060848 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m11:51:39.061160 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m11:51:39.065366 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m11:51:39.067949 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.068988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m11:51:39.072313 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:51:39.074977 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.075753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11000c890>]}
[0m11:51:39.077042 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:51:39.077333 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:51:39.077562 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:51:39.077741 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:51:39.081187 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:51:39.081605 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:51:39.091925 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:51:39.107055 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:51:39.115250 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:39.124529 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:51:39.128871 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.131001 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:51:39.131526 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:51:39.136276 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.147007 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f2d1f0>]}
[0m11:51:39.147378 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.07s]
[0m11:51:39.147675 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:51:39.147876 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:51:39.148100 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:51:39.148308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:51:39.148476 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:51:39.149502 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:51:39.149937 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:51:39.151863 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:51:39.152476 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:51:39.162294 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:39.163969 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:51:39.166505 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.167615 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:51:39.168080 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:51:39.170633 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.171719 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148f7ce0>]}
[0m11:51:39.172058 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:51:39.172333 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:51:39.172522 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:51:39.172871 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:51:39.173203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:51:39.173403 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:51:39.174622 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:51:39.175075 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:51:39.176246 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:51:39.176915 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:51:39.187215 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:39.189093 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:51:39.191802 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.192952 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:51:39.193428 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:51:39.195925 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.197046 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147eed50>]}
[0m11:51:39.197385 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:51:39.197662 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:51:39.197854 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:51:39.198100 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:51:39.198301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:51:39.198468 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:51:39.199566 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:51:39.199970 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:51:39.201155 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:51:39.202036 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:51:39.210952 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:39.212837 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:51:39.215431 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.216538 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:51:39.217003 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:51:39.219205 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.220437 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11493b560>]}
[0m11:51:39.220790 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:51:39.221081 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:51:39.221711 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:51:39.221904 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:51:39.222073 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:51:39.222319 [info ] [MainThread]: 
[0m11:51:39.222487 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m11:51:39.223015 [debug] [MainThread]: Command end result
[0m11:51:39.236472 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:51:39.237577 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:51:39.240590 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:51:39.240766 [info ] [MainThread]: 
[0m11:51:39.240962 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:51:39.241109 [info ] [MainThread]: 
[0m11:51:39.241271 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:51:39.243541 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8513326, "process_in_blocks": "0", "process_kernel_time": 0.199076, "process_mem_max_rss": "167804928", "process_out_blocks": "0", "process_user_time": 1.330064}
[0m11:51:39.243784 [debug] [MainThread]: Command `dbt run` succeeded at 11:51:39.243742 after 0.85 seconds
[0m11:51:39.243984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e94050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1149507d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114951130>]}
[0m11:51:39.244165 [debug] [MainThread]: Flushing usage events
[0m11:51:39.650284 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:53:56.269017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103937b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106914dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106487ef0>]}


============================== 11:53:56.271732 | a329feb5-7c90-49c3-8b1e-562f3e5ca819 ==============================
[0m11:53:56.271732 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:53:56.272090 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'invocation_command': 'dbt clean', 'write_json': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'target_path': 'None', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'log_cache_events': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'printer_width': '80', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'no_print': 'None', 'empty': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m11:53:56.331080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a329feb5-7c90-49c3-8b1e-562f3e5ca819', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106914dd0>]}
[0m11:53:56.340690 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.11157, "process_in_blocks": "0", "process_kernel_time": 0.107164, "process_mem_max_rss": "110723072", "process_out_blocks": "0", "process_user_time": 0.768911}
[0m11:53:56.341028 [debug] [MainThread]: Command `dbt clean` succeeded at 11:53:56.340975 after 0.11 seconds
[0m11:53:56.341241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047a2e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e96f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106caf320>]}
[0m11:53:56.341431 [debug] [MainThread]: Flushing usage events
[0m11:53:56.841573 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:54:09.601187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e8410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098f24e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098f1f70>]}


============================== 11:54:09.603956 | 580dcf39-ff95-4a15-ba8c-2c917e79e6d5 ==============================
[0m11:54:09.603956 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:54:09.604296 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'empty': 'False', 'debug': 'False', 'invocation_command': 'dbt run --full-refresh', 'warn_error': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_cache_events': 'False', 'no_print': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'target_path': 'None', 'static_parser': 'True', 'use_colors': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'log_format': 'default', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'use_experimental_parser': 'False'}
[0m11:54:09.694717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '580dcf39-ff95-4a15-ba8c-2c917e79e6d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a3f6b0>]}
[0m11:54:09.725574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '580dcf39-ff95-4a15-ba8c-2c917e79e6d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109893e00>]}
[0m11:54:09.726118 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:54:09.793286 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:54:09.793847 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:54:09.794063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '580dcf39-ff95-4a15-ba8c-2c917e79e6d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b30830>]}
[0m11:54:10.459051 [error] [MainThread]: Encountered an error:
can not serialize 'Undefined' object
[0m11:54:10.460365 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 272, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 303, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 373, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 350, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 389, in wrapper
    setup_manifest(ctx, write=write, write_perf_info=write_perf_info)
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 416, in setup_manifest
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 2123, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 320, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 518, in load
    self.write_manifest_for_partial_parse()
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 826, in write_manifest_for_partial_parse
    manifest_msgpack = self.manifest.to_msgpack(extended_mashumaro_encoder)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 3, in __mashumaro_to_msgpack__
  File "<string>", line 91, in __mashumaro_to_msgpack__
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 141, in extended_mashumaro_encoder
    return msgpack.packb(data, default=extended_msgpack_encoder, use_bin_type=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/msgpack/__init__.py", line 36, in packb
    return Packer(**kwargs).pack(o)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "msgpack/_packer.pyx", line 279, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 276, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 270, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 257, in msgpack._cmsgpack.Packer._pack_inner
TypeError: can not serialize 'Undefined' object

[0m11:54:10.462068 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.8996778, "process_in_blocks": "0", "process_kernel_time": 0.150504, "process_mem_max_rss": "123830272", "process_out_blocks": "0", "process_user_time": 1.525401}
[0m11:54:10.462334 [debug] [MainThread]: Command `dbt run` failed at 11:54:10.462284 after 0.90 seconds
[0m11:54:10.462544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098f24e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fb5550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f8a600>]}
[0m11:54:10.462727 [debug] [MainThread]: Flushing usage events
[0m11:54:10.902474 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:57:02.036328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058241d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e12e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074bf950>]}


============================== 11:57:02.039087 | 45f88efa-78b4-440e-8a91-303f0371f39c ==============================
[0m11:57:02.039087 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:57:02.039431 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt clean', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'empty': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'fail_fast': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'target_path': 'None', 'quiet': 'False', 'printer_width': '80', 'static_parser': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'use_colors': 'True'}
[0m11:57:02.101103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '45f88efa-78b4-440e-8a91-303f0371f39c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102cdf8f0>]}
[0m11:57:02.107751 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.109522335, "process_in_blocks": "0", "process_kernel_time": 0.104884, "process_mem_max_rss": "110149632", "process_out_blocks": "0", "process_user_time": 0.753536}
[0m11:57:02.108127 [debug] [MainThread]: Command `dbt clean` succeeded at 11:57:02.108067 after 0.11 seconds
[0m11:57:02.108354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e57da0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e12ff0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110010fb0>]}
[0m11:57:02.108578 [debug] [MainThread]: Flushing usage events
[0m11:57:02.581119 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:57:25.638165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fa8830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079765a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107976060>]}


============================== 11:57:25.641016 | 9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d ==============================
[0m11:57:25.641016 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:57:25.641341 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'printer_width': '80', 'debug': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'no_print': 'None', 'quiet': 'False', 'version_check': 'True', 'fail_fast': 'False', 'introspect': 'True', 'use_colors': 'True', 'log_format': 'default', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project'}
[0m11:57:25.734275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a13770>]}
[0m11:57:25.766306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069be300>]}
[0m11:57:25.766955 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:57:25.831691 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:57:25.832173 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:57:25.832375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bd36b0>]}
[0m11:57:26.493491 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m11:57:26.496452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b60ec0>]}
[0m11:57:26.535836 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:57:26.537013 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:57:26.544005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a27bc0>]}
[0m11:57:26.544272 [info ] [MainThread]: Found 4 models, 3 data tests, 487 macros
[0m11:57:26.544453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b62ab0>]}
[0m11:57:26.545335 [info ] [MainThread]: 
[0m11:57:26.545534 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:57:26.545686 [info ] [MainThread]: 
[0m11:57:26.545945 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:57:26.549390 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:57:26.555257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:57:26.849858 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:57:26.851630 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:57:26.860119 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__)
[0m11:57:26.860450 [debug] [ThreadPool]: Creating schema ""
[0m11:57:26.864743 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__"} */
create database if not exists ``
        
  
        
  ...
[0m11:57:26.867178 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__"} */
create database if not exists ``
        
  
        
  
[0m11:57:26.867674 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m11:57:26.868169 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:57:26.868481 [debug] [MainThread]: Connection 'create__' was left open.
[0m11:57:26.868659 [debug] [MainThread]: On create__: Close
[0m11:57:26.868829 [info ] [MainThread]: 
[0m11:57:26.869023 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.32 seconds (0.32s).
[0m11:57:26.869393 [error] [MainThread]: Encountered an error:
Database Error
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 165 (``) (line 2, col 31): ``
          
    
          
    . Expected identifier. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m11:57:26.872412 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.2763425, "process_in_blocks": "0", "process_kernel_time": 0.203752, "process_mem_max_rss": "168542208", "process_out_blocks": "0", "process_user_time": 1.808775}
[0m11:57:26.872727 [debug] [MainThread]: Command `dbt run` failed at 11:57:26.872675 after 1.28 seconds
[0m11:57:26.872944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107976480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131ccef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e003e0>]}
[0m11:57:26.873624 [debug] [MainThread]: Flushing usage events
[0m11:57:27.316291 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:59:33.034623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bd9d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073307d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd4e30>]}


============================== 11:59:33.037415 | 9606066d-8b8f-46e2-b472-8eec599e15e4 ==============================
[0m11:59:33.037415 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:59:33.037788 [debug] [MainThread]: running dbt with arguments {'empty': 'None', 'use_colors': 'True', 'version_check': 'True', 'write_json': 'True', 'static_parser': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'debug': 'False', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_cache_events': 'False', 'quiet': 'False', 'introspect': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'no_print': 'None', 'invocation_command': 'dbt clean', 'log_format': 'default', 'warn_error': 'None'}
[0m11:59:33.095627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9606066d-8b8f-46e2-b472-8eec599e15e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c75580>]}
[0m11:59:33.102822 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.10881804, "process_in_blocks": "0", "process_kernel_time": 0.110678, "process_mem_max_rss": "109772800", "process_out_blocks": "0", "process_user_time": 0.779027}
[0m11:59:33.103122 [debug] [MainThread]: Command `dbt clean` succeeded at 11:59:33.103070 after 0.11 seconds
[0m11:59:33.103317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071d20f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a3af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a3b6b0>]}
[0m11:59:33.103592 [debug] [MainThread]: Flushing usage events
[0m11:59:33.625113 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:59:42.303833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089f6f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10936e5a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10936e060>]}


============================== 11:59:42.306494 | 49c87960-4d62-402c-9df5-85611293de76 ==============================
[0m11:59:42.306494 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:59:42.306845 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'fail_fast': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'partial_parse': 'True', 'version_check': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'static_parser': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'write_json': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'introspect': 'True', 'empty': 'False', 'log_format': 'default', 'no_print': 'None'}
[0m11:59:42.395842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10648dca0>]}
[0m11:59:42.425255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094bbce0>]}
[0m11:59:42.425740 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:59:42.491305 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:59:42.491844 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:59:42.492056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10954e6c0>]}
[0m11:59:43.137423 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m11:59:43.140260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a331f40>]}
[0m11:59:43.178779 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:59:43.179937 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:59:43.186967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3fc1d0>]}
[0m11:59:43.187247 [info ] [MainThread]: Found 4 models, 3 data tests, 487 macros
[0m11:59:43.187428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4131a0>]}
[0m11:59:43.188325 [info ] [MainThread]: 
[0m11:59:43.188514 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:59:43.188654 [info ] [MainThread]: 
[0m11:59:43.188898 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:59:43.191746 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:59:43.197157 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:59:43.475651 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:59:43.477438 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.486071 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__market)
[0m11:59:43.486419 [debug] [ThreadPool]: Creating schema "schema: "market"
"
[0m11:59:43.490635 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__market"} */
create database if not exists `market`
        
  
        
  ...
[0m11:59:43.492968 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.494075 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__market, now list__market)
[0m11:59:43.497305 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m11:59:43.509761 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:59:43.510625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3df4a0>]}
[0m11:59:43.512002 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:59:43.512312 [info ] [Thread-1 (]: 1 of 4 START sql table model `market`.`daily_prices` ........................... [RUN]
[0m11:59:43.512564 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.daily_prices)
[0m11:59:43.512756 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:59:43.516381 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:59:43.517015 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:59:43.527898 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:59:43.542289 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:59:43.550182 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:59:43.560181 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m11:59:43.563429 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.565515 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:59:43.566200 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:59:43.570972 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.581622 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b248800>]}
[0m11:59:43.581996 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `market`.`daily_prices` ...................... [[32mOK[0m in 0.07s]
[0m11:59:43.582291 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:59:43.582494 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:59:43.582706 [info ] [Thread-1 (]: 2 of 4 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m11:59:43.582914 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:59:43.583094 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:59:43.584155 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:59:43.584598 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:59:43.586020 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:59:43.586738 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:59:43.597626 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:59:43.599331 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m11:59:43.601887 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.602992 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:59:43.603520 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:59:43.606283 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.607375 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7827e0>]}
[0m11:59:43.607709 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.02s]
[0m11:59:43.607990 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:59:43.608189 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:59:43.608434 [info ] [Thread-1 (]: 3 of 4 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m11:59:43.608630 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:59:43.608802 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:59:43.609953 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:59:43.610419 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:59:43.611575 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:59:43.612132 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:59:43.616769 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.618304 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m11:59:43.620927 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.622176 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:59:43.622740 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:59:43.625442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.626443 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7ed9d0>]}
[0m11:59:43.626767 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.02s]
[0m11:59:43.627039 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:59:43.627234 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:59:43.627465 [info ] [Thread-1 (]: 4 of 4 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m11:59:43.627659 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:59:43.627819 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:59:43.628937 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:59:43.629352 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:59:43.630537 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:59:43.631985 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:59:43.640506 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:59:43.642199 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m11:59:43.644634 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.645809 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:59:43.646317 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:59:43.649048 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.650120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7f59d0>]}
[0m11:59:43.650470 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.02s]
[0m11:59:43.650759 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:59:43.651426 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:59:43.651659 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:59:43.651820 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:59:43.652066 [info ] [MainThread]: 
[0m11:59:43.652240 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m11:59:43.652748 [debug] [MainThread]: Command end result
[0m11:59:43.665576 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:59:43.666711 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:59:43.669816 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:59:43.669999 [info ] [MainThread]: 
[0m11:59:43.670192 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:59:43.670347 [info ] [MainThread]: 
[0m11:59:43.670518 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:59:43.672893 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.4048234, "process_in_blocks": "0", "process_kernel_time": 0.207177, "process_mem_max_rss": "169459712", "process_out_blocks": "0", "process_user_time": 1.871413}
[0m11:59:43.673177 [debug] [MainThread]: Command `dbt run` succeeded at 11:59:43.673134 after 1.41 seconds
[0m11:59:43.673376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10904fb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089f7fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c564a10>]}
[0m11:59:43.673570 [debug] [MainThread]: Flushing usage events
[0m11:59:44.120441 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:19:57.325685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c86870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728f1a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069e11f0>]}


============================== 12:19:57.328921 | c972e173-e7a8-42b8-b7da-bfb72d8d5942 ==============================
[0m12:19:57.328921 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:19:57.329243 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'no_print': 'None', 'log_format': 'default', 'indirect_selection': 'eager', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'log_cache_events': 'False', 'fail_fast': 'False', 'warn_error': 'None', 'cache_selected_only': 'False', 'quiet': 'False', 'partial_parse': 'True', 'empty': 'None'}
[0m12:19:57.389013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c972e173-e7a8-42b8-b7da-bfb72d8d5942', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ae990>]}
[0m12:19:57.401008 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.112340875, "process_in_blocks": "0", "process_kernel_time": 0.125841, "process_mem_max_rss": "109199360", "process_out_blocks": "0", "process_user_time": 0.774779}
[0m12:19:57.401326 [debug] [MainThread]: Command `dbt clean` succeeded at 12:19:57.401267 after 0.11 seconds
[0m12:19:57.401537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ee150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c77f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dc5850>]}
[0m12:19:57.401732 [debug] [MainThread]: Flushing usage events
[0m12:19:57.886316 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:20:04.121913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107428560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108976360>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108975df0>]}


============================== 12:20:04.124473 | ea88ac6c-4ee1-4470-92cf-564f4f6a0dae ==============================
[0m12:20:04.124473 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:20:04.124811 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'indirect_selection': 'eager', 'no_print': 'None', 'empty': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt run --full-refresh', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_format': 'default', 'printer_width': '80', 'target_path': 'None', 'use_experimental_parser': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error': 'None', 'log_cache_events': 'False'}
[0m12:20:04.214713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077a2660>]}
[0m12:20:04.243920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087dce30>]}
[0m12:20:04.244886 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:20:04.315725 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:20:04.316234 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:20:04.316444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4e600>]}
[0m12:20:04.943128 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `unique`. Arguments to generic tests should be
nested under the `arguments` property.`
[0m12:20:04.944392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf9460>]}
[0m12:20:05.051174 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m12:20:05.056737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109667410>]}
[0m12:20:05.104808 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:20:05.106339 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:20:05.115577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b7ad0>]}
[0m12:20:05.115876 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 487 macros
[0m12:20:05.116067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4d8e0>]}
[0m12:20:05.117150 [info ] [MainThread]: 
[0m12:20:05.117343 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:20:05.117492 [info ] [MainThread]: 
[0m12:20:05.117754 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:20:05.120666 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:20:05.125783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:05.502123 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:20:05.503930 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.513922 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__market)
[0m12:20:05.514231 [debug] [ThreadPool]: Creating schema "schema: "market"
"
[0m12:20:05.518182 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__market"} */
create database if not exists `market`
        
  
        
  ...
[0m12:20:05.520482 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.521520 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__market, now list__market)
[0m12:20:05.524688 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m12:20:05.527383 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.528181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fc63c0>]}
[0m12:20:05.530321 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m12:20:05.530599 [info ] [Thread-1 (]: 1 of 4 START sql table model `market`.`daily_prices` ........................... [RUN]
[0m12:20:05.530830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.daily_prices)
[0m12:20:05.531013 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m12:20:05.534452 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m12:20:05.535106 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m12:20:05.545866 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m12:20:05.561162 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.daily_prices (schema only)
select
    ''  as ticker,                  -- String
    ''  as short_name,              -- String
    toDate('2000-01-01') as date,   -- Date
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDateTime64('2000-01-01 00:00:00', 3) as ingested_at,  -- DateTime64(3)
    '' as batch_id,                 -- String (UUID or run id when you load)
    'yfinance' as source            -- LowCardinality(String) at load time
where 1 = 0
          )
        
        ...
[0m12:20:05.570451 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:20:05.579485 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:20:05.584060 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.586529 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m12:20:05.587281 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume", "ingested_at", "batch_id", "source")-- placeholder model: market.daily_prices (schema only)
select
    ''  as ticker,                  -- String
    ''  as short_name,              -- String
    toDate('2000-01-01') as date,   -- Date
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDateTime64('2000-01-01 00:00:00', 3) as ingested_at,  -- DateTime64(3)
    '' as batch_id,                 -- String (UUID or run id when you load)
    'yfinance' as source            -- LowCardinality(String) at load time
where 1 = 0
  ...
[0m12:20:05.591950 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.602860 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051451f0>]}
[0m12:20:05.603293 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `market`.`daily_prices` ...................... [[32mOK[0m in 0.07s]
[0m12:20:05.603609 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m12:20:05.603820 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m12:20:05.604053 [info ] [Thread-1 (]: 2 of 4 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m12:20:05.604288 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m12:20:05.604467 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m12:20:05.605659 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m12:20:05.606266 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m12:20:05.607692 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m12:20:05.608269 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.monthly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-31') as month_ending, -- Date (last trading day of month)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
          )
        
        ...
[0m12:20:05.618478 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:20:05.620338 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:20:05.623247 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.624512 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m12:20:05.625007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.monthly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-31') as month_ending, -- Date (last trading day of month)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
  ...
[0m12:20:05.627945 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.628990 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9707d0>]}
[0m12:20:05.629319 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.02s]
[0m12:20:05.629603 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m12:20:05.629807 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m12:20:05.630044 [info ] [Thread-1 (]: 3 of 4 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m12:20:05.630239 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m12:20:05.630419 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m12:20:05.632525 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m12:20:05.633060 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m12:20:05.634233 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m12:20:05.634783 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.quarterly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-03-31') as quarter_ending, -- Date (last trading day of quarter)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
          )
        
        ...
[0m12:20:05.640628 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:20:05.642314 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:20:05.645119 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.646406 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m12:20:05.646985 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.quarterly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-03-31') as quarter_ending, -- Date (last trading day of quarter)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
  ...
[0m12:20:05.649862 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.650875 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f909490>]}
[0m12:20:05.651194 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.02s]
[0m12:20:05.651464 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m12:20:05.651663 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m12:20:05.651904 [info ] [Thread-1 (]: 4 of 4 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m12:20:05.652101 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m12:20:05.652274 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m12:20:05.653428 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m12:20:05.653873 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m12:20:05.655047 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m12:20:05.655759 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.weekly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-07') as week_ending,  -- Date (last trading day of week)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,                 -- max daily date used
    toDateTime64('2000-01-01 00:00:00', 3) as built_at        -- when built
where 1 = 0
          )
        
        ...
[0m12:20:05.661263 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:20:05.662920 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:20:05.665889 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.667241 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m12:20:05.667798 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.weekly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-07') as week_ending,  -- Date (last trading day of week)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,                 -- max daily date used
    toDateTime64('2000-01-01 00:00:00', 3) as built_at        -- when built
where 1 = 0
  ...
[0m12:20:05.670607 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.671637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8690a0>]}
[0m12:20:05.672081 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.02s]
[0m12:20:05.672430 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m12:20:05.673146 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:20:05.673366 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m12:20:05.673539 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m12:20:05.673811 [info ] [MainThread]: 
[0m12:20:05.673994 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m12:20:05.674513 [debug] [MainThread]: Command end result
[0m12:20:05.689528 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:20:05.690680 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:20:05.693815 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m12:20:05.694068 [info ] [MainThread]: 
[0m12:20:05.694279 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:20:05.694456 [info ] [MainThread]: 
[0m12:20:05.694636 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m12:20:05.694943 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 4 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m12:20:05.697342 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.6109853, "process_in_blocks": "0", "process_kernel_time": 0.219126, "process_mem_max_rss": "171999232", "process_out_blocks": "0", "process_user_time": 1.966634}
[0m12:20:05.697608 [debug] [MainThread]: Command `dbt run` succeeded at 12:20:05.697563 after 1.61 seconds
[0m12:20:05.697808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a940e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10965b920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8c6570>]}
[0m12:20:05.697994 [debug] [MainThread]: Flushing usage events
[0m12:20:06.124563 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:24:09.847704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10733a0c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d6660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d6150>]}


============================== 12:24:09.850120 | 0f886ab3-fa50-42b7-8190-603ff5e65494 ==============================
[0m12:24:09.850120 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:24:09.850457 [debug] [MainThread]: running dbt with arguments {'empty': 'None', 'invocation_command': 'dbt test', 'debug': 'False', 'partial_parse': 'True', 'use_colors': 'True', 'quiet': 'False', 'printer_width': '80', 'version_check': 'True', 'static_parser': 'True', 'warn_error': 'None', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'indirect_selection': 'eager', 'write_json': 'True', 'introspect': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m12:24:09.937362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107656a20>]}
[0m12:24:09.967006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10761baa0>]}
[0m12:24:09.967490 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:24:10.032261 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:24:10.091035 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:24:10.091300 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:24:10.094635 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
[0m12:24:10.116092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10771a180>]}
[0m12:24:10.164918 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:24:10.166353 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:24:10.182656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcd9d0>]}
[0m12:24:10.183014 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 487 macros
[0m12:24:10.183209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107719c10>]}
[0m12:24:10.184517 [info ] [MainThread]: 
[0m12:24:10.184740 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:24:10.184892 [info ] [MainThread]: 
[0m12:24:10.185189 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:24:10.188841 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__market'
[0m12:24:10.195420 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:24:10.481117 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m12:24:10.485059 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.493411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b02000>]}
[0m12:24:10.494629 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m12:24:10.494853 [info ] [Thread-1 (]: 1 of 14 START test not_null_daily_prices_date .................................. [RUN]
[0m12:24:10.495095 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now test.qi_dbt_project.not_null_daily_prices_date.287ad299aa)
[0m12:24:10.495279 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m12:24:10.504223 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m12:24:10.504994 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m12:24:10.514959 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m12:24:10.515796 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_date.287ad299aa: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from `market`.`daily_prices`
where date is null



  
  
    ) dbt_internal_test...
[0m12:24:10.519986 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.522393 [info ] [Thread-1 (]: 1 of 14 PASS not_null_daily_prices_date ........................................ [[32mPASS[0m in 0.03s]
[0m12:24:10.522723 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m12:24:10.522936 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m12:24:10.523189 [info ] [Thread-1 (]: 2 of 14 START test not_null_daily_prices_ingested_at ........................... [RUN]
[0m12:24:10.523455 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_date.287ad299aa, now test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837)
[0m12:24:10.523654 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m12:24:10.525963 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m12:24:10.526438 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m12:24:10.528436 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m12:24:10.529054 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ingested_at
from `market`.`daily_prices`
where ingested_at is null



  
  
    ) dbt_internal_test...
[0m12:24:10.532582 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.533622 [info ] [Thread-1 (]: 2 of 14 PASS not_null_daily_prices_ingested_at ................................. [[32mPASS[0m in 0.01s]
[0m12:24:10.533923 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m12:24:10.534132 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m12:24:10.534367 [info ] [Thread-1 (]: 3 of 14 START test not_null_daily_prices_short_name ............................ [RUN]
[0m12:24:10.534612 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837, now test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52)
[0m12:24:10.534790 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m12:24:10.537027 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m12:24:10.537456 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m12:24:10.538642 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m12:24:10.539173 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select short_name
from `market`.`daily_prices`
where short_name is null



  
  
    ) dbt_internal_test...
[0m12:24:10.542556 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.543526 [info ] [Thread-1 (]: 3 of 14 PASS not_null_daily_prices_short_name .................................. [[32mPASS[0m in 0.01s]
[0m12:24:10.543837 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m12:24:10.544071 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m12:24:10.544257 [info ] [Thread-1 (]: 4 of 14 START test not_null_daily_prices_ticker ................................ [RUN]
[0m12:24:10.544627 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52, now test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1)
[0m12:24:10.544914 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m12:24:10.547154 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m12:24:10.547912 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m12:24:10.549339 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m12:24:10.550172 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`daily_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m12:24:10.553655 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.554782 [info ] [Thread-1 (]: 4 of 14 PASS not_null_daily_prices_ticker ...................................... [[32mPASS[0m in 0.01s]
[0m12:24:10.555141 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m12:24:10.555341 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m12:24:10.555609 [info ] [Thread-1 (]: 5 of 14 START test not_null_monthly_prices_month_ending ........................ [RUN]
[0m12:24:10.555920 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1, now test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274)
[0m12:24:10.556124 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m12:24:10.558340 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"
[0m12:24:10.559091 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m12:24:10.560483 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"
[0m12:24:10.560946 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month_ending
from `market`.`monthly_prices`
where month_ending is null



  
  
    ) dbt_internal_test...
[0m12:24:10.564138 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.565198 [info ] [Thread-1 (]: 5 of 14 PASS not_null_monthly_prices_month_ending .............................. [[32mPASS[0m in 0.01s]
[0m12:24:10.565548 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m12:24:10.565757 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m12:24:10.565995 [info ] [Thread-1 (]: 6 of 14 START test not_null_monthly_prices_ticker .............................. [RUN]
[0m12:24:10.566270 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274, now test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2)
[0m12:24:10.566468 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m12:24:10.568875 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"
[0m12:24:10.569551 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m12:24:10.570730 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"
[0m12:24:10.571078 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`monthly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m12:24:10.574396 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.575411 [info ] [Thread-1 (]: 6 of 14 PASS not_null_monthly_prices_ticker .................................... [[32mPASS[0m in 0.01s]
[0m12:24:10.575719 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m12:24:10.575920 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m12:24:10.576127 [info ] [Thread-1 (]: 7 of 14 START test not_null_quarterly_prices_quarter_ending .................... [RUN]
[0m12:24:10.576342 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2, now test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab)
[0m12:24:10.576519 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m12:24:10.578781 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"
[0m12:24:10.579263 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m12:24:10.581464 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"
[0m12:24:10.582106 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select quarter_ending
from `market`.`quarterly_prices`
where quarter_ending is null



  
  
    ) dbt_internal_test...
[0m12:24:10.585447 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.586495 [info ] [Thread-1 (]: 7 of 14 PASS not_null_quarterly_prices_quarter_ending .......................... [[32mPASS[0m in 0.01s]
[0m12:24:10.586822 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m12:24:10.587024 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m12:24:10.587240 [info ] [Thread-1 (]: 8 of 14 START test not_null_quarterly_prices_ticker ............................ [RUN]
[0m12:24:10.587447 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab, now test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137)
[0m12:24:10.587628 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m12:24:10.590013 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"
[0m12:24:10.590474 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m12:24:10.591839 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"
[0m12:24:10.592575 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`quarterly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m12:24:10.595778 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.596654 [info ] [Thread-1 (]: 8 of 14 PASS not_null_quarterly_prices_ticker .................................. [[32mPASS[0m in 0.01s]
[0m12:24:10.596935 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m12:24:10.597121 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m12:24:10.597402 [info ] [Thread-1 (]: 9 of 14 START test not_null_weekly_prices_ticker ............................... [RUN]
[0m12:24:10.597734 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137, now test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469)
[0m12:24:10.597946 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m12:24:10.600498 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"
[0m12:24:10.600964 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m12:24:10.602216 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"
[0m12:24:10.602911 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`weekly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m12:24:10.606115 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.607166 [info ] [Thread-1 (]: 9 of 14 PASS not_null_weekly_prices_ticker ..................................... [[32mPASS[0m in 0.01s]
[0m12:24:10.607509 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m12:24:10.607723 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m12:24:10.607942 [info ] [Thread-1 (]: 10 of 14 START test not_null_weekly_prices_week_ending ......................... [RUN]
[0m12:24:10.608187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469, now test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de)
[0m12:24:10.608370 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m12:24:10.610742 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"
[0m12:24:10.611390 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m12:24:10.612784 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"
[0m12:24:10.613224 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select week_ending
from `market`.`weekly_prices`
where week_ending is null



  
  
    ) dbt_internal_test...
[0m12:24:10.616579 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.617517 [info ] [Thread-1 (]: 10 of 14 PASS not_null_weekly_prices_week_ending ............................... [[32mPASS[0m in 0.01s]
[0m12:24:10.617801 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m12:24:10.617992 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303
[0m12:24:10.618283 [info ] [Thread-1 (]: 11 of 14 START test unique_daily_prices_date__ticker__date ..................... [RUN]
[0m12:24:10.618665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de, now test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303)
[0m12:24:10.618881 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303
[0m12:24:10.627789 [debug] [Thread-1 (]: Compilation Error in test unique_daily_prices_date__ticker__date (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.628130 [error] [Thread-1 (]: 11 of 14 ERROR unique_daily_prices_date__ticker__date .......................... [[31mERROR[0m in 0.01s]
[0m12:24:10.628404 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303
[0m12:24:10.628612 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164
[0m12:24:10.628835 [debug] [Thread-4 (]: Marking all children of 'test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303' to be skipped because of status 'error'.  Reason: Compilation Error in test unique_daily_prices_date__ticker__date (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'.
[0m12:24:10.629068 [info ] [Thread-1 (]: 12 of 14 START test unique_monthly_prices_month_ending__ticker__month_ending ... [RUN]
[0m12:24:10.629928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303, now test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164)
[0m12:24:10.630185 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164
[0m12:24:10.633570 [debug] [Thread-1 (]: Compilation Error in test unique_monthly_prices_month_ending__ticker__month_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.633961 [error] [Thread-1 (]: 12 of 14 ERROR unique_monthly_prices_month_ending__ticker__month_ending ........ [[31mERROR[0m in 0.00s]
[0m12:24:10.634235 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164
[0m12:24:10.634443 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5
[0m12:24:10.634675 [debug] [Thread-4 (]: Marking all children of 'test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164' to be skipped because of status 'error'.  Reason: Compilation Error in test unique_monthly_prices_month_ending__ticker__month_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'.
[0m12:24:10.634881 [info ] [Thread-1 (]: 13 of 14 START test unique_quarterly_prices_quarter_ending__ticker__quarter_ending  [RUN]
[0m12:24:10.635216 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164, now test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5)
[0m12:24:10.635433 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5
[0m12:24:10.638493 [debug] [Thread-1 (]: Compilation Error in test unique_quarterly_prices_quarter_ending__ticker__quarter_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.638739 [error] [Thread-1 (]: 13 of 14 ERROR unique_quarterly_prices_quarter_ending__ticker__quarter_ending .. [[31mERROR[0m in 0.00s]
[0m12:24:10.638976 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5
[0m12:24:10.639160 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04
[0m12:24:10.639354 [debug] [Thread-4 (]: Marking all children of 'test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5' to be skipped because of status 'error'.  Reason: Compilation Error in test unique_quarterly_prices_quarter_ending__ticker__quarter_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'.
[0m12:24:10.639540 [info ] [Thread-1 (]: 14 of 14 START test unique_weekly_prices_week_ending__ticker__week_ending ...... [RUN]
[0m12:24:10.639787 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5, now test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04)
[0m12:24:10.639960 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04
[0m12:24:10.644212 [debug] [Thread-1 (]: Compilation Error in test unique_weekly_prices_week_ending__ticker__week_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.644504 [error] [Thread-1 (]: 14 of 14 ERROR unique_weekly_prices_week_ending__ticker__week_ending ........... [[31mERROR[0m in 0.00s]
[0m12:24:10.644765 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04
[0m12:24:10.644977 [debug] [Thread-4 (]: Marking all children of 'test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04' to be skipped because of status 'error'.  Reason: Compilation Error in test unique_weekly_prices_week_ending__ticker__week_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'.
[0m12:24:10.645687 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:24:10.645859 [debug] [MainThread]: Connection 'test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04' was left open.
[0m12:24:10.646015 [debug] [MainThread]: On test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04: Close
[0m12:24:10.646285 [info ] [MainThread]: 
[0m12:24:10.646512 [info ] [MainThread]: Finished running 14 data tests in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m12:24:10.647472 [debug] [MainThread]: Command end result
[0m12:24:10.661570 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:24:10.662919 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:24:10.667074 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m12:24:10.667287 [info ] [MainThread]: 
[0m12:24:10.667471 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m12:24:10.667626 [info ] [MainThread]: 
[0m12:24:10.667815 [error] [MainThread]: [31mFailure in test unique_daily_prices_date__ticker__date (models/market/schema.yml)[0m
[0m12:24:10.667992 [error] [MainThread]:   Compilation Error in test unique_daily_prices_date__ticker__date (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.668132 [info ] [MainThread]: 
[0m12:24:10.668298 [error] [MainThread]: [31mFailure in test unique_monthly_prices_month_ending__ticker__month_ending (models/market/schema.yml)[0m
[0m12:24:10.668463 [error] [MainThread]:   Compilation Error in test unique_monthly_prices_month_ending__ticker__month_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.668595 [info ] [MainThread]: 
[0m12:24:10.668760 [error] [MainThread]: [31mFailure in test unique_quarterly_prices_quarter_ending__ticker__quarter_ending (models/market/schema.yml)[0m
[0m12:24:10.669098 [error] [MainThread]:   Compilation Error in test unique_quarterly_prices_quarter_ending__ticker__quarter_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.669371 [info ] [MainThread]: 
[0m12:24:10.669573 [error] [MainThread]: [31mFailure in test unique_weekly_prices_week_ending__ticker__week_ending (models/market/schema.yml)[0m
[0m12:24:10.669759 [error] [MainThread]:   Compilation Error in test unique_weekly_prices_week_ending__ticker__week_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.669911 [info ] [MainThread]: 
[0m12:24:10.670077 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=4 SKIP=0 NO-OP=0 TOTAL=14
[0m12:24:10.672371 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 0.8604604, "process_in_blocks": "0", "process_kernel_time": 0.197659, "process_mem_max_rss": "168263680", "process_out_blocks": "0", "process_user_time": 1.347708}
[0m12:24:10.672693 [debug] [MainThread]: Command `dbt test` failed at 12:24:10.672642 after 0.86 seconds
[0m12:24:10.672900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cfe630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10714d2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d5fa0>]}
[0m12:24:10.673120 [debug] [MainThread]: Flushing usage events
[0m12:24:11.125528 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:52:21.353231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081345c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d0c110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a4d880>]}


============================== 16:52:21.356532 | 9699f629-9d04-4d2d-a8e7-bdd90da69add ==============================
[0m16:52:21.356532 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:52:21.356883 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'empty': 'None', 'log_cache_events': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'debug': 'False', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'no_print': 'None', 'indirect_selection': 'eager', 'version_check': 'True', 'fail_fast': 'False', 'printer_width': '80', 'warn_error': 'None', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m16:52:21.425883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9699f629-9d04-4d2d-a8e7-bdd90da69add', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109832870>]}
[0m16:52:21.437581 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-54jv47a3'
[0m16:52:21.437893 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m16:52:21.539211 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m16:52:21.540093 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m16:52:21.583621 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m16:52:21.592974 [info ] [MainThread]: Updating lock file in file path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/package-lock.yml
[0m16:52:21.595085 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-e8a0_11n'
[0m16:52:21.597213 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m16:52:21.949878 [info ] [MainThread]: Installed from version 1.3.1
[0m16:52:21.950207 [info ] [MainThread]: Up to date!
[0m16:52:21.950451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '9699f629-9d04-4d2d-a8e7-bdd90da69add', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109948860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10994b170>]}
[0m16:52:21.953162 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.64053786, "process_in_blocks": "0", "process_kernel_time": 0.178269, "process_mem_max_rss": "114163712", "process_out_blocks": "0", "process_user_time": 0.824509}
[0m16:52:21.953576 [debug] [MainThread]: Command `dbt deps` succeeded at 16:52:21.953509 after 0.64 seconds
[0m16:52:21.954026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093cc2c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c59a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096eeff0>]}
[0m16:52:21.954306 [debug] [MainThread]: Flushing usage events
[0m16:52:22.419711 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:54:31.421152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10932d3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093e5bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088fe7e0>]}


============================== 16:54:31.423682 | 0d854234-2b0e-4c05-b49e-79f47f3a7676 ==============================
[0m16:54:31.423682 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:54:31.424023 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'version_check': 'True', 'fail_fast': 'False', 'debug': 'False', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'empty': 'None', 'use_colors': 'True', 'target_path': 'None', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'quiet': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'invocation_command': 'dbt clean', 'partial_parse': 'True'}
[0m16:54:31.487417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0d854234-2b0e-4c05-b49e-79f47f3a7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e53cb0>]}
[0m16:54:31.500792 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.1147455, "process_in_blocks": "0", "process_kernel_time": 0.109589, "process_mem_max_rss": "110297088", "process_out_blocks": "0", "process_user_time": 0.763312}
[0m16:54:31.501105 [debug] [MainThread]: Command `dbt clean` succeeded at 16:54:31.501049 after 0.12 seconds
[0m16:54:31.501322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b94140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106345d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a94ef0>]}
[0m16:54:31.501529 [debug] [MainThread]: Flushing usage events
[0m16:54:31.966885 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:54:40.651665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060711f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061230b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065b6180>]}


============================== 16:54:40.654214 | dd5621fc-116a-42b8-91f4-6c28c216da42 ==============================
[0m16:54:40.654214 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:54:40.654569 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'indirect_selection': 'eager', 'fail_fast': 'False', 'use_colors': 'True', 'invocation_command': 'dbt deps', 'version_check': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'target_path': 'None', 'warn_error': 'None', 'cache_selected_only': 'False', 'partial_parse': 'True', 'empty': 'None', 'quiet': 'False', 'introspect': 'True'}
[0m16:54:40.717849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd5621fc-116a-42b8-91f4-6c28c216da42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ebbc80>]}
[0m16:54:40.740751 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-ton4_ejo'
[0m16:54:40.741018 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m16:54:40.829845 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m16:54:40.830767 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m16:54:40.885985 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m16:54:40.889497 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m16:54:41.402891 [info ] [MainThread]: Installed from version 1.3.1
[0m16:54:41.403185 [info ] [MainThread]: Up to date!
[0m16:54:41.403411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'dd5621fc-116a-42b8-91f4-6c28c216da42', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d7af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e90fe0>]}
[0m16:54:41.405376 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.78944796, "process_in_blocks": "0", "process_kernel_time": 0.146405, "process_mem_max_rss": "114180096", "process_out_blocks": "0", "process_user_time": 0.811004}
[0m16:54:41.405792 [debug] [MainThread]: Command `dbt deps` succeeded at 16:54:41.405732 after 0.79 seconds
[0m16:54:41.406029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106072750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068b1640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106de1c10>]}
[0m16:54:41.406238 [debug] [MainThread]: Flushing usage events
[0m16:54:41.837035 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:54:51.471016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10476e8a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10547a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10547a2a0>]}


============================== 16:54:51.473488 | 7b10cba7-bd23-4423-b3ee-7b28bce9cc32 ==============================
[0m16:54:51.473488 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:54:51.473852 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'write_json': 'True', 'printer_width': '80', 'target_path': 'None', 'empty': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'quiet': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt test', 'log_format': 'default', 'cache_selected_only': 'False', 'no_print': 'None', 'use_colors': 'True', 'debug': 'False'}
[0m16:54:51.570341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b10cba7-bd23-4423-b3ee-7b28bce9cc32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055bbc80>]}
[0m16:54:51.600538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b10cba7-bd23-4423-b3ee-7b28bce9cc32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10374f230>]}
[0m16:54:51.601189 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:54:51.676070 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:54:51.676604 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:54:51.676810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7b10cba7-bd23-4423-b3ee-7b28bce9cc32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b6480>]}
[0m16:54:52.399009 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `dbt_utils.unique_combination_of_columns`.
Arguments to generic tests should be nested under the `arguments` property.`
[0m16:54:52.399358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '7b10cba7-bd23-4423-b3ee-7b28bce9cc32', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b04cb0>]}
[0m16:54:52.409396 [error] [MainThread]: Encountered an error:
Compilation Error in test dbt_utils_unique_combination_of_columns_daily_prices_date__ticker__date (models/market/schema.yml)
  macro 'dbt_macro__test_unique_combination_of_columns' takes no keyword argument 'column_name'
[0m16:54:52.409761 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m16:54:52.411282 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 0.9782215, "process_in_blocks": "0", "process_kernel_time": 0.148857, "process_mem_max_rss": "123551744", "process_out_blocks": "0", "process_user_time": 1.560365}
[0m16:54:52.411634 [debug] [MainThread]: Command `dbt test` failed at 16:54:52.411582 after 0.98 seconds
[0m16:54:52.411857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ec4e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad4fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c0c770>]}
[0m16:54:52.412069 [debug] [MainThread]: Flushing usage events
[0m16:54:52.933275 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:56:26.414994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060f8fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f0f320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106ffe90>]}


============================== 16:56:26.417558 | 2b1b5772-3d1f-4c7d-8af1-c36c80eb547c ==============================
[0m16:56:26.417558 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:56:26.417900 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'target_path': 'None', 'log_format': 'default', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'debug': 'False', 'no_print': 'None', 'cache_selected_only': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'warn_error': 'None', 'invocation_command': 'dbt clean', 'version_check': 'True', 'quiet': 'False', 'printer_width': '80', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'empty': 'None'}
[0m16:56:26.480816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b1b5772-3d1f-4c7d-8af1-c36c80eb547c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110aee240>]}
[0m16:56:26.487878 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.10828979, "process_in_blocks": "0", "process_kernel_time": 0.101855, "process_mem_max_rss": "111378432", "process_out_blocks": "0", "process_user_time": 0.764041}
[0m16:56:26.488163 [debug] [MainThread]: Command `dbt clean` succeeded at 16:56:26.488112 after 0.11 seconds
[0m16:56:26.488353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f760f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062e1f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f0ef60>]}
[0m16:56:26.488530 [debug] [MainThread]: Flushing usage events
[0m16:56:26.971589 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:56:36.304559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107698d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053be7e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053be840>]}


============================== 16:56:36.307212 | 77c89f11-8a1f-4b2b-a549-b4b4bcd7c2d1 ==============================
[0m16:56:36.307212 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:56:36.307556 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt deps', 'partial_parse': 'True', 'fail_fast': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'use_colors': 'True', 'write_json': 'True', 'debug': 'False', 'quiet': 'False', 'log_format': 'default', 'empty': 'None', 'warn_error': 'None', 'log_cache_events': 'False', 'target_path': 'None'}
[0m16:56:36.369953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '77c89f11-8a1f-4b2b-a549-b4b4bcd7c2d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079743b0>]}
[0m16:56:36.391399 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-jgdmhnas'
[0m16:56:36.391643 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m16:56:36.481526 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m16:56:36.482416 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m16:56:36.523759 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m16:56:36.527204 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m16:56:37.030199 [info ] [MainThread]: Installed from version 1.3.1
[0m16:56:37.030495 [info ] [MainThread]: Up to date!
[0m16:56:37.030720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '77c89f11-8a1f-4b2b-a549-b4b4bcd7c2d1', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10780f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a12180>]}
[0m16:56:37.032685 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.76502454, "process_in_blocks": "0", "process_kernel_time": 0.159857, "process_mem_max_rss": "116211712", "process_out_blocks": "0", "process_user_time": 0.829765}
[0m16:56:37.032985 [debug] [MainThread]: Command `dbt deps` succeeded at 16:56:37.032932 after 0.77 seconds
[0m16:56:37.033199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053bd430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105470200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078761e0>]}
[0m16:56:37.033396 [debug] [MainThread]: Flushing usage events
[0m16:56:37.450343 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:56:46.895096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a4e570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10747a5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107479f70>]}


============================== 16:56:46.897466 | 30b3496b-344e-407b-b8a1-baf69285879e ==============================
[0m16:56:46.897466 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:56:46.897796 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'version_check': 'True', 'write_json': 'True', 'target_path': 'None', 'invocation_command': 'dbt test', 'cache_selected_only': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'printer_width': '80', 'static_parser': 'True', 'use_experimental_parser': 'False', 'quiet': 'False'}
[0m16:56:46.991626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074ae150>]}
[0m16:56:47.022806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c7cfb0>]}
[0m16:56:47.023394 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:56:47.092402 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:56:47.092970 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:56:47.093191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076cc470>]}
[0m16:56:47.916014 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
[0m16:56:47.921323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108515b80>]}
[0m16:56:47.970115 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:56:47.971759 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:56:47.986437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108848b00>]}
[0m16:56:47.986739 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m16:56:47.986929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10825f080>]}
[0m16:56:47.988067 [info ] [MainThread]: 
[0m16:56:47.988249 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:56:47.988390 [info ] [MainThread]: 
[0m16:56:47.988628 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:56:47.991536 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__market'
[0m16:56:47.997142 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:48.381270 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:56:48.383929 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.394882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b3e60>]}
[0m16:56:48.396431 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m16:56:48.396651 [info ] [Thread-1 (]: 1 of 14 START test dbt_utils_unique_combination_of_columns_daily_prices_ticker__date  [RUN]
[0m16:56:48.396873 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3)
[0m16:56:48.397050 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m16:56:48.402638 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"
[0m16:56:48.403648 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m16:56:48.413989 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"
[0m16:56:48.415068 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, date
    from `market`.`daily_prices`
    group by ticker, date
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m16:56:48.422386 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.424923 [info ] [Thread-1 (]: 1 of 14 PASS dbt_utils_unique_combination_of_columns_daily_prices_ticker__date . [[32mPASS[0m in 0.03s]
[0m16:56:48.425278 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m16:56:48.425502 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd
[0m16:56:48.425707 [info ] [Thread-1 (]: 2 of 14 START test dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending  [RUN]
[0m16:56:48.425996 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd)
[0m16:56:48.426231 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd
[0m16:56:48.428941 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd"
[0m16:56:48.429646 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd
[0m16:56:48.431054 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd"
[0m16:56:48.431631 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, month_ending
    from `market`.`monthly_prices`
    group by ticker, month_ending
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m16:56:48.437508 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.438505 [info ] [Thread-1 (]: 2 of 14 PASS dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending  [[32mPASS[0m in 0.01s]
[0m16:56:48.438840 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd
[0m16:56:48.439056 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325
[0m16:56:48.439281 [info ] [Thread-1 (]: 3 of 14 START test dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending  [RUN]
[0m16:56:48.439641 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325)
[0m16:56:48.439921 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325
[0m16:56:48.442408 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325"
[0m16:56:48.443159 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325
[0m16:56:48.444706 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325"
[0m16:56:48.445155 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, quarter_ending
    from `market`.`quarterly_prices`
    group by ticker, quarter_ending
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m16:56:48.449017 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.450035 [info ] [Thread-1 (]: 3 of 14 PASS dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending  [[32mPASS[0m in 0.01s]
[0m16:56:48.450372 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325
[0m16:56:48.450605 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20
[0m16:56:48.450915 [info ] [Thread-1 (]: 4 of 14 START test dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending  [RUN]
[0m16:56:48.451267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20)
[0m16:56:48.451470 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20
[0m16:56:48.454008 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20"
[0m16:56:48.454486 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20
[0m16:56:48.455840 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20"
[0m16:56:48.456443 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, week_ending
    from `market`.`weekly_prices`
    group by ticker, week_ending
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m16:56:48.463886 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.464928 [info ] [Thread-1 (]: 4 of 14 PASS dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending  [[32mPASS[0m in 0.01s]
[0m16:56:48.465229 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20
[0m16:56:48.465425 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m16:56:48.465598 [info ] [Thread-1 (]: 5 of 14 START test not_null_daily_prices_date .................................. [RUN]
[0m16:56:48.465802 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20, now test.qi_dbt_project.not_null_daily_prices_date.287ad299aa)
[0m16:56:48.465979 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m16:56:48.470736 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m16:56:48.471367 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m16:56:48.472855 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m16:56:48.473603 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_date.287ad299aa: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from `market`.`daily_prices`
where date is null



  
  
    ) dbt_internal_test...
[0m16:56:48.479156 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.480177 [info ] [Thread-1 (]: 5 of 14 PASS not_null_daily_prices_date ........................................ [[32mPASS[0m in 0.01s]
[0m16:56:48.480489 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m16:56:48.480692 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m16:56:48.480913 [info ] [Thread-1 (]: 6 of 14 START test not_null_daily_prices_ingested_at ........................... [RUN]
[0m16:56:48.481164 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_date.287ad299aa, now test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837)
[0m16:56:48.481350 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m16:56:48.483869 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m16:56:48.484728 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m16:56:48.486216 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m16:56:48.486869 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ingested_at
from `market`.`daily_prices`
where ingested_at is null



  
  
    ) dbt_internal_test...
[0m16:56:48.492263 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.493229 [info ] [Thread-1 (]: 6 of 14 PASS not_null_daily_prices_ingested_at ................................. [[32mPASS[0m in 0.01s]
[0m16:56:48.493529 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m16:56:48.493741 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m16:56:48.493962 [info ] [Thread-1 (]: 7 of 14 START test not_null_daily_prices_short_name ............................ [RUN]
[0m16:56:48.494175 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837, now test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52)
[0m16:56:48.494343 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m16:56:48.496552 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m16:56:48.497016 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m16:56:48.498279 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m16:56:48.498643 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select short_name
from `market`.`daily_prices`
where short_name is null



  
  
    ) dbt_internal_test...
[0m16:56:48.503993 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.505059 [info ] [Thread-1 (]: 7 of 14 PASS not_null_daily_prices_short_name .................................. [[32mPASS[0m in 0.01s]
[0m16:56:48.505414 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m16:56:48.505632 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m16:56:48.505930 [info ] [Thread-1 (]: 8 of 14 START test not_null_daily_prices_ticker ................................ [RUN]
[0m16:56:48.506271 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52, now test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1)
[0m16:56:48.506464 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m16:56:48.508739 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m16:56:48.509224 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m16:56:48.510621 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m16:56:48.511309 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`daily_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m16:56:48.517627 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.518594 [info ] [Thread-1 (]: 8 of 14 PASS not_null_daily_prices_ticker ...................................... [[32mPASS[0m in 0.01s]
[0m16:56:48.518875 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m16:56:48.519066 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m16:56:48.519356 [info ] [Thread-1 (]: 9 of 14 START test not_null_monthly_prices_month_ending ........................ [RUN]
[0m16:56:48.519733 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1, now test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274)
[0m16:56:48.519949 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m16:56:48.522382 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"
[0m16:56:48.523130 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m16:56:48.525645 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"
[0m16:56:48.526144 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month_ending
from `market`.`monthly_prices`
where month_ending is null



  
  
    ) dbt_internal_test...
[0m16:56:48.530757 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.531843 [info ] [Thread-1 (]: 9 of 14 PASS not_null_monthly_prices_month_ending .............................. [[32mPASS[0m in 0.01s]
[0m16:56:48.532157 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m16:56:48.532353 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m16:56:48.532618 [info ] [Thread-1 (]: 10 of 14 START test not_null_monthly_prices_ticker ............................. [RUN]
[0m16:56:48.532924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274, now test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2)
[0m16:56:48.533118 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m16:56:48.535660 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"
[0m16:56:48.536125 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m16:56:48.537335 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"
[0m16:56:48.537955 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`monthly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m16:56:48.541605 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.542552 [info ] [Thread-1 (]: 10 of 14 PASS not_null_monthly_prices_ticker ................................... [[32mPASS[0m in 0.01s]
[0m16:56:48.542847 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m16:56:48.543040 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m16:56:48.543323 [info ] [Thread-1 (]: 11 of 14 START test not_null_quarterly_prices_quarter_ending ................... [RUN]
[0m16:56:48.543664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2, now test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab)
[0m16:56:48.543858 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m16:56:48.546122 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"
[0m16:56:48.546824 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m16:56:48.548412 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"
[0m16:56:48.549055 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select quarter_ending
from `market`.`quarterly_prices`
where quarter_ending is null



  
  
    ) dbt_internal_test...
[0m16:56:48.554662 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.555721 [info ] [Thread-1 (]: 11 of 14 PASS not_null_quarterly_prices_quarter_ending ......................... [[32mPASS[0m in 0.01s]
[0m16:56:48.556062 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m16:56:48.556344 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m16:56:48.556695 [info ] [Thread-1 (]: 12 of 14 START test not_null_quarterly_prices_ticker ........................... [RUN]
[0m16:56:48.557002 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab, now test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137)
[0m16:56:48.557202 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m16:56:48.559594 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"
[0m16:56:48.560275 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m16:56:48.561568 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"
[0m16:56:48.561933 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`quarterly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m16:56:48.567077 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.568119 [info ] [Thread-1 (]: 12 of 14 PASS not_null_quarterly_prices_ticker ................................. [[32mPASS[0m in 0.01s]
[0m16:56:48.568437 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m16:56:48.568633 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m16:56:48.568916 [info ] [Thread-1 (]: 13 of 14 START test not_null_weekly_prices_ticker .............................. [RUN]
[0m16:56:48.569260 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137, now test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469)
[0m16:56:48.569456 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m16:56:48.571756 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"
[0m16:56:48.572189 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m16:56:48.573406 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"
[0m16:56:48.573816 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`weekly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m16:56:48.580205 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.581210 [info ] [Thread-1 (]: 13 of 14 PASS not_null_weekly_prices_ticker .................................... [[32mPASS[0m in 0.01s]
[0m16:56:48.581496 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m16:56:48.581693 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m16:56:48.581895 [info ] [Thread-1 (]: 14 of 14 START test not_null_weekly_prices_week_ending ......................... [RUN]
[0m16:56:48.582091 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469, now test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de)
[0m16:56:48.582259 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m16:56:48.585793 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"
[0m16:56:48.586304 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m16:56:48.624553 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"
[0m16:56:48.625150 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select week_ending
from `market`.`weekly_prices`
where week_ending is null



  
  
    ) dbt_internal_test...
[0m16:56:48.631561 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.632574 [info ] [Thread-1 (]: 14 of 14 PASS not_null_weekly_prices_week_ending ............................... [[32mPASS[0m in 0.05s]
[0m16:56:48.632918 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m16:56:48.633564 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:56:48.633766 [debug] [MainThread]: Connection 'test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de' was left open.
[0m16:56:48.633931 [debug] [MainThread]: On test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de: Close
[0m16:56:48.634152 [info ] [MainThread]: 
[0m16:56:48.634322 [info ] [MainThread]: Finished running 14 data tests in 0 hours 0 minutes and 0.65 seconds (0.65s).
[0m16:56:48.635332 [debug] [MainThread]: Command end result
[0m16:56:48.652485 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:56:48.653678 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:56:48.657714 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:56:48.657953 [info ] [MainThread]: 
[0m16:56:48.658147 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:56:48.658306 [info ] [MainThread]: 
[0m16:56:48.658480 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=14
[0m16:56:48.660965 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.8028938, "process_in_blocks": "0", "process_kernel_time": 0.226894, "process_mem_max_rss": "175423488", "process_out_blocks": "0", "process_user_time": 2.15768}
[0m16:56:48.661234 [debug] [MainThread]: Command `dbt test` succeeded at 16:56:48.661190 after 1.80 seconds
[0m16:56:48.661430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063961b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083008c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b624b0>]}
[0m16:56:48.661623 [debug] [MainThread]: Flushing usage events
[0m16:56:49.109451 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:35:20.859107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cafb00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11117d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137e6f0>]}


============================== 18:35:20.862124 | d9a20fa1-f653-4752-81d3-eda441d12856 ==============================
[0m18:35:20.862124 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:35:20.862463 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'empty': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'fail_fast': 'False', 'printer_width': '80', 'debug': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'static_parser': 'True', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'quiet': 'False'}
[0m18:35:20.961871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111330140>]}
[0m18:35:20.992329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113f3ec0>]}
[0m18:35:20.992926 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:35:21.063953 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:35:21.141724 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:35:21.141978 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:35:21.145176 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
[0m18:35:21.165959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11172a000>]}
[0m18:35:21.212574 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m18:35:21.214416 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m18:35:21.226682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ad0d70>]}
[0m18:35:21.226954 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m18:35:21.227139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11153eb70>]}
[0m18:35:21.228136 [info ] [MainThread]: 
[0m18:35:21.228318 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:35:21.228459 [info ] [MainThread]: 
[0m18:35:21.228698 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:35:21.231438 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:35:21.237632 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:35:21.729939 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:35:21.731772 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.743293 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m18:35:21.746895 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m18:35:21.750018 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.751232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116a53bc0>]}
[0m18:35:21.753058 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m18:35:21.753359 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m18:35:21.753602 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m18:35:21.753788 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m18:35:21.757416 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m18:35:21.757854 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m18:35:21.787305 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.monthly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-31') as month_ending, -- Date (last trading day of month)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
          )
        
        ...
[0m18:35:21.795589 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:35:21.804640 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:35:21.809784 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.812288 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m18:35:21.813080 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.monthly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-31') as month_ending, -- Date (last trading day of month)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
  ...
[0m18:35:21.818128 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.820752 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m18:35:21.823190 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.836257 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m18:35:21.840432 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.842242 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a44f50>]}
[0m18:35:21.842597 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.09s]
[0m18:35:21.842900 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m18:35:21.843111 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m18:35:21.843332 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m18:35:21.843578 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m18:35:21.843770 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m18:35:21.844904 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m18:35:21.845329 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m18:35:21.847020 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.quarterly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-03-31') as quarter_ending, -- Date (last trading day of quarter)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
          )
        
        ...
[0m18:35:21.854308 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:35:21.856070 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:35:21.858873 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.860117 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m18:35:21.860612 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.quarterly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-03-31') as quarter_ending, -- Date (last trading day of quarter)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
  ...
[0m18:35:21.863573 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.864256 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m18:35:21.866474 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.868382 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m18:35:21.869723 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.870519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a44f50>]}
[0m18:35:21.870844 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.03s]
[0m18:35:21.871135 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m18:35:21.871331 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m18:35:21.871544 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m18:35:21.871800 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m18:35:21.871998 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m18:35:21.873127 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m18:35:21.873547 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m18:35:21.876227 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.weekly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-07') as week_ending,  -- Date (last trading day of week)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,                 -- max daily date used
    toDateTime64('2000-01-01 00:00:00', 3) as built_at        -- when built
where 1 = 0
          )
        
        ...
[0m18:35:21.884683 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:35:21.886396 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:35:21.889405 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.890653 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m18:35:21.891209 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.weekly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-07') as week_ending,  -- Date (last trading day of week)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,                 -- max daily date used
    toDateTime64('2000-01-01 00:00:00', 3) as built_at        -- when built
where 1 = 0
  ...
[0m18:35:21.893978 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.894708 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m18:35:21.897368 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.899390 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m18:35:21.900779 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.901590 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117fbd370>]}
[0m18:35:21.901948 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.03s]
[0m18:35:21.902243 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m18:35:21.902915 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:35:21.903079 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m18:35:21.903228 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m18:35:21.903462 [info ] [MainThread]: 
[0m18:35:21.903621 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.67 seconds (0.67s).
[0m18:35:21.904041 [debug] [MainThread]: Command end result
[0m18:35:21.921050 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m18:35:21.922194 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m18:35:21.925610 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m18:35:21.925813 [info ] [MainThread]: 
[0m18:35:21.926011 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:35:21.926160 [info ] [MainThread]: 
[0m18:35:21.926325 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m18:35:21.928908 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1084697, "process_in_blocks": "0", "process_kernel_time": 0.235839, "process_mem_max_rss": "189890560", "process_out_blocks": "0", "process_user_time": 1.382548}
[0m18:35:21.929144 [debug] [MainThread]: Command `dbt run` succeeded at 18:35:21.929104 after 1.11 seconds
[0m18:35:21.929324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11131b530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11119b230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113f3d70>]}
[0m18:35:21.929503 [debug] [MainThread]: Flushing usage events
[0m18:35:22.425702 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:39:12.227899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab54d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c47aa80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c47a540>]}


============================== 18:39:12.230790 | bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79 ==============================
[0m18:39:12.230790 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:39:12.231126 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'log_format': 'default', 'debug': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'no_print': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_cache_events': 'False', 'introspect': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'warn_error': 'None'}
[0m18:39:12.323119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b929fa0>]}
[0m18:39:12.353192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c07e480>]}
[0m18:39:12.354111 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:39:12.426262 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:39:12.501536 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m18:39:12.501922 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/weekly_prices.sql
[0m18:39:12.502143 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/quarterly_prices.sql
[0m18:39:12.502350 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/monthly_prices.sql
[0m18:39:12.712000 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
[0m18:39:12.718853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ccc15e0>]}
[0m18:39:12.799793 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m18:39:12.801114 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m18:39:12.812496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cef2120>]}
[0m18:39:12.812766 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m18:39:12.812953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cfeb2c0>]}
[0m18:39:12.813958 [info ] [MainThread]: 
[0m18:39:12.814159 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:39:12.814304 [info ] [MainThread]: 
[0m18:39:12.814544 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:39:12.817482 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:39:12.823307 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:13.219738 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:39:13.221500 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.232386 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m18:39:13.236068 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m18:39:13.239097 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.240331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d8251f0>]}
[0m18:39:13.241931 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m18:39:13.242212 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m18:39:13.242444 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m18:39:13.242630 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m18:39:13.246415 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m18:39:13.246948 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m18:39:13.276559 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m18:39:13.284933 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:39:13.327049 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:39:13.330101 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.332475 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m18:39:13.333027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m18:39:13.355285 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:39:13.358129 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m18:39:13.360596 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.374452 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m18:39:13.376283 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.378110 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c45190>]}
[0m18:39:13.378464 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.14s]
[0m18:39:13.378771 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m18:39:13.378981 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m18:39:13.379273 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m18:39:13.379540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m18:39:13.379741 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m18:39:13.380965 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m18:39:13.381401 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m18:39:13.383113 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m18:39:13.387428 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.389147 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:39:13.391851 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.393001 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m18:39:13.393509 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m18:39:13.410554 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:39:13.411337 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m18:39:13.414452 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.416617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m18:39:13.418039 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.419010 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12d6ebda0>]}
[0m18:39:13.419367 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m18:39:13.419670 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m18:39:13.419886 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m18:39:13.420104 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m18:39:13.420386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m18:39:13.420623 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m18:39:13.421983 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m18:39:13.422434 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m18:39:13.425205 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m18:39:13.429824 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.431604 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:39:13.434212 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.435441 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m18:39:13.435958 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m18:39:13.465974 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:39:13.466807 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m18:39:13.469621 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.471670 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m18:39:13.473271 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.474117 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12d6fe420>]}
[0m18:39:13.474456 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m18:39:13.474748 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m18:39:13.475411 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:39:13.475614 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m18:39:13.475776 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m18:39:13.476013 [info ] [MainThread]: 
[0m18:39:13.476186 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.66 seconds (0.66s).
[0m18:39:13.476618 [debug] [MainThread]: Command end result
[0m18:39:13.494281 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m18:39:13.495466 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m18:39:13.498869 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m18:39:13.499094 [info ] [MainThread]: 
[0m18:39:13.499289 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:39:13.499439 [info ] [MainThread]: 
[0m18:39:13.499602 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m18:39:13.502501 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3112717, "process_in_blocks": "0", "process_kernel_time": 0.24293, "process_mem_max_rss": "195739648", "process_out_blocks": "0", "process_user_time": 1.624045}
[0m18:39:13.502875 [debug] [MainThread]: Command `dbt run` succeeded at 18:39:13.502819 after 1.31 seconds
[0m18:39:13.503121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107edf980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b4b3bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d80b290>]}
[0m18:39:13.503340 [debug] [MainThread]: Flushing usage events
[0m18:39:13.966164 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:01:00.965375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11419b980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112038ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114824200>]}


============================== 23:01:00.968438 | 8d855564-0f2f-410e-9099-3462909e6a6e ==============================
[0m23:01:00.968438 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:01:00.968873 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'write_json': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'target_path': 'None', 'empty': 'False', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'static_parser': 'True', 'quiet': 'False', 'printer_width': '80', 'use_colors': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'log_format': 'default', 'introspect': 'True', 'version_check': 'True', 'no_print': 'None', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices'}
[0m23:01:01.067000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eec650>]}
[0m23:01:01.097472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bbb920>]}
[0m23:01:01.098086 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m23:01:01.171503 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:01:01.253601 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:01:01.253905 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:01:01.257371 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
[0m23:01:01.280510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114dc4ce0>]}
[0m23:01:01.331846 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:01:01.333171 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:01:01.344764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e29df0>]}
[0m23:01:01.345053 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m23:01:01.345239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11489fb00>]}
[0m23:01:01.346280 [info ] [MainThread]: 
[0m23:01:01.346483 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:01:01.346639 [info ] [MainThread]: 
[0m23:01:01.346919 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m23:01:01.349814 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m23:01:01.355852 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:01:01.692546 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m23:01:01.694316 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.705233 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m23:01:01.708854 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m23:01:01.714615 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m23:01:01.716066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221195e0>]}
[0m23:01:01.718018 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m23:01:01.718373 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m23:01:01.718656 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m23:01:01.718860 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m23:01:01.722685 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m23:01:01.723193 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m23:01:01.752855 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m23:01:01.757696 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.766838 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:01:01.769401 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.771867 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m23:01:01.772390 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m23:01:01.821132 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m23:01:01.824420 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m23:01:01.827271 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.842143 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m23:01:01.843834 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.845798 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1236f3710>]}
[0m23:01:01.846176 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.13s]
[0m23:01:01.846521 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m23:01:01.846748 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m23:01:01.847055 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m23:01:01.847328 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m23:01:01.847546 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m23:01:01.848885 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m23:01:01.849460 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m23:01:01.851450 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m23:01:01.856298 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.858238 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:01:01.860897 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.862208 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m23:01:01.862740 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m23:01:01.889804 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m23:01:01.890603 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m23:01:01.893339 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.896385 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m23:01:01.897884 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.898893 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237267e0>]}
[0m23:01:01.899285 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.05s]
[0m23:01:01.899610 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m23:01:01.899855 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m23:01:01.900094 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m23:01:01.900335 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m23:01:01.900546 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m23:01:01.901841 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m23:01:01.902403 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m23:01:01.904431 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m23:01:01.909140 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.910998 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:01:01.913509 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.914793 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m23:01:01.915302 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m23:01:01.955637 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m23:01:01.956485 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m23:01:01.959070 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.961181 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m23:01:01.962727 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.963644 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123737620>]}
[0m23:01:01.964006 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.06s]
[0m23:01:01.964306 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m23:01:01.965025 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:01:01.965226 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m23:01:01.965386 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m23:01:01.965634 [info ] [MainThread]: 
[0m23:01:01.965886 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.62 seconds (0.62s).
[0m23:01:01.966393 [debug] [MainThread]: Command end result
[0m23:01:01.984873 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:01:01.986202 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:01:01.990084 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m23:01:01.990324 [info ] [MainThread]: 
[0m23:01:01.990545 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:01:01.990716 [info ] [MainThread]: 
[0m23:01:01.990899 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m23:01:01.993810 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0672667, "process_in_blocks": "0", "process_kernel_time": 0.234066, "process_mem_max_rss": "192692224", "process_out_blocks": "0", "process_user_time": 1.404802}
[0m23:01:01.994080 [debug] [MainThread]: Command `dbt run` succeeded at 23:01:01.994036 after 1.07 seconds
[0m23:01:01.994292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115a5dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c60200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c60d70>]}
[0m23:01:01.994504 [debug] [MainThread]: Flushing usage events
[0m23:01:08.275850 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:24:45.773412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10800e780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109144a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109144440>]}


============================== 23:24:45.776613 | 41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6 ==============================
[0m23:24:45.776613 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:24:45.776980 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'no_print': 'None', 'target_path': 'None', 'fail_fast': 'False', 'partial_parse': 'True', 'empty': 'False', 'introspect': 'True', 'warn_error': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'static_parser': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'use_colors': 'True', 'quiet': 'False', 'write_json': 'True', 'log_format': 'default'}
[0m23:24:45.882002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109144920>]}
[0m23:24:45.912236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087c61e0>]}
[0m23:24:45.912815 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m23:24:45.985057 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:24:46.067828 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:24:46.068110 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:24:46.071662 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m23:24:46.092785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109381d90>]}
[0m23:24:46.141323 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:24:46.142863 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:24:46.154585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092f3260>]}
[0m23:24:46.154860 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m23:24:46.155052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109786000>]}
[0m23:24:46.156046 [info ] [MainThread]: 
[0m23:24:46.156238 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:24:46.156385 [info ] [MainThread]: 
[0m23:24:46.156636 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m23:24:46.159450 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m23:24:46.165556 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:24:46.671138 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m23:24:46.672882 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.684360 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m23:24:46.688119 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m23:24:46.691611 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.692910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a00c4d0>]}
[0m23:24:46.694800 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m23:24:46.695099 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m23:24:46.695357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m23:24:46.695563 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m23:24:46.699382 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m23:24:46.699804 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m23:24:46.728882 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m23:24:46.736029 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m23:24:46.744954 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:24:46.749223 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.751445 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m23:24:46.751988 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m23:24:46.774281 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m23:24:46.777380 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m23:24:46.779899 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.794525 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m23:24:46.796118 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.798096 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a277a0>]}
[0m23:24:46.798481 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.10s]
[0m23:24:46.798798 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m23:24:46.799012 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m23:24:46.799239 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m23:24:46.799480 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m23:24:46.799667 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m23:24:46.800901 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m23:24:46.801415 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m23:24:46.803303 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m23:24:46.808222 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.809963 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:24:46.812381 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.813648 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m23:24:46.815037 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m23:24:46.833198 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m23:24:46.833989 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m23:24:46.836664 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.839762 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m23:24:46.841369 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.842231 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f23ea20>]}
[0m23:24:46.842601 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m23:24:46.842916 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m23:24:46.843132 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m23:24:46.843362 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m23:24:46.843586 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m23:24:46.843780 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m23:24:46.844952 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m23:24:46.845472 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m23:24:46.847307 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m23:24:46.852143 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.853926 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:24:46.856411 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.857632 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m23:24:46.858129 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m23:24:46.885777 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m23:24:46.886664 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m23:24:46.889319 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.891783 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m23:24:46.893361 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.894365 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f220560>]}
[0m23:24:46.894769 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m23:24:46.895111 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m23:24:46.895830 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:24:46.896071 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m23:24:46.896271 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m23:24:46.896565 [info ] [MainThread]: 
[0m23:24:46.896772 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m23:24:46.897288 [debug] [MainThread]: Command end result
[0m23:24:46.916833 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:24:46.918060 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:24:46.921232 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m23:24:46.921426 [info ] [MainThread]: 
[0m23:24:46.921630 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:24:46.921789 [info ] [MainThread]: 
[0m23:24:46.921963 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m23:24:46.924966 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1895678, "process_in_blocks": "0", "process_kernel_time": 0.248707, "process_mem_max_rss": "191791104", "process_out_blocks": "0", "process_user_time": 1.401782}
[0m23:24:46.925263 [debug] [MainThread]: Command `dbt run` succeeded at 23:24:46.925216 after 1.19 seconds
[0m23:24:46.925474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109113f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090c0ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc32b40>]}
[0m23:24:46.925675 [debug] [MainThread]: Flushing usage events
[0m23:24:47.428278 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:25:05.792635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ece180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b246e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b241a0>]}


============================== 23:25:05.795063 | cf75953a-0a4a-4f6a-ae60-edaa06294b19 ==============================
[0m23:25:05.795063 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:25:05.795398 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'warn_error': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'no_print': 'None', 'cache_selected_only': 'False', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'debug': 'False', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'use_colors': 'True', 'printer_width': '80', 'quiet': 'False', 'invocation_command': 'dbt test --select market.daily_prices', 'log_cache_events': 'False'}
[0m23:25:05.885914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105896d20>]}
[0m23:25:05.916470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b35400>]}
[0m23:25:05.916983 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m23:25:05.986830 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:25:06.048671 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:25:06.048939 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:25:06.052262 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m23:25:06.075056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc4620>]}
[0m23:25:06.124906 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:25:06.126254 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:25:06.139676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf6a50>]}
[0m23:25:06.139955 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m23:25:06.140136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b19280>]}
[0m23:25:06.141066 [info ] [MainThread]: 
[0m23:25:06.141254 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:25:06.141396 [info ] [MainThread]: 
[0m23:25:06.141658 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m23:25:06.144629 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__market'
[0m23:25:06.151597 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:25:06.483201 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m23:25:06.485999 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.494644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc5910>]}
[0m23:25:06.495969 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m23:25:06.496227 [info ] [Thread-1 (]: 1 of 5 START test dbt_utils_unique_combination_of_columns_daily_prices_ticker__date  [RUN]
[0m23:25:06.496483 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3)
[0m23:25:06.496674 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m23:25:06.507560 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"
[0m23:25:06.508400 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m23:25:06.518877 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"
[0m23:25:06.519400 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, date
    from `market`.`daily_prices`
    group by ticker, date
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m23:25:06.548353 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m23:25:06.551001 [info ] [Thread-1 (]: 1 of 5 PASS dbt_utils_unique_combination_of_columns_daily_prices_ticker__date .. [[32mPASS[0m in 0.05s]
[0m23:25:06.551352 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m23:25:06.551578 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m23:25:06.551777 [info ] [Thread-1 (]: 2 of 5 START test not_null_daily_prices_date ................................... [RUN]
[0m23:25:06.552069 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3, now test.qi_dbt_project.not_null_daily_prices_date.287ad299aa)
[0m23:25:06.552260 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m23:25:06.556307 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m23:25:06.557068 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m23:25:06.558643 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m23:25:06.559212 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_date.287ad299aa: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from `market`.`daily_prices`
where date is null



  
  
    ) dbt_internal_test...
[0m23:25:06.563030 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.564161 [info ] [Thread-1 (]: 2 of 5 PASS not_null_daily_prices_date ......................................... [[32mPASS[0m in 0.01s]
[0m23:25:06.564505 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m23:25:06.564727 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m23:25:06.564997 [info ] [Thread-1 (]: 3 of 5 START test not_null_daily_prices_ingested_at ............................ [RUN]
[0m23:25:06.565287 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_date.287ad299aa, now test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837)
[0m23:25:06.565508 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m23:25:06.567843 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m23:25:06.568549 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m23:25:06.571027 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m23:25:06.571482 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ingested_at
from `market`.`daily_prices`
where ingested_at is null



  
  
    ) dbt_internal_test...
[0m23:25:06.575251 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.576227 [info ] [Thread-1 (]: 3 of 5 PASS not_null_daily_prices_ingested_at .................................. [[32mPASS[0m in 0.01s]
[0m23:25:06.576550 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m23:25:06.576754 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m23:25:06.576977 [info ] [Thread-1 (]: 4 of 5 START test not_null_daily_prices_short_name ............................. [RUN]
[0m23:25:06.577253 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837, now test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52)
[0m23:25:06.577458 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m23:25:06.579910 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m23:25:06.580624 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m23:25:06.582120 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m23:25:06.582574 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select short_name
from `market`.`daily_prices`
where short_name is null



  
  
    ) dbt_internal_test...
[0m23:25:06.586140 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.587169 [info ] [Thread-1 (]: 4 of 5 PASS not_null_daily_prices_short_name ................................... [[32mPASS[0m in 0.01s]
[0m23:25:06.587491 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m23:25:06.587710 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m23:25:06.587911 [info ] [Thread-1 (]: 5 of 5 START test not_null_daily_prices_ticker ................................. [RUN]
[0m23:25:06.588126 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52, now test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1)
[0m23:25:06.588301 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m23:25:06.590753 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m23:25:06.591284 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m23:25:06.592883 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m23:25:06.593269 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`daily_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m23:25:06.596816 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.597873 [info ] [Thread-1 (]: 5 of 5 PASS not_null_daily_prices_ticker ....................................... [[32mPASS[0m in 0.01s]
[0m23:25:06.598206 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m23:25:06.598888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:25:06.599077 [debug] [MainThread]: Connection 'test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1' was left open.
[0m23:25:06.599241 [debug] [MainThread]: On test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1: Close
[0m23:25:06.599474 [info ] [MainThread]: 
[0m23:25:06.599645 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m23:25:06.600191 [debug] [MainThread]: Command end result
[0m23:25:06.617561 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:25:06.618558 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:25:06.622341 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m23:25:06.622586 [info ] [MainThread]: 
[0m23:25:06.622777 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:25:06.622934 [info ] [MainThread]: 
[0m23:25:06.623110 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m23:25:06.625625 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.8686088, "process_in_blocks": "0", "process_kernel_time": 0.206832, "process_mem_max_rss": "193904640", "process_out_blocks": "0", "process_user_time": 1.352156}
[0m23:25:06.625924 [debug] [MainThread]: Command `dbt test` succeeded at 23:25:06.625875 after 0.87 seconds
[0m23:25:06.626131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b24680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106789070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106980470>]}
[0m23:25:06.626324 [debug] [MainThread]: Flushing usage events
[0m23:25:07.073348 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:53:15.446266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc41970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da249b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da243b0>]}


============================== 23:53:15.449153 | f98943e9-a2af-4fb3-9c61-0a41ef60e0f7 ==============================
[0m23:53:15.449153 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:53:15.449534 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'log_cache_events': 'False', 'quiet': 'False', 'debug': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'fail_fast': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'target_path': 'None', 'static_parser': 'True', 'empty': 'False', 'log_format': 'default', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_colors': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False'}
[0m23:53:15.547429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db61d00>]}
[0m23:53:15.577883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db76330>]}
[0m23:53:15.578859 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m23:53:15.651658 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:53:15.732025 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:53:15.732329 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:53:15.735872 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m23:53:15.757418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dec46b0>]}
[0m23:53:15.804802 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:53:15.806335 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:53:15.818093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df27a10>]}
[0m23:53:15.818407 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m23:53:15.818603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc8b830>]}
[0m23:53:15.819690 [info ] [MainThread]: 
[0m23:53:15.819901 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:53:15.820057 [info ] [MainThread]: 
[0m23:53:15.820325 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m23:53:15.823247 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m23:53:15.829267 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:53:16.162217 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m23:53:16.163976 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.174379 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m23:53:16.177923 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m23:53:16.180980 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.182138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a9e810>]}
[0m23:53:16.183619 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m23:53:16.183916 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m23:53:16.184180 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m23:53:16.184378 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m23:53:16.188208 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m23:53:16.188736 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m23:53:16.217949 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m23:53:16.226476 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m23:53:16.235631 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:53:16.238475 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.240754 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m23:53:16.241292 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m23:53:16.261439 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m23:53:16.264313 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m23:53:16.267243 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.280917 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m23:53:16.282563 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.284500 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099c3260>]}
[0m23:53:16.284872 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.10s]
[0m23:53:16.285189 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m23:53:16.285404 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m23:53:16.285631 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m23:53:16.285862 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m23:53:16.286047 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m23:53:16.287242 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m23:53:16.287791 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m23:53:16.289859 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m23:53:16.294201 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.295929 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:53:16.298531 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.299752 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m23:53:16.300235 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m23:53:16.317815 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m23:53:16.318662 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m23:53:16.321146 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.324075 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m23:53:16.325504 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.326443 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c853ef0>]}
[0m23:53:16.326889 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m23:53:16.327215 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m23:53:16.327452 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m23:53:16.327767 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m23:53:16.328032 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m23:53:16.328232 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m23:53:16.329507 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m23:53:16.329974 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m23:53:16.332042 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m23:53:16.336842 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.338658 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:53:16.341352 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.342587 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m23:53:16.343128 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m23:53:16.371734 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m23:53:16.372657 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m23:53:16.375475 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.377796 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m23:53:16.379402 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.380268 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c853ef0>]}
[0m23:53:16.380638 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m23:53:16.380954 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m23:53:16.381645 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:53:16.381860 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m23:53:16.382050 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m23:53:16.382324 [info ] [MainThread]: 
[0m23:53:16.382524 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m23:53:16.383037 [debug] [MainThread]: Command end result
[0m23:53:16.401945 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:53:16.403143 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:53:16.406225 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m23:53:16.406408 [info ] [MainThread]: 
[0m23:53:16.406607 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:53:16.406761 [info ] [MainThread]: 
[0m23:53:16.406932 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m23:53:16.409864 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.99981904, "process_in_blocks": "0", "process_kernel_time": 0.215308, "process_mem_max_rss": "192118784", "process_out_blocks": "0", "process_user_time": 1.416586}
[0m23:53:16.410214 [debug] [MainThread]: Command `dbt run` succeeded at 23:53:16.410166 after 1.00 seconds
[0m23:53:16.410421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da249b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10daf4d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df1afc0>]}
[0m23:53:16.410618 [debug] [MainThread]: Flushing usage events
[0m23:53:16.889740 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:00:26.250174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111194560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e24830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e24140>]}


============================== 00:00:26.252703 | 368338c0-d95d-4820-896b-e931947b6c03 ==============================
[0m00:00:26.252703 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:00:26.253036 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'partial_parse': 'True', 'version_check': 'True', 'write_json': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_format': 'default', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_colors': 'True', 'empty': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'static_parser': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'no_print': 'None', 'indirect_selection': 'eager'}
[0m00:00:26.348838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e35580>]}
[0m00:00:26.382137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ef63f0>]}
[0m00:00:26.382755 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:00:26.452877 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:00:26.516513 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:00:26.516782 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:00:26.520114 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m00:00:26.541383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11318fb00>]}
[0m00:00:26.591150 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:00:26.592505 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:00:26.600180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1138663c0>]}
[0m00:00:26.600447 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:00:26.600633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113516ff0>]}
[0m00:00:26.601806 [info ] [MainThread]: 
[0m00:00:26.602038 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:00:26.602204 [info ] [MainThread]: 
[0m00:00:26.602495 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:00:26.605610 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:00:26.611783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:26.936292 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:00:26.938046 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:26.946189 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:00:26.949871 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:00:26.952903 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:26.954315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075eba10>]}
[0m00:00:26.955722 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:00:26.956046 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:00:26.956317 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:00:26.956521 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:00:26.960369 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:00:26.960790 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:00:26.990986 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:00:27.001733 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:00:27.011007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:00:27.013682 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.016026 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:00:27.016590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:00:27.034442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:00:27.037344 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:00:27.040410 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.055449 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:00:27.057080 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.058978 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075836e0>]}
[0m00:00:27.059336 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.10s]
[0m00:00:27.059644 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:00:27.059860 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:00:27.060154 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:00:27.060426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:00:27.060637 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:00:27.061823 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:00:27.062325 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:00:27.064121 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:00:27.068292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.069971 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:00:27.072657 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.073905 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:00:27.074450 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:00:27.091194 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:00:27.092066 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:00:27.095065 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.098093 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:00:27.099864 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.100709 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d3ee40>]}
[0m00:00:27.101064 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m00:00:27.101361 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:00:27.101570 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:00:27.101785 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:00:27.102041 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:00:27.102250 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:00:27.103510 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:00:27.103990 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:00:27.105723 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:00:27.110103 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.111802 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:00:27.114300 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.115662 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:00:27.116272 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:00:27.144365 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:00:27.145278 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:00:27.148068 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.150590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:00:27.152286 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.153228 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d4c3e0>]}
[0m00:00:27.153623 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m00:00:27.153937 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:00:27.154574 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:00:27.154766 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:00:27.154941 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:00:27.155192 [info ] [MainThread]: 
[0m00:00:27.155374 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.55 seconds (0.55s).
[0m00:00:27.155897 [debug] [MainThread]: Command end result
[0m00:00:27.175013 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:00:27.176274 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:00:27.179520 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:00:27.179722 [info ] [MainThread]: 
[0m00:00:27.179931 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:00:27.180091 [info ] [MainThread]: 
[0m00:00:27.180271 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:00:27.182679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.9698614, "process_in_blocks": "0", "process_kernel_time": 0.210403, "process_mem_max_rss": "194363392", "process_out_blocks": "0", "process_user_time": 1.428072}
[0m00:00:27.182923 [debug] [MainThread]: Command `dbt run` succeeded at 00:00:27.182882 after 0.97 seconds
[0m00:00:27.183130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e246e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117cd8ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d2c8f0>]}
[0m00:00:27.183327 [debug] [MainThread]: Flushing usage events
[0m00:00:27.678131 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:06:57.805388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118dd0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120249e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120243e0>]}


============================== 00:06:57.808114 | d81008ba-9594-4583-8490-c36d8b3c6b9e ==============================
[0m00:06:57.808114 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:06:57.808473 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_experimental_parser': 'False', 'static_parser': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'target_path': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'introspect': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'debug': 'False', 'empty': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m00:06:57.905150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120343b0>]}
[0m00:06:57.936914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fd00b0>]}
[0m00:06:57.937538 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:06:58.008262 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:06:58.071731 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:06:58.072005 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:06:58.075360 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
[0m00:06:58.097757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11238f410>]}
[0m00:06:58.146216 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:06:58.147514 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:06:58.155226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112625c10>]}
[0m00:06:58.155516 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:06:58.155695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112866480>]}
[0m00:06:58.156730 [info ] [MainThread]: 
[0m00:06:58.156945 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:06:58.157159 [info ] [MainThread]: 
[0m00:06:58.157433 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:06:58.160305 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:06:58.166182 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:06:58.506090 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:06:58.508001 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.516131 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:06:58.520076 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:06:58.523215 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.524562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f1b8f0>]}
[0m00:06:58.525905 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:06:58.526218 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:06:58.526475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:06:58.526676 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:06:58.530516 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:06:58.531050 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:06:58.560450 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:06:58.568513 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:06:58.577426 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:06:58.582598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.584838 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:06:58.585355 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:06:58.610326 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:06:58.613522 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:06:58.616330 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.630217 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:06:58.631987 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.633830 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dc33e0>]}
[0m00:06:58.634193 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.11s]
[0m00:06:58.634501 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:06:58.634718 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:06:58.635019 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:06:58.635295 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:06:58.635507 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:06:58.636738 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:06:58.637186 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:06:58.639027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:06:58.643962 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.645814 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:06:58.648891 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.650246 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:06:58.650789 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:06:58.666913 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:06:58.667757 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:06:58.670610 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.673562 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:06:58.675142 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.675989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122040050>]}
[0m00:06:58.676339 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m00:06:58.676639 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:06:58.676848 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:06:58.677076 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:06:58.677357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:06:58.677613 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:06:58.678878 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:06:58.679348 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:06:58.681149 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:06:58.685974 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.687756 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:06:58.690235 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.691548 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:06:58.692080 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:06:58.720687 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:06:58.721565 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:06:58.724223 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.726395 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:06:58.728225 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.729162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12200bdd0>]}
[0m00:06:58.729528 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m00:06:58.729839 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:06:58.730560 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:06:58.730734 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:06:58.730931 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:06:58.731200 [info ] [MainThread]: 
[0m00:06:58.731384 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m00:06:58.731833 [debug] [MainThread]: Command end result
[0m00:06:58.750435 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:06:58.751759 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:06:58.755491 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:06:58.755717 [info ] [MainThread]: 
[0m00:06:58.755921 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:06:58.756081 [info ] [MainThread]: 
[0m00:06:58.756257 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:06:58.758666 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.99306893, "process_in_blocks": "0", "process_kernel_time": 0.216167, "process_mem_max_rss": "193888256", "process_out_blocks": "0", "process_user_time": 1.431918}
[0m00:06:58.758925 [debug] [MainThread]: Command `dbt run` succeeded at 00:06:58.758881 after 0.99 seconds
[0m00:06:58.759119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d3560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1215a06e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120246b0>]}
[0m00:06:58.759308 [debug] [MainThread]: Flushing usage events
[0m00:06:59.227938 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:13:41.541570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107222d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074248c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074242c0>]}


============================== 00:13:41.544427 | 21e008d2-f266-4936-b5c4-eab818fcd6c4 ==============================
[0m00:13:41.544427 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:13:41.544785 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'static_parser': 'True', 'version_check': 'True', 'printer_width': '80', 'introspect': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'no_print': 'None', 'warn_error': 'None', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'target_path': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'fail_fast': 'False', 'write_json': 'True', 'empty': 'False'}
[0m00:13:41.638697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c71880>]}
[0m00:13:41.668910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074374a0>]}
[0m00:13:41.669433 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:13:41.738919 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:13:41.801613 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:13:41.801845 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:13:41.805101 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m00:13:41.826909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077639e0>]}
[0m00:13:41.876127 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:13:41.877438 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:13:41.885169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107927110>]}
[0m00:13:41.885446 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:13:41.885635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077606e0>]}
[0m00:13:41.886667 [info ] [MainThread]: 
[0m00:13:41.886871 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:13:41.887028 [info ] [MainThread]: 
[0m00:13:41.887303 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:13:41.890484 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:13:41.896887 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:13:42.228802 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:13:42.230720 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.238779 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:13:42.242423 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:13:42.245497 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.246717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2202f0>]}
[0m00:13:42.247919 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:13:42.248193 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:13:42.248434 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:13:42.248629 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:13:42.252404 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:13:42.252937 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:13:42.280965 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:13:42.288987 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:13:42.298436 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:13:42.301210 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.303481 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:13:42.304027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:13:42.321684 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:13:42.324498 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:13:42.327143 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.341417 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:13:42.343068 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.344909 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10749aa80>]}
[0m00:13:42.345267 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.10s]
[0m00:13:42.345564 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:13:42.345784 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:13:42.346014 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:13:42.346278 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:13:42.346504 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:13:42.347701 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:13:42.348169 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:13:42.349905 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:13:42.354871 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.356505 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:13:42.359042 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.360304 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:13:42.360913 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:13:42.376925 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:13:42.377802 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:13:42.380292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.383049 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:13:42.384647 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.385619 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da3e7b0>]}
[0m00:13:42.386003 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m00:13:42.386309 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:13:42.386514 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:13:42.386745 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:13:42.387117 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:13:42.387356 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:13:42.388658 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:13:42.389125 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:13:42.390984 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:13:42.395700 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.397431 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:13:42.399928 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.401132 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:13:42.401662 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:13:42.430793 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:13:42.431692 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:13:42.434668 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.437243 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:13:42.439126 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.440185 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da21820>]}
[0m00:13:42.440598 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m00:13:42.440936 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:13:42.441695 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:13:42.441882 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:13:42.442056 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:13:42.442318 [info ] [MainThread]: 
[0m00:13:42.442499 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m00:13:42.442949 [debug] [MainThread]: Command end result
[0m00:13:42.462321 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:13:42.463432 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:13:42.466957 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:13:42.467203 [info ] [MainThread]: 
[0m00:13:42.467410 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:13:42.467608 [info ] [MainThread]: 
[0m00:13:42.467815 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:13:42.470487 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.96795833, "process_in_blocks": "0", "process_kernel_time": 0.213082, "process_mem_max_rss": "192479232", "process_out_blocks": "0", "process_user_time": 1.419035}
[0m00:13:42.470834 [debug] [MainThread]: Command `dbt run` succeeded at 00:13:42.470786 after 0.97 seconds
[0m00:13:42.471067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107222cf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106514950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2663c0>]}
[0m00:13:42.471318 [debug] [MainThread]: Flushing usage events
[0m00:13:42.960012 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:17:49.110854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10701d820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105249b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105243b0>]}


============================== 00:17:49.113294 | e4345090-deaa-4772-b687-9e7df1366107 ==============================
[0m00:17:49.113294 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:17:49.113621 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'fail_fast': 'False', 'target_path': 'None', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'introspect': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'write_json': 'True', 'debug': 'False', 'version_check': 'True', 'empty': 'False', 'log_format': 'default', 'use_colors': 'True', 'static_parser': 'True', 'quiet': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None'}
[0m00:17:49.203540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107d8d40>]}
[0m00:17:49.236913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107baf500>]}
[0m00:17:49.237666 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:17:49.313086 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:17:49.379198 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:17:49.379486 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:17:49.382945 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m00:17:49.405290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ac4200>]}
[0m00:17:49.454471 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:17:49.455753 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:17:49.465047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b25640>]}
[0m00:17:49.465391 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:17:49.465601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d66600>]}
[0m00:17:49.466767 [info ] [MainThread]: 
[0m00:17:49.467011 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:17:49.467172 [info ] [MainThread]: 
[0m00:17:49.467450 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:17:49.470479 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:17:49.476990 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:17:49.811407 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:17:49.813323 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.821270 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:17:49.825062 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:17:49.828698 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.829978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112018b60>]}
[0m00:17:49.831323 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:17:49.831609 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:17:49.831852 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:17:49.832047 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:17:49.835790 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:17:49.836325 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:17:49.869245 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:17:49.884642 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:17:49.898189 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:17:49.904199 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:17:49.907024 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:17:49.907668 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:17:49.926242 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:17:49.929268 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:17:49.932278 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.946189 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:17:49.948222 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.950156 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1038bf980>]}
[0m00:17:49.950537 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.12s]
[0m00:17:49.950852 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:17:49.951077 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:17:49.951308 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:17:49.951628 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:17:49.951840 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:17:49.953062 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:17:49.953527 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:17:49.955416 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:17:49.960350 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.962098 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:17:49.965011 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.966335 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:17:49.966873 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:17:49.983175 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:17:49.984008 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:17:49.986960 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.990189 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:17:49.991865 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.992796 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117452780>]}
[0m00:17:49.993175 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m00:17:49.993487 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:17:49.993697 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:17:49.993923 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:17:49.994201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:17:49.994439 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:17:49.995684 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:17:49.996191 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:17:49.998027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:17:50.002595 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:50.004388 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:17:50.007163 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:50.008422 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:17:50.009168 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:17:50.036854 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:17:50.037710 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:17:50.040288 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:50.042429 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:17:50.043834 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:50.044826 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117421190>]}
[0m00:17:50.045191 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m00:17:50.045495 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:17:50.046213 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:17:50.046440 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:17:50.046623 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:17:50.046888 [info ] [MainThread]: 
[0m00:17:50.047071 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m00:17:50.047542 [debug] [MainThread]: Command end result
[0m00:17:50.066153 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:17:50.067511 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:17:50.070870 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:17:50.071098 [info ] [MainThread]: 
[0m00:17:50.071304 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:17:50.071459 [info ] [MainThread]: 
[0m00:17:50.071628 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:17:50.074045 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.9989956, "process_in_blocks": "0", "process_kernel_time": 0.213801, "process_mem_max_rss": "194560000", "process_out_blocks": "0", "process_user_time": 1.419204}
[0m00:17:50.074297 [debug] [MainThread]: Command `dbt run` succeeded at 00:17:50.074255 after 1.00 seconds
[0m00:17:50.074495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105246b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117440b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117427380>]}
[0m00:17:50.074682 [debug] [MainThread]: Flushing usage events
[0m00:17:50.521460 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:19:43.441525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dbdb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c249b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c243b0>]}


============================== 00:19:43.443992 | 7d096020-5dbb-4f25-a301-b70ece42a6ee ==============================
[0m00:19:43.443992 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:19:43.444337 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'log_cache_events': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'empty': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'quiet': 'False', 'no_print': 'None', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'printer_width': '80', 'partial_parse': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'version_check': 'True', 'debug': 'False'}
[0m00:19:43.538078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dbd700>]}
[0m00:19:43.569206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ad34a0>]}
[0m00:19:43.569750 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:19:43.642331 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:19:43.708545 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:19:43.708841 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:19:43.712681 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m00:19:43.735159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e8e450>]}
[0m00:19:43.783838 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:19:43.785126 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:19:43.792823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111327260>]}
[0m00:19:43.793105 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:19:43.793290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11136d1f0>]}
[0m00:19:43.794360 [info ] [MainThread]: 
[0m00:19:43.794596 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:19:43.794752 [info ] [MainThread]: 
[0m00:19:43.795016 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:19:43.797972 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:19:43.804184 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:19:44.165785 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:19:44.167736 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.176082 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:19:44.179855 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:19:44.183556 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.184867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111305190>]}
[0m00:19:44.186199 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:19:44.186507 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:19:44.186765 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:19:44.186964 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:19:44.190803 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:19:44.191297 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:19:44.220851 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:19:44.229921 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:19:44.239523 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:19:44.243742 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.246208 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:19:44.246823 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:19:44.278258 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:19:44.281098 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:19:44.284323 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.299440 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:19:44.301720 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.303831 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052bf8c0>]}
[0m00:19:44.304257 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.12s]
[0m00:19:44.304562 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:19:44.304787 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:19:44.305008 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:19:44.305242 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:19:44.305435 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:19:44.306660 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:19:44.307214 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:19:44.309303 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:19:44.314449 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.316081 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:19:44.319093 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.320596 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:19:44.321183 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:19:44.346041 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:19:44.346943 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:19:44.349979 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.353063 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:19:44.354911 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.355784 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1207400b0>]}
[0m00:19:44.356125 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.05s]
[0m00:19:44.356424 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:19:44.356630 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:19:44.356848 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:19:44.357064 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:19:44.357245 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:19:44.358438 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:19:44.358934 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:19:44.361002 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:19:44.366150 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.367954 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:19:44.370681 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.371765 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:19:44.372250 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:19:44.409349 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m00:19:44.410177 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:19:44.412734 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.414852 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:19:44.416381 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.417210 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120711160>]}
[0m00:19:44.417548 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.06s]
[0m00:19:44.417840 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:19:44.418472 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:19:44.418663 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:19:44.418836 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:19:44.419089 [info ] [MainThread]: 
[0m00:19:44.419268 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.62 seconds (0.62s).
[0m00:19:44.419730 [debug] [MainThread]: Command end result
[0m00:19:44.438828 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:19:44.440179 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:19:44.443371 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:19:44.443570 [info ] [MainThread]: 
[0m00:19:44.443781 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:19:44.443941 [info ] [MainThread]: 
[0m00:19:44.444123 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:19:44.446716 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0411824, "process_in_blocks": "0", "process_kernel_time": 0.212729, "process_mem_max_rss": "192610304", "process_out_blocks": "0", "process_user_time": 1.402905}
[0m00:19:44.447019 [debug] [MainThread]: Command `dbt run` succeeded at 00:19:44.446973 after 1.04 seconds
[0m00:19:44.447241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e60320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117f6bf80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1201832c0>]}
[0m00:19:44.447449 [debug] [MainThread]: Flushing usage events
[0m00:19:44.911416 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:49:50.171993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d32690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077249e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077242f0>]}


============================== 12:49:50.174468 | d702f897-a161-463d-bfc8-d22593ac7c49 ==============================
[0m12:49:50.174468 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:49:50.174808 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'target_path': 'None', 'log_cache_events': 'False', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'debug': 'False', 'use_colors': 'True', 'printer_width': '80', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_format': 'default', 'empty': 'False', 'use_experimental_parser': 'False', 'static_parser': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'write_json': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'indirect_selection': 'eager'}
[0m12:49:50.273042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107727290>]}
[0m12:49:50.303183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107862db0>]}
[0m12:49:50.303655 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:49:50.373372 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:49:50.437600 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:49:50.437839 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:49:50.441137 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m12:49:50.462719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798df70>]}
[0m12:49:50.510722 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:49:50.511930 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:49:50.519683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d26fc0>]}
[0m12:49:50.519942 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m12:49:50.520122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b7d430>]}
[0m12:49:50.521147 [info ] [MainThread]: 
[0m12:49:50.521345 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:49:50.521497 [info ] [MainThread]: 
[0m12:49:50.521742 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:49:50.524562 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:49:50.530229 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:49:50.881632 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:49:50.883978 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:50.893242 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m12:49:50.897050 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m12:49:50.908151 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:49:50.909665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115e487a0>]}
[0m12:49:50.911327 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m12:49:50.911675 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m12:49:50.911965 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m12:49:50.912199 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m12:49:50.916163 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m12:49:50.916618 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m12:49:50.947068 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m12:49:50.956645 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:49:50.966205 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:49:50.970244 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:50.972884 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m12:49:50.973438 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m12:49:51.027568 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:49:51.030407 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m12:49:51.033053 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.046767 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m12:49:51.048411 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.050315 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032c7860>]}
[0m12:49:51.050685 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.14s]
[0m12:49:51.051007 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m12:49:51.051231 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m12:49:51.051535 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m12:49:51.051817 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m12:49:51.052039 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m12:49:51.053288 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m12:49:51.053752 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m12:49:51.055633 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m12:49:51.060901 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.062680 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:49:51.065282 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.066647 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m12:49:51.067213 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m12:49:51.101035 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:49:51.101855 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m12:49:51.105031 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.107881 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m12:49:51.109425 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.110224 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116c2a7e0>]}
[0m12:49:51.110556 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.06s]
[0m12:49:51.110842 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m12:49:51.111040 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m12:49:51.111279 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m12:49:51.111491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m12:49:51.111674 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m12:49:51.112858 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m12:49:51.113408 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m12:49:51.115327 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m12:49:51.120521 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.122176 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:49:51.125011 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.126230 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m12:49:51.126726 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m12:49:51.219538 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.09 seconds
[0m12:49:51.220345 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m12:49:51.222866 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.224879 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m12:49:51.226357 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:49:51.227157 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd702f897-a161-463d-bfc8-d22593ac7c49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116c0d550>]}
[0m12:49:51.227492 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.12s]
[0m12:49:51.227775 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m12:49:51.228453 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:49:51.228633 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m12:49:51.228801 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m12:49:51.229037 [info ] [MainThread]: 
[0m12:49:51.229206 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.71 seconds (0.71s).
[0m12:49:51.229646 [debug] [MainThread]: Command end result
[0m12:49:51.249138 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:49:51.250409 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:49:51.254394 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m12:49:51.254643 [info ] [MainThread]: 
[0m12:49:51.254861 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:49:51.255035 [info ] [MainThread]: 
[0m12:49:51.255228 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m12:49:51.258214 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1230044, "process_in_blocks": "0", "process_kernel_time": 0.213852, "process_mem_max_rss": "192151552", "process_out_blocks": "0", "process_user_time": 1.396095}
[0m12:49:51.258549 [debug] [MainThread]: Command `dbt run` succeeded at 12:49:51.258490 after 1.12 seconds
[0m12:49:51.258803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107724680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078dade0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d1b1a0>]}
[0m12:49:51.259048 [debug] [MainThread]: Flushing usage events
[0m12:49:51.752903 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:47:57.028272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d22960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea1160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ecd490>]}


============================== 14:47:57.031091 | fbf9dc79-683f-448b-9286-bc5f87a266af ==============================
[0m14:47:57.031091 [info ] [MainThread]: Running with dbt=1.10.13
[0m14:47:57.031438 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'no_print': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'quiet': 'False', 'introspect': 'True', 'version_check': 'True', 'empty': 'None', 'debug': 'False', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'static_parser': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'target_path': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_experimental_parser': 'False', 'log_format': 'default'}
[0m14:47:57.102363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fbf9dc79-683f-448b-9286-bc5f87a266af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105feca40>]}
[0m14:47:57.127167 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-3sgw7_c5'
[0m14:47:57.127471 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:47:57.335403 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:47:57.336864 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:47:57.426114 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:47:57.428944 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:47:57.920310 [info ] [MainThread]: Installed from version 1.3.1
[0m14:47:57.920780 [info ] [MainThread]: Up to date!
[0m14:47:57.921075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'fbf9dc79-683f-448b-9286-bc5f87a266af', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea0fb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068bb860>]}
[0m14:47:57.923365 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.9321098, "process_in_blocks": "0", "process_kernel_time": 0.168153, "process_mem_max_rss": "116801536", "process_out_blocks": "0", "process_user_time": 0.829205}
[0m14:47:57.923786 [debug] [MainThread]: Command `dbt deps` succeeded at 14:47:57.923702 after 0.93 seconds
[0m14:47:57.924086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105672ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068eddc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068efc50>]}
[0m14:47:57.924322 [debug] [MainThread]: Flushing usage events
[0m14:47:58.450133 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:48:09.237563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acdcad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c160f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c16000>]}


============================== 14:48:09.240130 | 8c754121-8d13-48b9-85c7-217d3a2f9bea ==============================
[0m14:48:09.240130 [info ] [MainThread]: Running with dbt=1.10.13
[0m14:48:09.240459 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run-operation provision_fundamentals_raw', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'warn_error': 'None', 'version_check': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'partial_parse': 'True', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'debug': 'False', 'write_json': 'True', 'quiet': 'False', 'use_colors': 'True', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'log_format': 'default'}
[0m14:48:09.331693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8c754121-8d13-48b9-85c7-217d3a2f9bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bac380>]}
[0m14:48:09.361514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8c754121-8d13-48b9-85c7-217d3a2f9bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acdc200>]}
[0m14:48:09.362012 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m14:48:09.429961 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m14:48:09.497745 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 3 files added, 0 files changed.
[0m14:48:09.498160 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/key_ratios.sql
[0m14:48:09.498344 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/quarterly_fundamentals.sql
[0m14:48:09.498533 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://macros/provision_fundamentals.sql
[0m14:48:09.629547 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m14:48:09.637006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8c754121-8d13-48b9-85c7-217d3a2f9bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bff7170>]}
[0m14:48:09.686506 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m14:48:09.687799 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m14:48:09.694663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8c754121-8d13-48b9-85c7-217d3a2f9bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf950d0>]}
[0m14:48:09.694949 [info ] [MainThread]: Found 6 models, 14 data tests, 1 source, 604 macros
[0m14:48:09.695131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8c754121-8d13-48b9-85c7-217d3a2f9bea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9c43e0>]}
[0m14:48:09.695464 [debug] [MainThread]: Acquiring new clickhouse connection 'macro_provision_fundamentals_raw'
[0m14:48:09.700725 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:48:10.047106 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE DATABASE IF NOT EXISTS fundamentals
  ...
[0m14:48:10.050061 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:48:10.057562 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    
    CREATE TABLE IF NOT EXISTS fundamentals.income_statement
    (
      ticker      String,
      fiscal_date Date,
      period      LowCardinality(String),   -- 'Q' or 'A'
      metric      LowCardinality(String),
      value       Float64,
      currency    LowCardinality(String),
      source      LowCardinality(String) DEFAULT 'yfinance',
      loaded_at   DateTime DEFAULT now(),
      _batch_id   UUID DEFAULT generateUUIDv4()
    )
    ENGINE = ReplacingMergeTree(_batch_id)
    PARTITION BY toYYYYMM(fiscal_date)
    ORDER BY (ticker, fiscal_date, metric)
  
  ...
[0m14:48:10.063310 [debug] [MainThread]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    
    CREATE TABLE IF NOT EXISTS fundamentals.income_statement
    (
      ticker      String,
      fiscal_date Date,
      period      LowCardinality(String),   -- 'Q' or 'A'
      metric      LowCardinality(String),
      value       Float64,
      currency    LowCardinality(String),
      source      LowCardinality(String) DEFAULT 'yfinance',
      loaded_at   DateTime DEFAULT now(),
      _batch_id   UUID DEFAULT generateUUIDv4()
    )
    ENGINE = ReplacingMergeTree(_batch_id)
    PARTITION BY toYYYYMM(fiscal_date)
    ORDER BY (ticker, fiscal_date, metric)
  
  
[0m14:48:10.063589 [debug] [MainThread]: dbt_clickhouse adapter: Error running SQL: macro provision_fundamentals_raw
[0m14:48:10.063839 [error] [MainThread]: Encountered an error while running operation: Database Error
  Received ClickHouse exception, code: 169, server response: Code: 169. DB::Exception: The column _batch_id cannot be used as a version column for storage ReplacingMergeTree because it is of type UUID (must be of an integer type or of type Date/DateTime/DateTime64). (BAD_TYPE_OF_FIELD) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m14:48:10.067479 [debug] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/adapters/clickhouse/httpclient.py", line 23, in command
    return self._client.command(sql, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 412, in command
    response = self._raw_request(payload, params, headers, method, fields=fields, server_wait=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 547, in _raw_request
    self._error_handler(response)
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 468, in _error_handler
    raise OperationalError(err_str) if retried else DatabaseError(err_str) from None
clickhouse_connect.driver.exceptions.DatabaseError: Received ClickHouse exception, code: 169, server response: Code: 169. DB::Exception: The column _batch_id cannot be used as a version column for storage ReplacingMergeTree because it is of type UUID (must be of an integer type or of type Date/DateTime/DateTime64). (BAD_TYPE_OF_FIELD) (version 25.9.2.1 (official build)) (for url http://localhost:8124)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/run_operation.py", line 64, in run
    self._run_unsafe(package_name, macro_name)
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/run_operation.py", line 45, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 1282, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 427, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 23, in macro
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 33, in macro
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/clients/jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt_common/clients/jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/jinja2/runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt_common/record.py", line 512, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/adapters/base/impl.py", line 438, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/adapters/clickhouse/connections.py", line 95, in execute
    query_result = client.command(sql)
                   ^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/adapters/clickhouse/httpclient.py", line 26, in command
    raise DbtDatabaseError(err_msg) from ex
dbt_common.exceptions.base.DbtDatabaseError: Database Error
  Received ClickHouse exception, code: 169, server response: Code: 169. DB::Exception: The column _batch_id cannot be used as a version column for storage ReplacingMergeTree because it is of type UUID (must be of an integer type or of type Date/DateTime/DateTime64). (BAD_TYPE_OF_FIELD) (version 25.9.2.1 (official build)) (for url http://localhost:8124)

[0m14:48:10.071619 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m14:48:10.074168 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": false, "command_wall_clock_time": 0.8719082, "process_in_blocks": "0", "process_kernel_time": 0.194965, "process_mem_max_rss": "193396736", "process_out_blocks": "0", "process_user_time": 1.3726}
[0m14:48:10.074476 [debug] [MainThread]: Command `dbt run-operation` failed at 14:48:10.074429 after 0.87 seconds
[0m14:48:10.074662 [debug] [MainThread]: Connection 'macro_provision_fundamentals_raw' was left open.
[0m14:48:10.074816 [debug] [MainThread]: On macro_provision_fundamentals_raw: Close
[0m14:48:10.075033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c160f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf97f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ad802f0>]}
[0m14:48:10.075226 [debug] [MainThread]: Flushing usage events
[0m14:48:10.801597 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:49:49.076019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108445d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a1a1e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a1a0f0>]}


============================== 14:49:49.078973 | 07f73c11-8c5f-473b-80ec-2ad4d9fb4f03 ==============================
[0m14:49:49.078973 [info ] [MainThread]: Running with dbt=1.10.13
[0m14:49:49.079362 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'fail_fast': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'write_json': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'use_colors': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'version_check': 'True', 'no_print': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run-operation provision_fundamentals_raw', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'debug': 'False', 'empty': 'None'}
[0m14:49:49.171836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '07f73c11-8c5f-473b-80ec-2ad4d9fb4f03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105627860>]}
[0m14:49:49.201666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '07f73c11-8c5f-473b-80ec-2ad4d9fb4f03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109682b40>]}
[0m14:49:49.202162 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m14:49:49.271442 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m14:49:49.337948 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:49:49.338371 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://macros/provision_fundamentals.sql
[0m14:49:49.380635 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m14:49:49.387885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '07f73c11-8c5f-473b-80ec-2ad4d9fb4f03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079e3470>]}
[0m14:49:49.438713 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m14:49:49.440035 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m14:49:49.446250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '07f73c11-8c5f-473b-80ec-2ad4d9fb4f03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b38080>]}
[0m14:49:49.446516 [info ] [MainThread]: Found 6 models, 14 data tests, 1 source, 604 macros
[0m14:49:49.446699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07f73c11-8c5f-473b-80ec-2ad4d9fb4f03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097952b0>]}
[0m14:49:49.447006 [debug] [MainThread]: Acquiring new clickhouse connection 'macro_provision_fundamentals_raw'
[0m14:49:49.453020 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m14:49:49.454502 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 0.41396278, "process_in_blocks": "0", "process_kernel_time": 0.148755, "process_mem_max_rss": "124534784", "process_out_blocks": "0", "process_user_time": 1.023811}
[0m14:49:49.454789 [debug] [MainThread]: Command `dbt run-operation` succeeded at 14:49:49.454741 after 0.41 seconds
[0m14:49:49.454986 [debug] [MainThread]: Connection 'macro_provision_fundamentals_raw' was properly closed.
[0m14:49:49.455170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109258dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109769c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b382c0>]}
[0m14:49:49.455354 [debug] [MainThread]: Flushing usage events
[0m14:49:50.010935 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:51:55.726415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dfd3b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9ebfb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9ebdd0>]}


============================== 14:51:55.728831 | 1e2d9c57-0bd4-4434-be60-cf39b33415a6 ==============================
[0m14:51:55.728831 [info ] [MainThread]: Running with dbt=1.10.13
[0m14:51:55.729165 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run-operation provision_fundamentals_raw', 'introspect': 'True', 'log_format': 'default', 'debug': 'False', 'printer_width': '80', 'empty': 'None', 'cache_selected_only': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'version_check': 'True', 'quiet': 'False', 'target_path': 'None', 'use_colors': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:51:55.820031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e2d9c57-0bd4-4434-be60-cf39b33415a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df60d40>]}
[0m14:51:55.852882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e2d9c57-0bd4-4434-be60-cf39b33415a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1b9a30>]}
[0m14:51:55.853524 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m14:51:55.921651 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m14:51:55.988081 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:51:55.988496 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://macros/provision_fundamentals.sql
[0m14:51:56.031200 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m14:51:56.038826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e2d9c57-0bd4-4434-be60-cf39b33415a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec8f320>]}
[0m14:51:56.087054 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m14:51:56.088321 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m14:51:56.094513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e2d9c57-0bd4-4434-be60-cf39b33415a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f139160>]}
[0m14:51:56.094783 [info ] [MainThread]: Found 6 models, 14 data tests, 1 source, 604 macros
[0m14:51:56.094970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e2d9c57-0bd4-4434-be60-cf39b33415a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec8ee70>]}
[0m14:51:56.095271 [debug] [MainThread]: Acquiring new clickhouse connection 'macro_provision_fundamentals_raw'
[0m14:51:56.099149 [info ] [MainThread]: Running: CREATE DATABASE IF NOT EXISTS fundamentals
[0m14:51:56.103040 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:51:56.434219 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE DATABASE IF NOT EXISTS fundamentals
  ...
[0m14:51:56.436067 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:51:56.443996 [info ] [MainThread]: Running: CREATE TABLE IF NOT EXISTS fundamentals.income_statement (       ticker String,       fiscal_date Date,       period Low...
[0m14:51:56.444419 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE TABLE IF NOT EXISTS fundamentals.income_statement (       ticker String,       fiscal_date Date,       period LowCardinality(String),       metric LowCardinality(String),       value Float64,       currency LowCardinality(String),       source LowCardinality(String) DEFAULT 'yfinance',       loaded_at DateTime64(3) DEFAULT now64(3),       _batch_id UUID DEFAULT generateUUIDv4()     )     ENGINE = ReplacingMergeTree(loaded_at)     PARTITION BY toYYYYMM(fiscal_date)     ORDER BY (ticker, fiscal_date, metric)
  ...
[0m14:51:56.449149 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:51:56.449773 [info ] [MainThread]: Running: CREATE TABLE IF NOT EXISTS fundamentals.balance_sheet (       ticker String,       fiscal_date Date,       period LowCar...
[0m14:51:56.450123 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE TABLE IF NOT EXISTS fundamentals.balance_sheet (       ticker String,       fiscal_date Date,       period LowCardinality(String),       metric LowCardinality(String),       value Float64,       currency LowCardinality(String),       source LowCardinality(String) DEFAULT 'yfinance',       loaded_at DateTime64(3) DEFAULT now64(3),       _batch_id UUID DEFAULT generateUUIDv4()     )     ENGINE = ReplacingMergeTree(loaded_at)     PARTITION BY toYYYYMM(fiscal_date)     ORDER BY (ticker, fiscal_date, metric)
  ...
[0m14:51:56.453607 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:51:56.454168 [info ] [MainThread]: Running: CREATE TABLE IF NOT EXISTS fundamentals.cashflow_statement (       ticker String,       fiscal_date Date,       period L...
[0m14:51:56.454450 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE TABLE IF NOT EXISTS fundamentals.cashflow_statement (       ticker String,       fiscal_date Date,       period LowCardinality(String),       metric LowCardinality(String),       value Float64,       currency LowCardinality(String),       source LowCardinality(String) DEFAULT 'yfinance',       loaded_at DateTime64(3) DEFAULT now64(3),       _batch_id UUID DEFAULT generateUUIDv4()     )     ENGINE = ReplacingMergeTree(loaded_at)     PARTITION BY toYYYYMM(fiscal_date)     ORDER BY (ticker, fiscal_date, metric)
  ...
[0m14:51:56.457599 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:51:56.458086 [info ] [MainThread]: Provisioned fundamentals DB + tables ✅
[0m14:51:56.461904 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m14:51:56.464670 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 0.7730261, "process_in_blocks": "0", "process_kernel_time": 0.195483, "process_mem_max_rss": "192249856", "process_out_blocks": "0", "process_user_time": 1.309682}
[0m14:51:56.464981 [debug] [MainThread]: Command `dbt run-operation` succeeded at 14:51:56.464932 after 0.77 seconds
[0m14:51:56.465164 [debug] [MainThread]: Connection 'macro_provision_fundamentals_raw' was left open.
[0m14:51:56.465322 [debug] [MainThread]: On macro_provision_fundamentals_raw: Close
[0m14:51:56.465569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f138cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a786690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fefb860>]}
[0m14:51:56.465772 [debug] [MainThread]: Flushing usage events
[0m14:51:56.997170 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:53:39.532082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10506fe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046b71d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046b7260>]}


============================== 14:53:39.534759 | b22671b4-1ba8-4390-aaf4-7dceba81327d ==============================
[0m14:53:39.534759 [info ] [MainThread]: Running with dbt=1.10.13
[0m14:53:39.535105 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'invocation_command': 'dbt deps', 'partial_parse': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'introspect': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'cache_selected_only': 'False', 'use_colors': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_format': 'default', 'use_experimental_parser': 'False', 'static_parser': 'True', 'version_check': 'True', 'empty': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False'}
[0m14:53:39.601682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b22671b4-1ba8-4390-aaf4-7dceba81327d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058213a0>]}
[0m14:53:39.620947 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-jn_stevn'
[0m14:53:39.621220 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:53:39.771730 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:53:39.772498 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:53:39.943148 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:53:39.948865 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:53:40.283890 [info ] [MainThread]: Installed from version 1.3.1
[0m14:53:40.284211 [info ] [MainThread]: Up to date!
[0m14:53:40.284457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b22671b4-1ba8-4390-aaf4-7dceba81327d', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058ce570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059de180>]}
[0m14:53:40.286551 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.792111, "process_in_blocks": "0", "process_kernel_time": 0.167343, "process_mem_max_rss": "118947840", "process_out_blocks": "0", "process_user_time": 0.842567}
[0m14:53:40.286924 [debug] [MainThread]: Command `dbt deps` succeeded at 14:53:40.286856 after 0.79 seconds
[0m14:53:40.287289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105820b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b5130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103dbe420>]}
[0m14:53:40.287605 [debug] [MainThread]: Flushing usage events
[0m14:53:40.825082 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:53:41.791727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aaeb70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a8a660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a8be00>]}


============================== 14:53:41.794282 | 847c46c0-2b51-44a2-843a-e613fabb251a ==============================
[0m14:53:41.794282 [info ] [MainThread]: Running with dbt=1.10.13
[0m14:53:41.794626 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'target_path': 'None', 'warn_error': 'None', 'static_parser': 'True', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'debug': 'False', 'invocation_command': 'dbt run-operation provision_fundamentals_raw', 'version_check': 'True', 'log_format': 'default', 'printer_width': '80', 'write_json': 'True', 'indirect_selection': 'eager', 'empty': 'None', 'cache_selected_only': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_experimental_parser': 'False', 'use_colors': 'True', 'introspect': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project'}
[0m14:53:41.884767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '847c46c0-2b51-44a2-843a-e613fabb251a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120c34200>]}
[0m14:53:41.915280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '847c46c0-2b51-44a2-843a-e613fabb251a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120beda00>]}
[0m14:53:41.915757 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m14:53:41.984826 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m14:53:42.045783 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:53:42.046039 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:53:42.049277 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m14:53:42.070454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '847c46c0-2b51-44a2-843a-e613fabb251a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1218c8620>]}
[0m14:53:42.120222 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m14:53:42.121497 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m14:53:42.127799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '847c46c0-2b51-44a2-843a-e613fabb251a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121b2ede0>]}
[0m14:53:42.128081 [info ] [MainThread]: Found 6 models, 14 data tests, 1 source, 604 macros
[0m14:53:42.128271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '847c46c0-2b51-44a2-843a-e613fabb251a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120f4f440>]}
[0m14:53:42.128572 [debug] [MainThread]: Acquiring new clickhouse connection 'macro_provision_fundamentals_raw'
[0m14:53:42.132152 [info ] [MainThread]: Running: CREATE DATABASE IF NOT EXISTS fundamentals
[0m14:53:42.135711 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:53:42.470774 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE DATABASE IF NOT EXISTS fundamentals
  ...
[0m14:53:42.472217 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:53:42.479920 [info ] [MainThread]: Running: CREATE TABLE IF NOT EXISTS fundamentals.income_statement (       ticker String,       fiscal_date Date,       period Low...
[0m14:53:42.480361 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE TABLE IF NOT EXISTS fundamentals.income_statement (       ticker String,       fiscal_date Date,       period LowCardinality(String),       metric LowCardinality(String),       value Float64,       currency LowCardinality(String),       source LowCardinality(String) DEFAULT 'yfinance',       loaded_at DateTime64(3) DEFAULT now64(3),       _batch_id UUID DEFAULT generateUUIDv4()     )     ENGINE = ReplacingMergeTree(loaded_at)     PARTITION BY toYYYYMM(fiscal_date)     ORDER BY (ticker, fiscal_date, metric)
  ...
[0m14:53:42.482385 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:53:42.483021 [info ] [MainThread]: Running: CREATE TABLE IF NOT EXISTS fundamentals.balance_sheet (       ticker String,       fiscal_date Date,       period LowCar...
[0m14:53:42.483351 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE TABLE IF NOT EXISTS fundamentals.balance_sheet (       ticker String,       fiscal_date Date,       period LowCardinality(String),       metric LowCardinality(String),       value Float64,       currency LowCardinality(String),       source LowCardinality(String) DEFAULT 'yfinance',       loaded_at DateTime64(3) DEFAULT now64(3),       _batch_id UUID DEFAULT generateUUIDv4()     )     ENGINE = ReplacingMergeTree(loaded_at)     PARTITION BY toYYYYMM(fiscal_date)     ORDER BY (ticker, fiscal_date, metric)
  ...
[0m14:53:42.485239 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:53:42.485866 [info ] [MainThread]: Running: CREATE TABLE IF NOT EXISTS fundamentals.cashflow_statement (       ticker String,       fiscal_date Date,       period L...
[0m14:53:42.486195 [debug] [MainThread]: dbt_clickhouse adapter: On macro_provision_fundamentals_raw: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "macro_provision_fundamentals_raw"} */

    CREATE TABLE IF NOT EXISTS fundamentals.cashflow_statement (       ticker String,       fiscal_date Date,       period LowCardinality(String),       metric LowCardinality(String),       value Float64,       currency LowCardinality(String),       source LowCardinality(String) DEFAULT 'yfinance',       loaded_at DateTime64(3) DEFAULT now64(3),       _batch_id UUID DEFAULT generateUUIDv4()     )     ENGINE = ReplacingMergeTree(loaded_at)     PARTITION BY toYYYYMM(fiscal_date)     ORDER BY (ticker, fiscal_date, metric)
  ...
[0m14:53:42.488035 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:53:42.488641 [info ] [MainThread]: Provisioned fundamentals DB + tables ✅
[0m14:53:42.493568 [debug] [MainThread]: Wrote artifact RunResultsArtifact to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m14:53:42.496347 [debug] [MainThread]: Resource report: {"command_name": "run-operation", "command_success": true, "command_wall_clock_time": 0.7421057, "process_in_blocks": "0", "process_kernel_time": 0.193508, "process_mem_max_rss": "189743104", "process_out_blocks": "0", "process_user_time": 1.287435}
[0m14:53:42.496687 [debug] [MainThread]: Command `dbt run-operation` succeeded at 14:53:42.496632 after 0.74 seconds
[0m14:53:42.496892 [debug] [MainThread]: Connection 'macro_provision_fundamentals_raw' was left open.
[0m14:53:42.497095 [debug] [MainThread]: On macro_provision_fundamentals_raw: Close
[0m14:53:42.497335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121b2ee70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1305a4dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1305a4d70>]}
[0m14:53:42.497545 [debug] [MainThread]: Flushing usage events
[0m14:53:43.092225 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:40:07.410755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103e20470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d1dd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d1dd60>]}


============================== 15:40:07.413382 | 84cb5c6b-5c54-42bb-866c-b208391e18a1 ==============================
[0m15:40:07.413382 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:40:07.413709 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_long fundamentals.quarterly_fundamentals_wide', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'printer_width': '80', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'quiet': 'False', 'introspect': 'True', 'target_path': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'static_parser': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'no_print': 'None', 'empty': 'False', 'version_check': 'True', 'fail_fast': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True'}
[0m15:40:07.417019 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'CLICKHOUSE_USER'
[0m15:40:07.418586 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.045496624, "process_in_blocks": "0", "process_kernel_time": 0.100363, "process_mem_max_rss": "107642880", "process_out_blocks": "0", "process_user_time": 0.703178}
[0m15:40:07.418852 [debug] [MainThread]: Command `dbt run` failed at 15:40:07.418804 after 0.05 seconds
[0m15:40:07.419032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056dac60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054c8a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059a4920>]}
[0m15:40:07.419209 [debug] [MainThread]: Flushing usage events
[0m15:40:08.052206 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:41:39.223462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104901eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d2ddc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d2dd90>]}


============================== 15:41:39.226003 | 8fbe2453-7996-47af-bb94-01fbd9755b4a ==============================
[0m15:41:39.226003 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:41:39.226360 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'introspect': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'version_check': 'True', 'no_print': 'None', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_long fundamentals.quarterly_fundamentals_wide', 'write_json': 'True', 'warn_error': 'None', 'empty': 'False', 'static_parser': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None'}
[0m15:41:39.229483 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'CLICKHOUSE_USER'
[0m15:41:39.230917 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.042804625, "process_in_blocks": "0", "process_kernel_time": 0.104286, "process_mem_max_rss": "109068288", "process_out_blocks": "0", "process_user_time": 0.706933}
[0m15:41:39.231256 [debug] [MainThread]: Command `dbt run` failed at 15:41:39.231201 after 0.04 seconds
[0m15:41:39.231449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b4920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fe11f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10586baa0>]}
[0m15:41:39.231638 [debug] [MainThread]: Flushing usage events
[0m15:41:39.797091 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:41:59.493351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059e0800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b1d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b1cb90>]}


============================== 15:41:59.495865 | ebe60a4a-34e7-448a-8e38-c87716143496 ==============================
[0m15:41:59.495865 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:41:59.496199 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'indirect_selection': 'eager', 'empty': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'cache_selected_only': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'partial_parse': 'True', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'use_colors': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'debug': 'False', 'version_check': 'True', 'target_path': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True'}
[0m15:41:59.588391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102dd0e60>]}
[0m15:41:59.618502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cb2ba0>]}
[0m15:41:59.619013 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:41:59.688372 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:41:59.752567 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 6 files added, 0 files changed.
[0m15:41:59.752930 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://macros/safe_divide.sql
[0m15:41:59.753158 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/schema.yml
[0m15:41:59.753323 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_long.sql
[0m15:41:59.753484 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/key_ratios_long.sql
[0m15:41:59.753638 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:41:59.753785 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/key_ratios_wide.sql
[0m15:41:59.753935 [debug] [MainThread]: Partial parsing: deleted file: qi_dbt_project://models/fundamentals/quarterly_fundamentals.sql
[0m15:41:59.754076 [debug] [MainThread]: Partial parsing: deleted file: qi_dbt_project://models/fundamentals/key_ratios.sql
[0m15:41:59.877660 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'key_ratios' in the 'models' section of file 'models/fundamentals/schema.yml'
[0m15:41:59.923721 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.qi_dbt_project.not_null_key_ratios_ticker.948b0ba38a' (models/fundamentals/schema.yml) depends on a node named 'key_ratios' in package '' which was not found
[0m15:41:59.924065 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.qi_dbt_project.not_null_key_ratios_fiscal_date.cadc0e1ad5' (models/fundamentals/schema.yml) depends on a node named 'key_ratios' in package '' which was not found
[0m15:41:59.957278 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m15:41:59.964459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d79c10>]}
[0m15:42:00.043167 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:42:00.044260 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:42:00.053764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa2570>]}
[0m15:42:00.054037 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:42:00.054220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fe8cb0>]}
[0m15:42:00.055309 [info ] [MainThread]: 
[0m15:42:00.055493 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:42:00.055642 [info ] [MainThread]: 
[0m15:42:00.055897 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:42:00.058669 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:42:00.063632 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:42:00.366298 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:42:00.368119 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.376497 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m15:42:00.380612 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:42:00.383749 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.384722 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m15:42:00.419954 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:42:00.427379 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:42:00.428666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d873500>]}
[0m15:42:00.431623 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m15:42:00.431947 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m15:42:00.432209 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.monthly_prices)
[0m15:42:00.432413 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m15:42:00.436334 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m15:42:00.436870 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m15:42:00.466430 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m15:42:00.471684 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.481177 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m15:42:00.483862 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.486429 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m15:42:00.487028 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m15:42:00.553370 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m15:42:00.556230 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m15:42:00.558956 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.572826 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m15:42:00.575801 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.577850 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102dd0050>]}
[0m15:42:00.578246 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.15s]
[0m15:42:00.578597 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m15:42:00.578853 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m15:42:00.579107 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m15:42:00.579365 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m15:42:00.579653 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m15:42:00.581853 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m15:42:00.582424 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m15:42:00.584369 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m15:42:00.589666 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.591531 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m15:42:00.594014 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.595249 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m15:42:00.595773 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m15:42:00.630118 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:42:00.630936 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m15:42:00.633390 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.635353 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m15:42:00.636885 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.637874 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dfd6f30>]}
[0m15:42:00.638217 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.06s]
[0m15:42:00.638507 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m15:42:00.638717 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m15:42:00.638934 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m15:42:00.639154 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m15:42:00.639333 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m15:42:00.640601 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m15:42:00.641160 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m15:42:00.643227 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m15:42:00.647544 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.649315 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m15:42:00.651679 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.652983 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m15:42:00.653522 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m15:42:00.748263 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.09 seconds
[0m15:42:00.749085 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m15:42:00.751502 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.753394 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m15:42:00.754758 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:42:00.755543 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebe60a4a-34e7-448a-8e38-c87716143496', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e615580>]}
[0m15:42:00.755874 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.12s]
[0m15:42:00.756151 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m15:42:00.756771 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:42:00.756960 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m15:42:00.757118 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m15:42:00.757345 [info ] [MainThread]: 
[0m15:42:00.757513 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.70 seconds (0.70s).
[0m15:42:00.757931 [debug] [MainThread]: Command end result
[0m15:42:00.777194 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:42:00.778464 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:42:00.781948 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:42:00.782236 [info ] [MainThread]: 
[0m15:42:00.782489 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:42:00.782699 [info ] [MainThread]: 
[0m15:42:00.782926 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m15:42:00.785970 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3283825, "process_in_blocks": "0", "process_kernel_time": 0.209229, "process_mem_max_rss": "198819840", "process_out_blocks": "0", "process_user_time": 1.612447}
[0m15:42:00.786284 [debug] [MainThread]: Command `dbt run` succeeded at 15:42:00.786231 after 1.33 seconds
[0m15:42:00.786532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10500fe00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d75b560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10575b800>]}
[0m15:42:00.786771 [debug] [MainThread]: Flushing usage events
[0m15:42:01.293046 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:43:04.504201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a717f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112824710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112824050>]}


============================== 15:43:04.506667 | 343db00f-9335-4863-b4ae-f7802b0c48e9 ==============================
[0m15:43:04.506667 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:43:04.507000 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'printer_width': '80', 'static_parser': 'True', 'fail_fast': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_format': 'default', 'empty': 'False', 'use_colors': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'introspect': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_long fundamentals.quarterly_fundamentals_wide', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m15:43:04.598483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '343db00f-9335-4863-b4ae-f7802b0c48e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067ec650>]}
[0m15:43:04.628421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '343db00f-9335-4863-b4ae-f7802b0c48e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ead580>]}
[0m15:43:04.628928 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:43:04.698243 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:43:04.760026 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:43:04.760258 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:43:04.763645 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m15:43:04.785919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '343db00f-9335-4863-b4ae-f7802b0c48e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128d20f0>]}
[0m15:43:04.835813 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:43:04.837117 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:43:04.845062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '343db00f-9335-4863-b4ae-f7802b0c48e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140668a0>]}
[0m15:43:04.845329 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:43:04.845515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '343db00f-9335-4863-b4ae-f7802b0c48e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11289f230>]}
[0m15:43:04.846491 [info ] [MainThread]: 
[0m15:43:04.846680 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:43:04.846824 [info ] [MainThread]: 
[0m15:43:04.847084 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:43:04.850414 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:43:04.856687 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:43:05.195356 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:43:05.197134 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:43:05.205261 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m15:43:05.209483 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:43:05.212660 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:43:05.213594 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m15:43:05.214777 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:43:05.217831 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:43:05.218915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '343db00f-9335-4863-b4ae-f7802b0c48e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112db57c0>]}
[0m15:43:05.220089 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:43:05.220390 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_long` ....... [RUN]
[0m15:43:05.220647 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.quarterly_fundamentals_long)
[0m15:43:05.220837 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:43:05.224958 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:43:05.225501 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:43:05.233239 [debug] [Thread-1 (]: Creating new relation quarterly_fundamentals_long
[0m15:43:05.240991 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:43:05.241677 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_long` 
  
    
  
  
    
    
  as (
    

-- Unified LONG ledger across the three raw tables, quarterly only, keep source + loaded_at
with inc as (
  select
    'income_statement'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.income_statement
  where period = 'Q'
),
bs as (
  select
    'balance_sheet'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.balance_sheet
  where period = 'Q'
),
cf as (
  select
    'cashflow_statement'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.cashflow_statement
  where period = 'Q'
)

select * from inc
union all
select * from bs
union all
select * from cf
;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:43:05.245005 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_long` 
  
    
  
  
    
    
  as (
    

-- Unified LONG ledger across the three raw tables, quarterly only, keep source + loaded_at
with inc as (
  select
    'income_statement'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.income_statement
  where period = 'Q'
),
bs as (
  select
    'balance_sheet'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.balance_sheet
  where period = 'Q'
),
cf as (
  select
    'cashflow_statement'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.cashflow_statement
  where period = 'Q'
)

select * from inc
union all
select * from bs
union all
select * from cf
;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:43:05.249067 [debug] [Thread-1 (]: Database Error in model quarterly_fundamentals_long (models/fundamentals/quarterly_fundamentals_long.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 1126 (end of query) (line 63, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token sequence, Dot, token, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, GLOBAL, LOCAL, ANY, ALL, ASOF, SEMI, ANTI, ONLY, LEFT, RIGHT, FULL, CROSS, PASTE, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_long.sql
[0m15:43:05.249943 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '343db00f-9335-4863-b4ae-f7802b0c48e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123d25880>]}
[0m15:43:05.250320 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model `fundamentals`.`quarterly_fundamentals_long`  [[31mERROR[0m in 0.03s]
[0m15:43:05.250656 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:43:05.250963 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.quarterly_fundamentals_long' to be skipped because of status 'error'.  Reason: Database Error in model quarterly_fundamentals_long (models/fundamentals/quarterly_fundamentals_long.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 1126 (end of query) (line 63, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token sequence, Dot, token, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, GLOBAL, LOCAL, ANY, ALL, ASOF, SEMI, ANTI, ONLY, LEFT, RIGHT, FULL, CROSS, PASTE, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_long.sql.
[0m15:43:05.251735 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:43:05.251982 [info ] [Thread-1 (]: 2 of 2 SKIP relation fundamentals.quarterly_fundamentals_wide .................. [[33mSKIP[0m]
[0m15:43:05.252246 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:43:05.252799 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:43:05.252966 [debug] [MainThread]: Connection 'model.qi_dbt_project.quarterly_fundamentals_long' was left open.
[0m15:43:05.253122 [debug] [MainThread]: On model.qi_dbt_project.quarterly_fundamentals_long: Close
[0m15:43:05.253377 [info ] [MainThread]: 
[0m15:43:05.253556 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m15:43:05.253925 [debug] [MainThread]: Command end result
[0m15:43:05.273134 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:43:05.274336 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:43:05.277401 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:43:05.277597 [info ] [MainThread]: 
[0m15:43:05.277798 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:43:05.278083 [info ] [MainThread]: 
[0m15:43:05.278365 [error] [MainThread]: [31mFailure in model quarterly_fundamentals_long (models/fundamentals/quarterly_fundamentals_long.sql)[0m
[0m15:43:05.278608 [error] [MainThread]:   Database Error in model quarterly_fundamentals_long (models/fundamentals/quarterly_fundamentals_long.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 1126 (end of query) (line 63, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: token sequence, Dot, token, OpeningRoundBracket, UUID, alias, AS, identifier, FINAL, SAMPLE, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, GLOBAL, LOCAL, ANY, ALL, ASOF, SEMI, ANTI, ONLY, LEFT, RIGHT, FULL, CROSS, PASTE, JOIN, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_long.sql
[0m15:43:05.278788 [info ] [MainThread]: 
[0m15:43:05.278966 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/quarterly_fundamentals_long.sql
[0m15:43:05.279115 [info ] [MainThread]: 
[0m15:43:05.279294 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m15:43:05.281853 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.81249505, "process_in_blocks": "0", "process_kernel_time": 0.21146, "process_mem_max_rss": "192233472", "process_out_blocks": "0", "process_user_time": 1.336693}
[0m15:43:05.282151 [debug] [MainThread]: Command `dbt run` failed at 15:43:05.282106 after 0.81 seconds
[0m15:43:05.282368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079d5f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a3db20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115c1c950>]}
[0m15:43:05.282588 [debug] [MainThread]: Flushing usage events
[0m15:43:05.889848 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:44:39.640039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114b24e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c246e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c240e0>]}


============================== 15:44:39.642554 | 66d8632f-3541-471c-af51-f1766b2dd741 ==============================
[0m15:44:39.642554 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:44:39.642888 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'debug': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'introspect': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'printer_width': '80', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_long fundamentals.quarterly_fundamentals_wide', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'write_json': 'True', 'quiet': 'False', 'version_check': 'True', 'warn_error': 'None', 'no_print': 'None', 'use_experimental_parser': 'False', 'use_colors': 'True'}
[0m15:44:39.734178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '66d8632f-3541-471c-af51-f1766b2dd741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c9b290>]}
[0m15:44:39.763831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '66d8632f-3541-471c-af51-f1766b2dd741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113832000>]}
[0m15:44:39.764292 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:44:39.833174 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:44:39.897197 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:44:39.897640 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_long.sql
[0m15:44:40.091168 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m15:44:40.098837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66d8632f-3541-471c-af51-f1766b2dd741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116077b60>]}
[0m15:44:40.178573 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:44:40.179693 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:44:40.187613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66d8632f-3541-471c-af51-f1766b2dd741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114680170>]}
[0m15:44:40.187883 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:44:40.188067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66d8632f-3541-471c-af51-f1766b2dd741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143667b0>]}
[0m15:44:40.189017 [info ] [MainThread]: 
[0m15:44:40.189198 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:44:40.189342 [info ] [MainThread]: 
[0m15:44:40.189583 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:44:40.192272 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:44:40.197732 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:44:40.501811 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:44:40.503706 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:44:40.512258 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m15:44:40.516083 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:44:40.519081 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:44:40.520056 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m15:44:40.521846 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:44:40.524525 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:44:40.525671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66d8632f-3541-471c-af51-f1766b2dd741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12302b7a0>]}
[0m15:44:40.526917 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:44:40.527200 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_long` ....... [RUN]
[0m15:44:40.527449 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.quarterly_fundamentals_long)
[0m15:44:40.527638 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:44:40.531873 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:44:40.532357 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:44:40.575598 [debug] [Thread-1 (]: Creating new relation quarterly_fundamentals_long
[0m15:44:40.582537 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:44:40.583083 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_long` 
  
    
  
  
    
    
  as (
    -- models/fundamentals/quarterly_fundamentals_long.sql


-- Unified LONG ledger across the three raw tables, quarterly only
with inc as (
  select
    'income_statement' as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency
  from fundamentals.income_statement
  where period = 'Q'
),
bs as (
  select
    'balance_sheet' as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency
  from fundamentals.balance_sheet
  where period = 'Q'
),
cf as (
  select
    'cashflow_statement' as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency
  from fundamentals.cashflow_statement
  where period = 'Q'
)

select * from inc
union all
select * from bs
union all
select * from cf
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:44:40.587598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:44:40.598478 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '66d8632f-3541-471c-af51-f1766b2dd741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc3680>]}
[0m15:44:40.598926 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `fundamentals`.`quarterly_fundamentals_long` .. [[32mOK[0m in 0.07s]
[0m15:44:40.599233 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:44:40.599638 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:44:40.599912 [info ] [Thread-1 (]: 2 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_wide` ....... [RUN]
[0m15:44:40.600169 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_fundamentals_long, now model.qi_dbt_project.quarterly_fundamentals_wide)
[0m15:44:40.600358 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:44:40.602251 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m15:44:40.602826 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:44:40.604345 [debug] [Thread-1 (]: Creating new relation quarterly_fundamentals_wide
[0m15:44:40.604827 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m15:44:40.605359 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

-- Build off the unified long view to keep filters/logic in one place
with f as (
  select *
  from `fundamentals`.`quarterly_fundamentals_long`
  where source = 'yfinance' and period = 'Q'
),

base as (
  select
    ticker,
    fiscal_date,
    -- Prefer the currency value associated with the latest loaded_at in case of multiple loads
    argMax(currency, loaded_at) as currency
  from f
  group by ticker, fiscal_date
),

inc as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalRevenue')    as total_revenue,
    maxIf(value, metric = 'CostOfRevenue')   as cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')     as gross_profit,
    maxIf(value, metric = 'OperatingIncome') as operating_income,
    maxIf(value, metric = 'NetIncome')       as net_income
  from f
  where statement = 'income_statement'
  group by ticker, fiscal_date
),

bs as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                as total_assets,
    maxIf(value, metric = 'TotalLiab')                  as total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')     as equity,
    maxIf(value, metric = 'TotalCurrentAssets')         as current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')    as current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')     as cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')               as long_term_debt
  from f
  where statement = 'balance_sheet'
  group by ticker, fiscal_date
),

cf as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') as cfo,
    maxIf(value, metric = 'CapitalExpenditures')              as capex,
    maxIf(value, metric = 'Depreciation')                     as depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  as issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    as dividends_paid
  from f
  where statement = 'cashflow_statement'
  group by ticker, fiscal_date
)

select
  b.ticker,
  b.fiscal_date,
  b.currency,
  -- income
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  -- balance
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  -- cashflow
  cf.cfo,
  cf.capex,
  cf.depreciation,
  cf.issuance_of_stock,
  cf.dividends_paid
from base b
left join inc on (b.ticker = inc.ticker and b.fiscal_date = inc.fiscal_date)
left join bs  on (b.ticker = bs.ticker  and b.fiscal_date = bs.fiscal_date)
left join cf  on (b.ticker = cf.ticker  and b.fiscal_date = cf.fiscal_date)
;
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:44:40.608034 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

-- Build off the unified long view to keep filters/logic in one place
with f as (
  select *
  from `fundamentals`.`quarterly_fundamentals_long`
  where source = 'yfinance' and period = 'Q'
),

base as (
  select
    ticker,
    fiscal_date,
    -- Prefer the currency value associated with the latest loaded_at in case of multiple loads
    argMax(currency, loaded_at) as currency
  from f
  group by ticker, fiscal_date
),

inc as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalRevenue')    as total_revenue,
    maxIf(value, metric = 'CostOfRevenue')   as cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')     as gross_profit,
    maxIf(value, metric = 'OperatingIncome') as operating_income,
    maxIf(value, metric = 'NetIncome')       as net_income
  from f
  where statement = 'income_statement'
  group by ticker, fiscal_date
),

bs as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                as total_assets,
    maxIf(value, metric = 'TotalLiab')                  as total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')     as equity,
    maxIf(value, metric = 'TotalCurrentAssets')         as current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')    as current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')     as cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')               as long_term_debt
  from f
  where statement = 'balance_sheet'
  group by ticker, fiscal_date
),

cf as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') as cfo,
    maxIf(value, metric = 'CapitalExpenditures')              as capex,
    maxIf(value, metric = 'Depreciation')                     as depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  as issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    as dividends_paid
  from f
  where statement = 'cashflow_statement'
  group by ticker, fiscal_date
)

select
  b.ticker,
  b.fiscal_date,
  b.currency,
  -- income
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  -- balance
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  -- cashflow
  cf.cfo,
  cf.capex,
  cf.depreciation,
  cf.issuance_of_stock,
  cf.dividends_paid
from base b
left join inc on (b.ticker = inc.ticker and b.fiscal_date = inc.fiscal_date)
left join bs  on (b.ticker = bs.ticker  and b.fiscal_date = bs.fiscal_date)
left join cf  on (b.ticker = cf.ticker  and b.fiscal_date = cf.fiscal_date)
;
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:44:40.610768 [debug] [Thread-1 (]: Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 2949 (end of query) (line 103, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, GLOBAL, LOCAL, ANY, ALL, ASOF, SEMI, ANTI, ONLY, LEFT, RIGHT, FULL, CROSS, PASTE, JOIN, token, OpeningRoundBracket, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:44:40.611143 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '66d8632f-3541-471c-af51-f1766b2dd741', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1170479e0>]}
[0m15:44:40.611483 [error] [Thread-1 (]: 2 of 2 ERROR creating sql view model `fundamentals`.`quarterly_fundamentals_wide`  [[31mERROR[0m in 0.01s]
[0m15:44:40.611794 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:44:40.612132 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.quarterly_fundamentals_wide' to be skipped because of status 'error'.  Reason: Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 2949 (end of query) (line 103, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, GLOBAL, LOCAL, ANY, ALL, ASOF, SEMI, ANTI, ONLY, LEFT, RIGHT, FULL, CROSS, PASTE, JOIN, token, OpeningRoundBracket, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql.
[0m15:44:40.613139 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:44:40.613342 [debug] [MainThread]: Connection 'model.qi_dbt_project.quarterly_fundamentals_wide' was left open.
[0m15:44:40.613513 [debug] [MainThread]: On model.qi_dbt_project.quarterly_fundamentals_wide: Close
[0m15:44:40.613753 [info ] [MainThread]: 
[0m15:44:40.613926 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.42 seconds (0.42s).
[0m15:44:40.614344 [debug] [MainThread]: Command end result
[0m15:44:40.633064 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:44:40.634339 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:44:40.637493 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:44:40.637681 [info ] [MainThread]: 
[0m15:44:40.637874 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:44:40.638036 [info ] [MainThread]: 
[0m15:44:40.638242 [error] [MainThread]: [31mFailure in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)[0m
[0m15:44:40.638449 [error] [MainThread]:   Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 2949 (end of query) (line 103, col 1): ;
      
    )
        
        
                      -- end_of_sql
                      
                      . Expected one of: OR, AND, IS NOT DISTINCT FROM, IS NULL, IS NOT NULL, BETWEEN, NOT BETWEEN, LIKE, ILIKE, NOT LIKE, NOT ILIKE, REGEXP, IN, NOT IN, GLOBAL IN, GLOBAL NOT IN, MOD, DIV, table, table function, subquery or list of joined tables, array join, LEFT ARRAY JOIN, INNER, ARRAY JOIN, GLOBAL, LOCAL, ANY, ALL, ASOF, SEMI, ANTI, ONLY, LEFT, RIGHT, FULL, CROSS, PASTE, JOIN, token, OpeningRoundBracket, PREWHERE, WHERE, GROUP BY, WITH, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET, FETCH, SETTINGS, UNION, EXCEPT, INTERSECT. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:44:40.638692 [info ] [MainThread]: 
[0m15:44:40.638911 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:44:40.639076 [info ] [MainThread]: 
[0m15:44:40.639248 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m15:44:40.641789 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0366781, "process_in_blocks": "0", "process_kernel_time": 0.206178, "process_mem_max_rss": "196820992", "process_out_blocks": "0", "process_user_time": 1.548784}
[0m15:44:40.642036 [debug] [MainThread]: Command `dbt run` failed at 15:44:40.641993 after 1.04 seconds
[0m15:44:40.642244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c243e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c246e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c24410>]}
[0m15:44:40.642452 [debug] [MainThread]: Flushing usage events
[0m15:44:41.192006 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:46:06.281871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089899d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0e0bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2effe0>]}


============================== 15:46:06.284577 | e1900467-01d7-4306-a6b8-e3981d86e7f6 ==============================
[0m15:46:06.284577 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:46:06.284936 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'version_check': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'introspect': 'True', 'write_json': 'True', 'static_parser': 'True', 'quiet': 'False', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'indirect_selection': 'eager', 'empty': 'False', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_long fundamentals.quarterly_fundamentals_wide', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False'}
[0m15:46:06.385865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e1900467-01d7-4306-a6b8-e3981d86e7f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6b5760>]}
[0m15:46:06.416161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e1900467-01d7-4306-a6b8-e3981d86e7f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093ad100>]}
[0m15:46:06.416632 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:46:06.486910 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:46:06.552770 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:46:06.553180 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:46:06.742926 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m15:46:06.750321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1900467-01d7-4306-a6b8-e3981d86e7f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5522d0>]}
[0m15:46:06.832457 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:46:06.833579 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:46:06.841653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1900467-01d7-4306-a6b8-e3981d86e7f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b484d70>]}
[0m15:46:06.841919 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:46:06.842106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1900467-01d7-4306-a6b8-e3981d86e7f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1bb980>]}
[0m15:46:06.843052 [info ] [MainThread]: 
[0m15:46:06.843230 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:46:06.843375 [info ] [MainThread]: 
[0m15:46:06.843614 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:46:06.846367 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:46:06.851771 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:46:07.160048 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:46:07.161842 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:46:07.169736 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__fundamentals)
[0m15:46:07.173248 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:46:07.176318 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:46:07.177193 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__fundamentals, now list__market)
[0m15:46:07.178739 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:46:07.181381 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:46:07.182505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1900467-01d7-4306-a6b8-e3981d86e7f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b21c9b0>]}
[0m15:46:07.183779 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:46:07.184048 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_long` ....... [RUN]
[0m15:46:07.184274 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.quarterly_fundamentals_long)
[0m15:46:07.184461 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:46:07.188582 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:46:07.189158 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:46:07.198170 [debug] [Thread-1 (]: Relation quarterly_fundamentals_long already exists, replacing it
[0m15:46:07.204356 [debug] [Thread-1 (]: Model mvs to replace ['quarterly_fundamentals_long_mv']
[0m15:46:07.206007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.quarterly_fundamentals_long'
  
  ...
[0m15:46:07.213049 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:46:07.258670 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:46:07.259262 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_long` 
  
    
  
  
    
    
  as (
    -- models/fundamentals/quarterly_fundamentals_long.sql


-- Unified LONG ledger across the three raw tables, quarterly only
with inc as (
  select
    'income_statement' as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency
  from fundamentals.income_statement
  where period = 'Q'
),
bs as (
  select
    'balance_sheet' as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency
  from fundamentals.balance_sheet
  where period = 'Q'
),
cf as (
  select
    'cashflow_statement' as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency
  from fundamentals.cashflow_statement
  where period = 'Q'
)

select * from inc
union all
select * from bs
union all
select * from cf
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:46:07.263802 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:46:07.276118 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1900467-01d7-4306-a6b8-e3981d86e7f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089b1d60>]}
[0m15:46:07.276528 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `fundamentals`.`quarterly_fundamentals_long` .. [[32mOK[0m in 0.09s]
[0m15:46:07.276848 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:46:07.277282 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:46:07.277527 [info ] [Thread-1 (]: 2 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_wide` ....... [RUN]
[0m15:46:07.277821 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_fundamentals_long, now model.qi_dbt_project.quarterly_fundamentals_wide)
[0m15:46:07.278065 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:46:07.280149 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m15:46:07.280596 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:46:07.281895 [debug] [Thread-1 (]: Creating new relation quarterly_fundamentals_wide
[0m15:46:07.282326 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m15:46:07.282758 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

-- Build off the unified long view to keep filters/logic in one place
with f as (
  select *
  from `fundamentals`.`quarterly_fundamentals_long`
  where source = 'yfinance' and period = 'Q'
),

base as (
  select
    ticker,
    fiscal_date,
    -- Prefer the currency value associated with the latest loaded_at in case of multiple loads
    argMax(currency, loaded_at) as currency
  from f
  group by ticker, fiscal_date
),

inc as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalRevenue')    as total_revenue,
    maxIf(value, metric = 'CostOfRevenue')   as cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')     as gross_profit,
    maxIf(value, metric = 'OperatingIncome') as operating_income,
    maxIf(value, metric = 'NetIncome')       as net_income
  from f
  where statement = 'income_statement'
  group by ticker, fiscal_date
),

bs as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                as total_assets,
    maxIf(value, metric = 'TotalLiab')                  as total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')     as equity,
    maxIf(value, metric = 'TotalCurrentAssets')         as current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')    as current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')     as cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')               as long_term_debt
  from f
  where statement = 'balance_sheet'
  group by ticker, fiscal_date
),

cf as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') as cfo,
    maxIf(value, metric = 'CapitalExpenditures')              as capex,
    maxIf(value, metric = 'Depreciation')                     as depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  as issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    as dividends_paid
  from f
  where statement = 'cashflow_statement'
  group by ticker, fiscal_date
)

select
  b.ticker,
  b.fiscal_date,
  b.currency,
  -- income
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  -- balance
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  -- cashflow
  cf.cfo,
  cf.capex,
  cf.depreciation,
  cf.issuance_of_stock,
  cf.dividends_paid
from base b
left join inc on (b.ticker = inc.ticker and b.fiscal_date = inc.fiscal_date)
left join bs  on (b.ticker = bs.ticker  and b.fiscal_date = bs.fiscal_date)
left join cf  on (b.ticker = cf.ticker  and b.fiscal_date = cf.fiscal_date)
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:46:07.287312 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

-- Build off the unified long view to keep filters/logic in one place
with f as (
  select *
  from `fundamentals`.`quarterly_fundamentals_long`
  where source = 'yfinance' and period = 'Q'
),

base as (
  select
    ticker,
    fiscal_date,
    -- Prefer the currency value associated with the latest loaded_at in case of multiple loads
    argMax(currency, loaded_at) as currency
  from f
  group by ticker, fiscal_date
),

inc as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalRevenue')    as total_revenue,
    maxIf(value, metric = 'CostOfRevenue')   as cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')     as gross_profit,
    maxIf(value, metric = 'OperatingIncome') as operating_income,
    maxIf(value, metric = 'NetIncome')       as net_income
  from f
  where statement = 'income_statement'
  group by ticker, fiscal_date
),

bs as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                as total_assets,
    maxIf(value, metric = 'TotalLiab')                  as total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')     as equity,
    maxIf(value, metric = 'TotalCurrentAssets')         as current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')    as current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')     as cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')               as long_term_debt
  from f
  where statement = 'balance_sheet'
  group by ticker, fiscal_date
),

cf as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') as cfo,
    maxIf(value, metric = 'CapitalExpenditures')              as capex,
    maxIf(value, metric = 'Depreciation')                     as depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  as issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    as dividends_paid
  from f
  where statement = 'cashflow_statement'
  group by ticker, fiscal_date
)

select
  b.ticker,
  b.fiscal_date,
  b.currency,
  -- income
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  -- balance
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  -- cashflow
  cf.cfo,
  cf.capex,
  cf.depreciation,
  cf.issuance_of_stock,
  cf.dividends_paid
from base b
left join inc on (b.ticker = inc.ticker and b.fiscal_date = inc.fiscal_date)
left join bs  on (b.ticker = bs.ticker  and b.fiscal_date = bs.fiscal_date)
left join cf  on (b.ticker = cf.ticker  and b.fiscal_date = cf.fiscal_date)
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:46:07.289911 [debug] [Thread-1 (]: Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or function identifier `source` in scope SELECT * FROM fundamentals.quarterly_fundamentals_long WHERE (source = 'yfinance') AND (period = 'Q'). (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:46:07.290325 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1900467-01d7-4306-a6b8-e3981d86e7f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124551f0>]}
[0m15:46:07.290694 [error] [Thread-1 (]: 2 of 2 ERROR creating sql view model `fundamentals`.`quarterly_fundamentals_wide`  [[31mERROR[0m in 0.01s]
[0m15:46:07.291002 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:46:07.291262 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.quarterly_fundamentals_wide' to be skipped because of status 'error'.  Reason: Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or function identifier `source` in scope SELECT * FROM fundamentals.quarterly_fundamentals_long WHERE (source = 'yfinance') AND (period = 'Q'). (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql.
[0m15:46:07.292235 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:46:07.292454 [debug] [MainThread]: Connection 'model.qi_dbt_project.quarterly_fundamentals_wide' was left open.
[0m15:46:07.292631 [debug] [MainThread]: On model.qi_dbt_project.quarterly_fundamentals_wide: Close
[0m15:46:07.292876 [info ] [MainThread]: 
[0m15:46:07.293062 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m15:46:07.293459 [debug] [MainThread]: Command end result
[0m15:46:07.312551 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:46:07.313678 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:46:07.316979 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:46:07.317190 [info ] [MainThread]: 
[0m15:46:07.317399 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:46:07.317571 [info ] [MainThread]: 
[0m15:46:07.317780 [error] [MainThread]: [31mFailure in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)[0m
[0m15:46:07.317985 [error] [MainThread]:   Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or function identifier `source` in scope SELECT * FROM fundamentals.quarterly_fundamentals_long WHERE (source = 'yfinance') AND (period = 'Q'). (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:46:07.318145 [info ] [MainThread]: 
[0m15:46:07.318321 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:46:07.318468 [info ] [MainThread]: 
[0m15:46:07.318637 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m15:46:07.321133 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.076984, "process_in_blocks": "0", "process_kernel_time": 0.214196, "process_mem_max_rss": "196132864", "process_out_blocks": "0", "process_user_time": 1.562756}
[0m15:46:07.321428 [debug] [MainThread]: Command `dbt run` failed at 15:46:07.321382 after 1.08 seconds
[0m15:46:07.321646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2effe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e397e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e451d00>]}
[0m15:46:07.321851 [debug] [MainThread]: Flushing usage events
[0m15:46:07.965889 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:47:50.928634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062ae720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e24770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e24170>]}


============================== 15:47:50.931226 | a3d3dfa0-f65c-4f0f-963b-c22c5aa40491 ==============================
[0m15:47:50.931226 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:47:50.931559 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'write_json': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_long fundamentals.quarterly_fundamentals_wide', 'static_parser': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'printer_width': '80', 'partial_parse': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'indirect_selection': 'eager'}
[0m15:47:51.023721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3d3dfa0-f65c-4f0f-963b-c22c5aa40491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca3bf0>]}
[0m15:47:51.054294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3d3dfa0-f65c-4f0f-963b-c22c5aa40491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f27b00>]}
[0m15:47:51.054939 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:47:51.125376 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:47:51.187967 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:47:51.188376 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_long.sql
[0m15:47:51.383949 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m15:47:51.391101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3d3dfa0-f65c-4f0f-963b-c22c5aa40491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa77530>]}
[0m15:47:51.470920 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:47:51.472030 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:47:51.480053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3d3dfa0-f65c-4f0f-963b-c22c5aa40491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a971e20>]}
[0m15:47:51.480323 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:47:51.480513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3d3dfa0-f65c-4f0f-963b-c22c5aa40491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e11e20>]}
[0m15:47:51.481451 [info ] [MainThread]: 
[0m15:47:51.481631 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:47:51.481772 [info ] [MainThread]: 
[0m15:47:51.482008 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:47:51.484735 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:47:51.489928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:51.795329 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:47:51.797173 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:47:51.805270 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m15:47:51.808853 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:47:51.811856 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:47:51.812754 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m15:47:51.814297 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:47:51.816991 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:47:51.818197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3d3dfa0-f65c-4f0f-963b-c22c5aa40491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119071b50>]}
[0m15:47:51.819299 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:47:51.819575 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_long` ....... [RUN]
[0m15:47:51.819811 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.quarterly_fundamentals_long)
[0m15:47:51.820003 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:47:51.824648 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:47:51.825233 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:47:51.867657 [debug] [Thread-1 (]: Relation quarterly_fundamentals_long already exists, replacing it
[0m15:47:51.873272 [debug] [Thread-1 (]: Model mvs to replace ['quarterly_fundamentals_long_mv']
[0m15:47:51.874482 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.quarterly_fundamentals_long'
  
  ...
[0m15:47:51.878575 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:47:51.887101 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:47:51.887659 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_long` 
  
    
  
  
    
    
  as (
    

-- Unified LONG ledger across the three raw tables, quarterly only
with inc as (
  select
    'income_statement'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source
  from fundamentals.income_statement
  where period = 'Q'
),
bs as (
  select
    'balance_sheet'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source
  from fundamentals.balance_sheet
  where period = 'Q'
),
cf as (
  select
    'cashflow_statement'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source
  from fundamentals.cashflow_statement
  where period = 'Q'
)

select * from inc
union all
select * from bs
union all
select * from cf
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:47:51.905479 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:47:51.918136 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3d3dfa0-f65c-4f0f-963b-c22c5aa40491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cc3650>]}
[0m15:47:51.918563 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `fundamentals`.`quarterly_fundamentals_long` .. [[32mOK[0m in 0.10s]
[0m15:47:51.918877 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:47:51.919323 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:47:51.919615 [info ] [Thread-1 (]: 2 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_wide` ....... [RUN]
[0m15:47:51.919838 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_fundamentals_long, now model.qi_dbt_project.quarterly_fundamentals_wide)
[0m15:47:51.920031 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:47:51.922055 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m15:47:51.922600 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:47:51.924099 [debug] [Thread-1 (]: Creating new relation quarterly_fundamentals_wide
[0m15:47:51.924612 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m15:47:51.925134 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

-- Build off the unified long view to keep filters/logic in one place
with f as (
  select *
  from `fundamentals`.`quarterly_fundamentals_long`
  where source = 'yfinance' and period = 'Q'
),

base as (
  select
    ticker,
    fiscal_date,
    -- Prefer the currency value associated with the latest loaded_at in case of multiple loads
    argMax(currency, loaded_at) as currency
  from f
  group by ticker, fiscal_date
),

inc as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalRevenue')    as total_revenue,
    maxIf(value, metric = 'CostOfRevenue')   as cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')     as gross_profit,
    maxIf(value, metric = 'OperatingIncome') as operating_income,
    maxIf(value, metric = 'NetIncome')       as net_income
  from f
  where statement = 'income_statement'
  group by ticker, fiscal_date
),

bs as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                as total_assets,
    maxIf(value, metric = 'TotalLiab')                  as total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')     as equity,
    maxIf(value, metric = 'TotalCurrentAssets')         as current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')    as current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')     as cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')               as long_term_debt
  from f
  where statement = 'balance_sheet'
  group by ticker, fiscal_date
),

cf as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') as cfo,
    maxIf(value, metric = 'CapitalExpenditures')              as capex,
    maxIf(value, metric = 'Depreciation')                     as depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  as issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    as dividends_paid
  from f
  where statement = 'cashflow_statement'
  group by ticker, fiscal_date
)

select
  b.ticker,
  b.fiscal_date,
  b.currency,
  -- income
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  -- balance
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  -- cashflow
  cf.cfo,
  cf.capex,
  cf.depreciation,
  cf.issuance_of_stock,
  cf.dividends_paid
from base b
left join inc on (b.ticker = inc.ticker and b.fiscal_date = inc.fiscal_date)
left join bs  on (b.ticker = bs.ticker  and b.fiscal_date = bs.fiscal_date)
left join cf  on (b.ticker = cf.ticker  and b.fiscal_date = cf.fiscal_date)
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:47:51.929107 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

-- Build off the unified long view to keep filters/logic in one place
with f as (
  select *
  from `fundamentals`.`quarterly_fundamentals_long`
  where source = 'yfinance' and period = 'Q'
),

base as (
  select
    ticker,
    fiscal_date,
    -- Prefer the currency value associated with the latest loaded_at in case of multiple loads
    argMax(currency, loaded_at) as currency
  from f
  group by ticker, fiscal_date
),

inc as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalRevenue')    as total_revenue,
    maxIf(value, metric = 'CostOfRevenue')   as cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')     as gross_profit,
    maxIf(value, metric = 'OperatingIncome') as operating_income,
    maxIf(value, metric = 'NetIncome')       as net_income
  from f
  where statement = 'income_statement'
  group by ticker, fiscal_date
),

bs as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                as total_assets,
    maxIf(value, metric = 'TotalLiab')                  as total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')     as equity,
    maxIf(value, metric = 'TotalCurrentAssets')         as current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')    as current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')     as cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')               as long_term_debt
  from f
  where statement = 'balance_sheet'
  group by ticker, fiscal_date
),

cf as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') as cfo,
    maxIf(value, metric = 'CapitalExpenditures')              as capex,
    maxIf(value, metric = 'Depreciation')                     as depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  as issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    as dividends_paid
  from f
  where statement = 'cashflow_statement'
  group by ticker, fiscal_date
)

select
  b.ticker,
  b.fiscal_date,
  b.currency,
  -- income
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  -- balance
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  -- cashflow
  cf.cfo,
  cf.capex,
  cf.depreciation,
  cf.issuance_of_stock,
  cf.dividends_paid
from base b
left join inc on (b.ticker = inc.ticker and b.fiscal_date = inc.fiscal_date)
left join bs  on (b.ticker = bs.ticker  and b.fiscal_date = bs.fiscal_date)
left join cf  on (b.ticker = cf.ticker  and b.fiscal_date = cf.fiscal_date)
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:47:51.931813 [debug] [Thread-1 (]: Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or function identifier `loaded_at` in scope SELECT ticker, fiscal_date, argMax(currency, loaded_at) AS currency FROM f GROUP BY ticker, fiscal_date. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:47:51.932131 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3d3dfa0-f65c-4f0f-963b-c22c5aa40491', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9a4080>]}
[0m15:47:51.932491 [error] [Thread-1 (]: 2 of 2 ERROR creating sql view model `fundamentals`.`quarterly_fundamentals_wide`  [[31mERROR[0m in 0.01s]
[0m15:47:51.932823 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:47:51.933118 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.quarterly_fundamentals_wide' to be skipped because of status 'error'.  Reason: Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or function identifier `loaded_at` in scope SELECT ticker, fiscal_date, argMax(currency, loaded_at) AS currency FROM f GROUP BY ticker, fiscal_date. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql.
[0m15:47:51.934173 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:47:51.934510 [debug] [MainThread]: Connection 'model.qi_dbt_project.quarterly_fundamentals_wide' was left open.
[0m15:47:51.934731 [debug] [MainThread]: On model.qi_dbt_project.quarterly_fundamentals_wide: Close
[0m15:47:51.934975 [info ] [MainThread]: 
[0m15:47:51.935139 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m15:47:51.935536 [debug] [MainThread]: Command end result
[0m15:47:51.954142 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:47:51.955490 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:47:51.958502 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:47:51.958686 [info ] [MainThread]: 
[0m15:47:51.958881 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:47:51.959044 [info ] [MainThread]: 
[0m15:47:51.959237 [error] [MainThread]: [31mFailure in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)[0m
[0m15:47:51.959427 [error] [MainThread]:   Database Error in model quarterly_fundamentals_wide (models/fundamentals/quarterly_fundamentals_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression or function identifier `loaded_at` in scope SELECT ticker, fiscal_date, argMax(currency, loaded_at) AS currency FROM f GROUP BY ticker, fiscal_date. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:47:51.959581 [info ] [MainThread]: 
[0m15:47:51.959746 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/quarterly_fundamentals_wide.sql
[0m15:47:51.959883 [info ] [MainThread]: 
[0m15:47:51.960041 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m15:47:51.962379 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0703274, "process_in_blocks": "0", "process_kernel_time": 0.208377, "process_mem_max_rss": "196476928", "process_out_blocks": "0", "process_user_time": 1.561433}
[0m15:47:51.962624 [debug] [MainThread]: Command `dbt run` failed at 15:47:51.962583 after 1.07 seconds
[0m15:47:51.962823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cf3f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a817890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f86d1c0>]}
[0m15:47:51.963002 [debug] [MainThread]: Flushing usage events
[0m15:47:52.553244 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:49:14.616131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f97ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055c8ec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10561bfb0>]}


============================== 15:49:14.618763 | 7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec ==============================
[0m15:49:14.618763 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:49:14.619111 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'debug': 'False', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'fail_fast': 'False', 'printer_width': '80', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_long fundamentals.quarterly_fundamentals_wide', 'log_format': 'default', 'indirect_selection': 'eager', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'static_parser': 'True', 'write_json': 'True'}
[0m15:49:14.711432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10564f830>]}
[0m15:49:14.742555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053b1040>]}
[0m15:49:14.743067 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:49:14.813479 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:49:14.876543 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:49:14.876968 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_long.sql
[0m15:49:15.068511 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m15:49:15.075556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea79b0>]}
[0m15:49:15.157217 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:49:15.158364 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:49:15.166183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105daae70>]}
[0m15:49:15.166453 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:49:15.166642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f13a70>]}
[0m15:49:15.167594 [info ] [MainThread]: 
[0m15:49:15.167769 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:49:15.167915 [info ] [MainThread]: 
[0m15:49:15.168154 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:49:15.170854 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:49:15.176022 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:49:15.478110 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:49:15.479968 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:49:15.488233 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__fundamentals)
[0m15:49:15.492227 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:49:15.495057 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:49:15.496046 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__fundamentals, now list__market)
[0m15:49:15.497685 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:49:15.500392 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:49:15.501650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062f5820>]}
[0m15:49:15.502975 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:49:15.503271 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_long` ....... [RUN]
[0m15:49:15.503517 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.quarterly_fundamentals_long)
[0m15:49:15.503717 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:49:15.508106 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:49:15.508690 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:49:15.551450 [debug] [Thread-1 (]: Relation quarterly_fundamentals_long already exists, replacing it
[0m15:49:15.556837 [debug] [Thread-1 (]: Model mvs to replace ['quarterly_fundamentals_long_mv']
[0m15:49:15.558014 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.quarterly_fundamentals_long'
  
  ...
[0m15:49:15.563616 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:49:15.571993 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_long"
[0m15:49:15.572567 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_long"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_long` 
  
    
  
  
    
    
  as (
    

-- Unified LONG ledger across the three raw tables, quarterly only
with inc as (
  select
    'income_statement'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.income_statement
  where period = 'Q'
),
bs as (
  select
    'balance_sheet'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.balance_sheet
  where period = 'Q'
),
cf as (
  select
    'cashflow_statement'::String as statement,
    ticker,
    fiscal_date,
    period,
    metric,
    value,
    currency,
    source,
    loaded_at
  from fundamentals.cashflow_statement
  where period = 'Q'
)

select * from inc
union all
select * from bs
union all
select * from cf
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:49:15.580416 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:49:15.592880 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102ecf890>]}
[0m15:49:15.593291 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `fundamentals`.`quarterly_fundamentals_long` .. [[32mOK[0m in 0.09s]
[0m15:49:15.593599 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_long
[0m15:49:15.593966 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:49:15.594247 [info ] [Thread-1 (]: 2 of 2 START sql view model `fundamentals`.`quarterly_fundamentals_wide` ....... [RUN]
[0m15:49:15.594489 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_fundamentals_long, now model.qi_dbt_project.quarterly_fundamentals_wide)
[0m15:49:15.594686 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:49:15.596691 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m15:49:15.597277 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:49:15.598715 [debug] [Thread-1 (]: Creating new relation quarterly_fundamentals_wide
[0m15:49:15.599203 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m15:49:15.599694 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

-- Build off the unified long view to keep filters/logic in one place
with f as (
  select *
  from `fundamentals`.`quarterly_fundamentals_long`
  where source = 'yfinance' and period = 'Q'
),

base as (
  select
    ticker,
    fiscal_date,
    -- Prefer the currency value associated with the latest loaded_at in case of multiple loads
    argMax(currency, loaded_at) as currency
  from f
  group by ticker, fiscal_date
),

inc as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalRevenue')    as total_revenue,
    maxIf(value, metric = 'CostOfRevenue')   as cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')     as gross_profit,
    maxIf(value, metric = 'OperatingIncome') as operating_income,
    maxIf(value, metric = 'NetIncome')       as net_income
  from f
  where statement = 'income_statement'
  group by ticker, fiscal_date
),

bs as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                as total_assets,
    maxIf(value, metric = 'TotalLiab')                  as total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')     as equity,
    maxIf(value, metric = 'TotalCurrentAssets')         as current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')    as current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')     as cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')               as long_term_debt
  from f
  where statement = 'balance_sheet'
  group by ticker, fiscal_date
),

cf as (
  select
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') as cfo,
    maxIf(value, metric = 'CapitalExpenditures')              as capex,
    maxIf(value, metric = 'Depreciation')                     as depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  as issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    as dividends_paid
  from f
  where statement = 'cashflow_statement'
  group by ticker, fiscal_date
)

select
  b.ticker,
  b.fiscal_date,
  b.currency,
  -- income
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  -- balance
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  -- cashflow
  cf.cfo,
  cf.capex,
  cf.depreciation,
  cf.issuance_of_stock,
  cf.dividends_paid
from base b
left join inc on (b.ticker = inc.ticker and b.fiscal_date = inc.fiscal_date)
left join bs  on (b.ticker = bs.ticker  and b.fiscal_date = bs.fiscal_date)
left join cf  on (b.ticker = cf.ticker  and b.fiscal_date = cf.fiscal_date)
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:49:15.615445 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:49:15.616791 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8c8a89-3bdd-42b3-9d52-34ec0b4c87ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c067d40>]}
[0m15:49:15.617189 [info ] [Thread-1 (]: 2 of 2 OK created sql view model `fundamentals`.`quarterly_fundamentals_wide` .. [[32mOK[0m in 0.02s]
[0m15:49:15.617486 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m15:49:15.618212 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:49:15.618447 [debug] [MainThread]: Connection 'model.qi_dbt_project.quarterly_fundamentals_wide' was left open.
[0m15:49:15.618634 [debug] [MainThread]: On model.qi_dbt_project.quarterly_fundamentals_wide: Close
[0m15:49:15.618893 [info ] [MainThread]: 
[0m15:49:15.619079 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m15:49:15.619489 [debug] [MainThread]: Command end result
[0m15:49:15.639236 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:49:15.640490 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:49:15.643686 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:49:15.643888 [info ] [MainThread]: 
[0m15:49:15.644113 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:49:15.644275 [info ] [MainThread]: 
[0m15:49:15.644452 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m15:49:15.647046 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0671582, "process_in_blocks": "0", "process_kernel_time": 0.215066, "process_mem_max_rss": "196378624", "process_out_blocks": "0", "process_user_time": 1.56482}
[0m15:49:15.647319 [debug] [MainThread]: Command `dbt run` succeeded at 15:49:15.647273 after 1.07 seconds
[0m15:49:15.647533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea7950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048fc110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055c8e30>]}
[0m15:49:15.647727 [debug] [MainThread]: Flushing usage events
[0m15:49:16.234547 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:50:44.716261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111dcef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117315e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109121b0>]}


============================== 15:50:44.718825 | 4a9aad4d-f5ec-47a7-94b5-808981de712e ==============================
[0m15:50:44.718825 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:50:44.719184 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'printer_width': '80', 'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'empty': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'indirect_selection': 'eager', 'fail_fast': 'False', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'version_check': 'True', 'debug': 'False', 'static_parser': 'True', 'introspect': 'True', 'write_json': 'True', 'partial_parse': 'True', 'quiet': 'False', 'target_path': 'None', 'use_colors': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m15:50:44.809325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a9aad4d-f5ec-47a7-94b5-808981de712e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e4c500>]}
[0m15:50:44.839388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a9aad4d-f5ec-47a7-94b5-808981de712e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112299df0>]}
[0m15:50:44.839861 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:50:44.908203 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:50:44.971627 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:50:44.971881 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:50:44.975366 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m15:50:44.996444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a9aad4d-f5ec-47a7-94b5-808981de712e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11258e090>]}
[0m15:50:45.045366 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:50:45.046599 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:50:45.054272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a9aad4d-f5ec-47a7-94b5-808981de712e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132985f0>]}
[0m15:50:45.054532 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:50:45.054717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a9aad4d-f5ec-47a7-94b5-808981de712e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113142de0>]}
[0m15:50:45.055114 [warn ] [MainThread]: The selection criterion 'fundamentals.key_ratios_quarterly_wide' does not match any enabled nodes
[0m15:50:45.055367 [warn ] [MainThread]: The selection criterion 'fundamentals.key_ratios_quarterly_long' does not match any enabled nodes
[0m15:50:45.055930 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m15:50:45.056856 [debug] [MainThread]: Command end result
[0m15:50:45.074297 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:50:45.075443 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:50:45.077089 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:50:45.078507 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.39779013, "process_in_blocks": "0", "process_kernel_time": 0.148324, "process_mem_max_rss": "122716160", "process_out_blocks": "0", "process_user_time": 1.011256}
[0m15:50:45.078826 [debug] [MainThread]: Command `dbt run` succeeded at 15:50:45.078774 after 0.40 seconds
[0m15:50:45.079049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11300c3e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111141b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113068710>]}
[0m15:50:45.079243 [debug] [MainThread]: Flushing usage events
[0m15:50:45.672607 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:51:50.966527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a229c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059e0bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059e0b30>]}


============================== 15:51:50.969033 | 4c26c310-1e93-4dee-9a2f-cd1895848638 ==============================
[0m15:51:50.969033 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:51:50.969371 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'indirect_selection': 'eager', 'use_colors': 'True', 'static_parser': 'True', 'printer_width': '80', 'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'log_format': 'default', 'log_cache_events': 'False', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'quiet': 'False', 'version_check': 'True', 'introspect': 'True', 'partial_parse': 'True', 'empty': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m15:51:51.064448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4c26c310-1e93-4dee-9a2f-cd1895848638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d83470>]}
[0m15:51:51.095677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4c26c310-1e93-4dee-9a2f-cd1895848638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a23350>]}
[0m15:51:51.096210 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:51:51.166777 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:51:51.232004 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:51:51.232289 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:51:51.235891 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m15:51:51.258108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4c26c310-1e93-4dee-9a2f-cd1895848638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106861b50>]}
[0m15:51:51.309917 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:51:51.311310 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:51:51.319725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4c26c310-1e93-4dee-9a2f-cd1895848638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d98260>]}
[0m15:51:51.320004 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:51:51.320197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4c26c310-1e93-4dee-9a2f-cd1895848638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10683e0f0>]}
[0m15:51:51.320646 [warn ] [MainThread]: The selection criterion 'fundamentals.key_ratios_quarterly_wide' does not match any enabled nodes
[0m15:51:51.320915 [warn ] [MainThread]: The selection criterion 'fundamentals.key_ratios_quarterly_long' does not match any enabled nodes
[0m15:51:51.321682 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m15:51:51.322711 [debug] [MainThread]: Command end result
[0m15:51:51.340810 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:51:51.342104 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:51:51.343910 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:51:51.345433 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.4168384, "process_in_blocks": "0", "process_kernel_time": 0.153033, "process_mem_max_rss": "122552320", "process_out_blocks": "0", "process_user_time": 1.039191}
[0m15:51:51.345737 [debug] [MainThread]: Command `dbt run` succeeded at 15:51:51.345688 after 0.42 seconds
[0m15:51:51.345969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c24350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106861100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049fff20>]}
[0m15:51:51.346174 [debug] [MainThread]: Flushing usage events
[0m15:51:51.824325 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:56:04.611530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c88800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d208c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d202c0>]}


============================== 15:56:04.614428 | 1a9b30ba-fed0-4a11-9b79-b04bb432a377 ==============================
[0m15:56:04.614428 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:56:04.614785 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'write_json': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'target_path': 'None', 'use_experimental_parser': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'introspect': 'True', 'no_print': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'fail_fast': 'False', 'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'indirect_selection': 'eager', 'empty': 'False', 'static_parser': 'True', 'log_format': 'default', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False'}
[0m15:56:04.707148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1a9b30ba-fed0-4a11-9b79-b04bb432a377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ac83b0>]}
[0m15:56:04.737717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1a9b30ba-fed0-4a11-9b79-b04bb432a377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10643af90>]}
[0m15:56:04.738223 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:56:04.807394 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:56:04.869881 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 2 files added, 0 files changed.
[0m15:56:04.870254 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:56:04.870438 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_long.sql
[0m15:56:04.870597 [debug] [MainThread]: Partial parsing: deleted file: qi_dbt_project://models/fundamentals/key_ratios_wide.sql
[0m15:56:04.870747 [debug] [MainThread]: Partial parsing: deleted file: qi_dbt_project://models/fundamentals/key_ratios_long.sql
[0m15:56:04.990427 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m15:56:04.997639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a9b30ba-fed0-4a11-9b79-b04bb432a377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084dd820>]}
[0m15:56:05.047378 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:56:05.048644 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:56:05.056890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a9b30ba-fed0-4a11-9b79-b04bb432a377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085ea300>]}
[0m15:56:05.057179 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:56:05.057363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a9b30ba-fed0-4a11-9b79-b04bb432a377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108497080>]}
[0m15:56:05.058370 [info ] [MainThread]: 
[0m15:56:05.058573 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:56:05.058730 [info ] [MainThread]: 
[0m15:56:05.058999 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:56:05.062273 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:56:05.067611 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:56:05.398098 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:56:05.400004 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:56:05.408126 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__fundamentals)
[0m15:56:05.412136 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:56:05.415592 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:56:05.416510 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__fundamentals, now list__market)
[0m15:56:05.418162 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:56:05.421040 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:56:05.422281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a9b30ba-fed0-4a11-9b79-b04bb432a377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d9e8a0>]}
[0m15:56:05.423431 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m15:56:05.423715 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_long` ......... [RUN]
[0m15:56:05.423951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.key_ratios_quarterly_long)
[0m15:56:05.424145 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_long
[0m15:56:05.428378 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m15:56:05.429017 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_long
[0m15:56:05.437179 [debug] [Thread-1 (]: Creating new relation key_ratios_quarterly_long
[0m15:56:05.444911 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m15:56:05.445546 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

-- Long (tidy) version of key ratios for flexible charting and filtering.

WITH w AS (
  SELECT
    *
  FROM fundamentals.key_ratios_quarterly_wide
),

u AS (
  SELECT
    ticker,
    fiscal_date,
    currency,
    arrayJoin([
      'gross_margin',
      'operating_margin',
      'net_margin',
      'return_on_assets',
      'return_on_equity',
      'current_ratio',
      'debt_to_equity_total',
      'debt_to_equity_long',
      'free_cash_flow',
      'fcf_margin',
      'cfo_margin',
      'cfo_to_long_term_debt'
    ])                                        AS ratio_name,
    arrayJoin([
      gross_margin,
      operating_margin,
      net_margin,
      return_on_assets,
      return_on_equity,
      current_ratio,
      debt_to_equity_total,
      debt_to_equity_long,
      free_cash_flow,
      fcf_margin,
      cfo_margin,
      cfo_to_long_term_debt
    ])                                        AS ratio_value
  FROM w
)

SELECT
  ticker,
  fiscal_date,
  currency,
  ratio_name,
  ratio_value
FROM u
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:56:05.448868 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

-- Long (tidy) version of key ratios for flexible charting and filtering.

WITH w AS (
  SELECT
    *
  FROM fundamentals.key_ratios_quarterly_wide
),

u AS (
  SELECT
    ticker,
    fiscal_date,
    currency,
    arrayJoin([
      'gross_margin',
      'operating_margin',
      'net_margin',
      'return_on_assets',
      'return_on_equity',
      'current_ratio',
      'debt_to_equity_total',
      'debt_to_equity_long',
      'free_cash_flow',
      'fcf_margin',
      'cfo_margin',
      'cfo_to_long_term_debt'
    ])                                        AS ratio_name,
    arrayJoin([
      gross_margin,
      operating_margin,
      net_margin,
      return_on_assets,
      return_on_equity,
      current_ratio,
      debt_to_equity_total,
      debt_to_equity_long,
      free_cash_flow,
      fcf_margin,
      cfo_margin,
      cfo_to_long_term_debt
    ])                                        AS ratio_value
  FROM w
)

SELECT
  ticker,
  fiscal_date,
  currency,
  ratio_name,
  ratio_value
FROM u
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:56:05.451216 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'fundamentals.key_ratios_quarterly_wide' in scope SELECT * FROM fundamentals.key_ratios_quarterly_wide. (UNKNOWN_TABLE) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m15:56:05.452146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a9b30ba-fed0-4a11-9b79-b04bb432a377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069b1df0>]}
[0m15:56:05.452544 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_long`  [[31mERROR[0m in 0.03s]
[0m15:56:05.452860 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m15:56:05.453068 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:56:05.453337 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_long' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'fundamentals.key_ratios_quarterly_wide' in scope SELECT * FROM fundamentals.key_ratios_quarterly_wide. (UNKNOWN_TABLE) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql.
[0m15:56:05.453639 [info ] [Thread-1 (]: 2 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m15:56:05.454276 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.key_ratios_quarterly_long, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m15:56:05.454516 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:56:05.456360 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m15:56:05.456810 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:56:05.458046 [debug] [Thread-1 (]: Creating new relation key_ratios_quarterly_wide
[0m15:56:05.458507 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m15:56:05.458898 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

-- Derived quarterly ratios from the wide fundamentals view.
-- Uses yfinance-only metrics already filtered/assembled upstream.

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    currency,
    total_revenue,
    gross_profit,
    operating_income,
    net_income,
    total_assets,
    total_liab,
    equity,
    current_assets,
    current_liab,
    cash_and_equiv,
    long_term_debt,
    cfo,
    capex,
    (cfo - capex) AS fcf
  FROM fundamentals.quarterly_fundamentals_wide
)

SELECT
  ticker,
  fiscal_date,
  currency,

  -- Profitability
  gross_profit / nullIf(total_revenue, 0)        AS gross_margin,
  operating_income / nullIf(total_revenue, 0)    AS operating_margin,
  net_income / nullIf(total_revenue, 0)          AS net_margin,

  -- Returns
  net_income / nullIf(total_assets, 0)           AS return_on_assets,
  net_income / nullIf(equity, 0)                 AS return_on_equity,

  -- Liquidity (quick ratio needs inventory; omitted until we ingest it)
  current_assets / nullIf(current_liab, 0)       AS current_ratio,

  -- Leverage
  total_liab / nullIf(equity, 0)                 AS debt_to_equity_total,
  long_term_debt / nullIf(equity, 0)             AS debt_to_equity_long,

  -- Cash flow
  fcf                                           AS free_cash_flow,
  fcf / nullIf(total_revenue, 0)                 AS fcf_margin,
  cfo / nullIf(total_revenue, 0)                 AS cfo_margin,

  -- Coverage (simple proxy)
  cfo / nullIf(long_term_debt, 0)                AS cfo_to_long_term_debt

FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:56:05.461476 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

-- Derived quarterly ratios from the wide fundamentals view.
-- Uses yfinance-only metrics already filtered/assembled upstream.

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    currency,
    total_revenue,
    gross_profit,
    operating_income,
    net_income,
    total_assets,
    total_liab,
    equity,
    current_assets,
    current_liab,
    cash_and_equiv,
    long_term_debt,
    cfo,
    capex,
    (cfo - capex) AS fcf
  FROM fundamentals.quarterly_fundamentals_wide
)

SELECT
  ticker,
  fiscal_date,
  currency,

  -- Profitability
  gross_profit / nullIf(total_revenue, 0)        AS gross_margin,
  operating_income / nullIf(total_revenue, 0)    AS operating_margin,
  net_income / nullIf(total_revenue, 0)          AS net_margin,

  -- Returns
  net_income / nullIf(total_assets, 0)           AS return_on_assets,
  net_income / nullIf(equity, 0)                 AS return_on_equity,

  -- Liquidity (quick ratio needs inventory; omitted until we ingest it)
  current_assets / nullIf(current_liab, 0)       AS current_ratio,

  -- Leverage
  total_liab / nullIf(equity, 0)                 AS debt_to_equity_total,
  long_term_debt / nullIf(equity, 0)             AS debt_to_equity_long,

  -- Cash flow
  fcf                                           AS free_cash_flow,
  fcf / nullIf(total_revenue, 0)                 AS fcf_margin,
  cfo / nullIf(total_revenue, 0)                 AS cfo_margin,

  -- Coverage (simple proxy)
  cfo / nullIf(long_term_debt, 0)                AS cfo_to_long_term_debt

FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:56:05.463021 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:56:05.463338 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a9b30ba-fed0-4a11-9b79-b04bb432a377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3963c0>]}
[0m15:56:05.463693 [error] [Thread-1 (]: 2 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_wide`  [[31mERROR[0m in 0.01s]
[0m15:56:05.464011 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:56:05.464330 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_wide' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql.
[0m15:56:05.465124 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:56:05.465405 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_wide' was left open.
[0m15:56:05.465581 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_wide: Close
[0m15:56:05.465827 [info ] [MainThread]: 
[0m15:56:05.465987 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m15:56:05.466376 [debug] [MainThread]: Command end result
[0m15:56:05.485421 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:56:05.486755 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:56:05.490122 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:56:05.490324 [info ] [MainThread]: 
[0m15:56:05.490534 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m15:56:05.490696 [info ] [MainThread]: 
[0m15:56:05.490900 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)[0m
[0m15:56:05.491097 [error] [MainThread]:   Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 60, server response: Code: 60. DB::Exception: Unknown table expression identifier 'fundamentals.key_ratios_quarterly_wide' in scope SELECT * FROM fundamentals.key_ratios_quarterly_wide. (UNKNOWN_TABLE) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m15:56:05.491258 [info ] [MainThread]: 
[0m15:56:05.491434 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m15:56:05.491580 [info ] [MainThread]: 
[0m15:56:05.491757 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)[0m
[0m15:56:05.491943 [error] [MainThread]:   Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:56:05.492103 [info ] [MainThread]: 
[0m15:56:05.492270 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:56:05.492413 [info ] [MainThread]: 
[0m15:56:05.492586 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=2
[0m15:56:05.495114 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9208033, "process_in_blocks": "0", "process_kernel_time": 0.203499, "process_mem_max_rss": "195756032", "process_out_blocks": "0", "process_user_time": 1.439168}
[0m15:56:05.495377 [debug] [MainThread]: Command `dbt run` failed at 15:56:05.495335 after 0.92 seconds
[0m15:56:05.495569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e3b470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e665a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10898a960>]}
[0m15:56:05.495756 [debug] [MainThread]: Flushing usage events
[0m15:56:06.138418 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:57:55.166662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acdcfb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3eff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3eff80>]}


============================== 15:57:55.169222 | 16b1a3f7-3786-4550-8dd7-1fd7ad2b30ae ==============================
[0m15:57:55.169222 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:57:55.169577 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'use_colors': 'True', 'log_format': 'default', 'no_print': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'target_path': 'None', 'version_check': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'partial_parse': 'True', 'printer_width': '80', 'fail_fast': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'debug': 'False', 'send_anonymous_usage_stats': 'True'}
[0m15:57:55.261897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '16b1a3f7-3786-4550-8dd7-1fd7ad2b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3d7fb0>]}
[0m15:57:55.293170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '16b1a3f7-3786-4550-8dd7-1fd7ad2b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b765a30>]}
[0m15:57:55.293761 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:57:55.364401 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:57:55.429093 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m15:57:55.429529 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_long.sql
[0m15:57:55.429752 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:57:55.558746 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m15:57:55.566360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16b1a3f7-3786-4550-8dd7-1fd7ad2b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b793470>]}
[0m15:57:55.615776 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:57:55.617270 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:57:55.625716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16b1a3f7-3786-4550-8dd7-1fd7ad2b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1e4bf0>]}
[0m15:57:55.626017 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:57:55.626215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '16b1a3f7-3786-4550-8dd7-1fd7ad2b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdc5cd0>]}
[0m15:57:55.627294 [info ] [MainThread]: 
[0m15:57:55.627524 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:57:55.627685 [info ] [MainThread]: 
[0m15:57:55.627974 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:57:55.631246 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:57:55.636596 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:55.981088 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:57:55.982999 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:57:55.990954 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m15:57:55.995027 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:57:55.997970 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:57:55.998800 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m15:57:55.999921 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:57:56.003154 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:57:56.004410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '16b1a3f7-3786-4550-8dd7-1fd7ad2b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b49a870>]}
[0m15:57:56.005751 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:57:56.006081 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m15:57:56.006344 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m15:57:56.006539 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:57:56.010928 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m15:57:56.011462 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:57:56.019236 [debug] [Thread-1 (]: Creating new relation key_ratios_quarterly_wide
[0m15:57:56.026983 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m15:57:56.027617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

WITH qf AS (
  SELECT *
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT
  qf.ticker,
  qf.fiscal_date,
  qf.currency,

  -- inputs we’ll reuse
  qf.total_revenue,
  qf.gross_profit,
  qf.operating_income,
  qf.net_income,
  qf.total_assets,
  qf.total_liab,
  qf.equity,
  qf.current_assets,
  qf.current_liab,
  qf.cash_and_equiv,
  qf.long_term_debt,
  qf.cfo,
  qf.capex,

  -- derived ratios (guard against div-by-zero)
  ifNull(qf.gross_profit / nullIf(qf.total_revenue, 0), 0)        AS gross_margin,
  ifNull(qf.operating_income / nullIf(qf.total_revenue, 0), 0)    AS operating_margin,
  ifNull(qf.net_income / nullIf(qf.total_revenue, 0), 0)          AS net_margin,

  ifNull(qf.current_assets / nullIf(qf.current_liab, 0), 0)       AS current_ratio,
  ifNull((qf.current_assets - qf.inventory) / nullIf(qf.current_liab, 0), 0) AS quick_ratio, -- inventory may be null; will resolve to 0
  ifNull(qf.total_liab / nullIf(qf.equity, 0), 0)                 AS debt_to_equity,

  -- cash metrics
  qf.cfo - qf.capex                                                AS fcf

FROM qf
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:57:56.030410 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

WITH qf AS (
  SELECT *
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT
  qf.ticker,
  qf.fiscal_date,
  qf.currency,

  -- inputs we’ll reuse
  qf.total_revenue,
  qf.gross_profit,
  qf.operating_income,
  qf.net_income,
  qf.total_assets,
  qf.total_liab,
  qf.equity,
  qf.current_assets,
  qf.current_liab,
  qf.cash_and_equiv,
  qf.long_term_debt,
  qf.cfo,
  qf.capex,

  -- derived ratios (guard against div-by-zero)
  ifNull(qf.gross_profit / nullIf(qf.total_revenue, 0), 0)        AS gross_margin,
  ifNull(qf.operating_income / nullIf(qf.total_revenue, 0), 0)    AS operating_margin,
  ifNull(qf.net_income / nullIf(qf.total_revenue, 0), 0)          AS net_margin,

  ifNull(qf.current_assets / nullIf(qf.current_liab, 0), 0)       AS current_ratio,
  ifNull((qf.current_assets - qf.inventory) / nullIf(qf.current_liab, 0), 0) AS quick_ratio, -- inventory may be null; will resolve to 0
  ifNull(qf.total_liab / nullIf(qf.equity, 0), 0)                 AS debt_to_equity,

  -- cash metrics
  qf.cfo - qf.capex                                                AS fcf

FROM qf
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:57:56.032690 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'qf.ticker' cannot be resolved from subquery with name qf. In scope WITH qf AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT qf.ticker, qf.fiscal_date, qf.currency, qf.total_revenue, qf.gross_profit, qf.operating_income, qf.net_income, qf.total_assets, qf.total_liab, qf.equity, qf.current_assets, qf.current_liab, qf.cash_and_equiv, qf.long_term_debt, qf.cfo, qf.capex, ifNull(qf.gross_profit / nullIf(qf.total_revenue, 0), 0) AS gross_margin, ifNull(qf.operating_income / nullIf(qf.total_revenue, 0), 0) AS operating_margin, ifNull(qf.net_income / nullIf(qf.total_revenue, 0), 0) AS net_margin, ifNull(qf.current_assets / nullIf(qf.current_liab, 0), 0) AS current_ratio, ifNull((qf.current_assets - qf.inventory) / nullIf(qf.current_liab, 0), 0) AS quick_ratio, ifNull(qf.total_liab / nullIf(qf.equity, 0), 0) AS debt_to_equity, qf.cfo - qf.capex AS fcf FROM qf. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:57:56.033533 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16b1a3f7-3786-4550-8dd7-1fd7ad2b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8a73b0>]}
[0m15:57:56.033891 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_wide`  [[31mERROR[0m in 0.03s]
[0m15:57:56.034239 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:57:56.034569 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_wide' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'qf.ticker' cannot be resolved from subquery with name qf. In scope WITH qf AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT qf.ticker, qf.fiscal_date, qf.currency, qf.total_revenue, qf.gross_profit, qf.operating_income, qf.net_income, qf.total_assets, qf.total_liab, qf.equity, qf.current_assets, qf.current_liab, qf.cash_and_equiv, qf.long_term_debt, qf.cfo, qf.capex, ifNull(qf.gross_profit / nullIf(qf.total_revenue, 0), 0) AS gross_margin, ifNull(qf.operating_income / nullIf(qf.total_revenue, 0), 0) AS operating_margin, ifNull(qf.net_income / nullIf(qf.total_revenue, 0), 0) AS net_margin, ifNull(qf.current_assets / nullIf(qf.current_liab, 0), 0) AS current_ratio, ifNull((qf.current_assets - qf.inventory) / nullIf(qf.current_liab, 0), 0) AS quick_ratio, ifNull(qf.total_liab / nullIf(qf.equity, 0), 0) AS debt_to_equity, qf.cfo - qf.capex AS fcf FROM qf. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql.
[0m15:57:56.035328 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m15:57:56.035584 [info ] [Thread-1 (]: 2 of 2 SKIP relation fundamentals.key_ratios_quarterly_long .................... [[33mSKIP[0m]
[0m15:57:56.035808 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m15:57:56.036349 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:57:56.036520 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_wide' was left open.
[0m15:57:56.036685 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_wide: Close
[0m15:57:56.036930 [info ] [MainThread]: 
[0m15:57:56.037097 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m15:57:56.037459 [debug] [MainThread]: Command end result
[0m15:57:56.056406 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:57:56.057649 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:57:56.060856 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:57:56.061051 [info ] [MainThread]: 
[0m15:57:56.061251 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:57:56.061410 [info ] [MainThread]: 
[0m15:57:56.061605 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)[0m
[0m15:57:56.061819 [error] [MainThread]:   Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'qf.ticker' cannot be resolved from subquery with name qf. In scope WITH qf AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT qf.ticker, qf.fiscal_date, qf.currency, qf.total_revenue, qf.gross_profit, qf.operating_income, qf.net_income, qf.total_assets, qf.total_liab, qf.equity, qf.current_assets, qf.current_liab, qf.cash_and_equiv, qf.long_term_debt, qf.cfo, qf.capex, ifNull(qf.gross_profit / nullIf(qf.total_revenue, 0), 0) AS gross_margin, ifNull(qf.operating_income / nullIf(qf.total_revenue, 0), 0) AS operating_margin, ifNull(qf.net_income / nullIf(qf.total_revenue, 0), 0) AS net_margin, ifNull(qf.current_assets / nullIf(qf.current_liab, 0), 0) AS current_ratio, ifNull((qf.current_assets - qf.inventory) / nullIf(qf.current_liab, 0), 0) AS quick_ratio, ifNull(qf.total_liab / nullIf(qf.equity, 0), 0) AS debt_to_equity, qf.cfo - qf.capex AS fcf FROM qf. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:57:56.062002 [info ] [MainThread]: 
[0m15:57:56.062173 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:57:56.062309 [info ] [MainThread]: 
[0m15:57:56.062473 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m15:57:56.064947 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9333087, "process_in_blocks": "0", "process_kernel_time": 0.218926, "process_mem_max_rss": "197427200", "process_out_blocks": "0", "process_user_time": 1.449528}
[0m15:57:56.065235 [debug] [MainThread]: Command `dbt run` failed at 15:57:56.065192 after 0.93 seconds
[0m15:57:56.065449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b08a6f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3efb00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db026c0>]}
[0m15:57:56.065644 [debug] [MainThread]: Flushing usage events
[0m15:57:56.617727 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:59:41.151940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105041430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120df3bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cd5280>]}


============================== 15:59:41.154830 | c6b2e5af-16dc-400d-9705-cd8e295b8dd6 ==============================
[0m15:59:41.154830 [info ] [MainThread]: Running with dbt=1.10.13
[0m15:59:41.155209 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_format': 'default', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'target_path': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'debug': 'False', 'empty': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'fail_fast': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_colors': 'True', 'quiet': 'False', 'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide+', 'indirect_selection': 'eager', 'warn_error': 'None'}
[0m15:59:41.249977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c6b2e5af-16dc-400d-9705-cd8e295b8dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120e243b0>]}
[0m15:59:41.281341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c6b2e5af-16dc-400d-9705-cd8e295b8dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120f66f90>]}
[0m15:59:41.281879 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m15:59:41.352820 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m15:59:41.418883 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m15:59:41.419325 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:59:41.419548 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_long.sql
[0m15:59:41.543797 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m15:59:41.550947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c6b2e5af-16dc-400d-9705-cd8e295b8dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1215dcfb0>]}
[0m15:59:41.600191 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:59:41.601532 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:59:41.609550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c6b2e5af-16dc-400d-9705-cd8e295b8dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1215dfda0>]}
[0m15:59:41.609832 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m15:59:41.610013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6b2e5af-16dc-400d-9705-cd8e295b8dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1213691c0>]}
[0m15:59:41.610918 [info ] [MainThread]: 
[0m15:59:41.611106 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:59:41.611256 [info ] [MainThread]: 
[0m15:59:41.611518 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:59:41.614273 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:59:41.619376 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:59:41.950914 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:59:41.952755 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:59:41.960965 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m15:59:41.965045 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m15:59:41.968157 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:59:41.969064 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m15:59:41.970650 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m15:59:41.973348 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:59:41.974547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6b2e5af-16dc-400d-9705-cd8e295b8dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1229e5400>]}
[0m15:59:41.975660 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:59:41.975940 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m15:59:41.976177 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m15:59:41.976366 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:59:41.980727 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m15:59:41.981233 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:59:41.989763 [debug] [Thread-1 (]: Creating new relation key_ratios_quarterly_wide
[0m15:59:41.997543 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m15:59:41.998223 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

-- Build ratios straight from the wide fundamentals view.
-- Avoid table aliases to sidestep ClickHouse column resolution issues.
SELECT
  ticker,
  fiscal_date,
  currency,

  -- inputs we’ll also expose
  total_revenue,
  gross_profit,
  operating_income,
  net_income,
  total_assets,
  total_liab,
  equity,
  current_assets,
  current_liab,
  cash_and_equiv,
  long_term_debt,
  cfo,
  capex,

  -- ratios (guard against div-by-zero)
  ifNull(gross_profit      / nullIf(total_revenue, 0), 0) AS gross_margin,
  ifNull(operating_income  / nullIf(total_revenue, 0), 0) AS operating_margin,
  ifNull(net_income        / nullIf(total_revenue, 0), 0) AS net_margin,

  ifNull(current_assets / nullIf(current_liab, 0), 0)     AS current_ratio,
  -- If you later add Inventory to the wide view, switch to (current_assets - inventory) / current_liab
  ifNull(current_assets / nullIf(current_liab, 0), 0)     AS quick_ratio,

  ifNull(total_liab / nullIf(equity, 0), 0)               AS debt_to_equity,

  -- cash metric
  cfo - capex                                              AS fcf
FROM `fundamentals`.`quarterly_fundamentals_wide`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:59:42.001420 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

-- Build ratios straight from the wide fundamentals view.
-- Avoid table aliases to sidestep ClickHouse column resolution issues.
SELECT
  ticker,
  fiscal_date,
  currency,

  -- inputs we’ll also expose
  total_revenue,
  gross_profit,
  operating_income,
  net_income,
  total_assets,
  total_liab,
  equity,
  current_assets,
  current_liab,
  cash_and_equiv,
  long_term_debt,
  cfo,
  capex,

  -- ratios (guard against div-by-zero)
  ifNull(gross_profit      / nullIf(total_revenue, 0), 0) AS gross_margin,
  ifNull(operating_income  / nullIf(total_revenue, 0), 0) AS operating_margin,
  ifNull(net_income        / nullIf(total_revenue, 0), 0) AS net_margin,

  ifNull(current_assets / nullIf(current_liab, 0), 0)     AS current_ratio,
  -- If you later add Inventory to the wide view, switch to (current_assets - inventory) / current_liab
  ifNull(current_assets / nullIf(current_liab, 0), 0)     AS quick_ratio,

  ifNull(total_liab / nullIf(equity, 0), 0)               AS debt_to_equity,

  -- cash metric
  cfo - capex                                              AS fcf
FROM `fundamentals`.`quarterly_fundamentals_wide`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:59:42.003991 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(current_assets / nullIf(current_liab, 0), 0) AS quick_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:59:42.004977 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6b2e5af-16dc-400d-9705-cd8e295b8dd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1487224e0>]}
[0m15:59:42.005386 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_wide`  [[31mERROR[0m in 0.03s]
[0m15:59:42.005724 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m15:59:42.006012 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_wide' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(current_assets / nullIf(current_liab, 0), 0) AS quick_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql.
[0m15:59:42.006828 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m15:59:42.007218 [info ] [Thread-1 (]: 2 of 2 SKIP relation fundamentals.key_ratios_quarterly_long .................... [[33mSKIP[0m]
[0m15:59:42.007511 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m15:59:42.008215 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:59:42.008459 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_wide' was left open.
[0m15:59:42.008639 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_wide: Close
[0m15:59:42.008926 [info ] [MainThread]: 
[0m15:59:42.009121 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.40 seconds (0.40s).
[0m15:59:42.009691 [debug] [MainThread]: Command end result
[0m15:59:42.029504 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m15:59:42.030864 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m15:59:42.034269 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m15:59:42.034490 [info ] [MainThread]: 
[0m15:59:42.034699 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:59:42.034870 [info ] [MainThread]: 
[0m15:59:42.035082 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)[0m
[0m15:59:42.035302 [error] [MainThread]:   Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(current_assets / nullIf(current_liab, 0), 0) AS quick_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:59:42.035509 [info ] [MainThread]: 
[0m15:59:42.035693 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m15:59:42.035840 [info ] [MainThread]: 
[0m15:59:42.036017 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m15:59:42.038666 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.92416763, "process_in_blocks": "0", "process_kernel_time": 0.217879, "process_mem_max_rss": "198230016", "process_out_blocks": "0", "process_user_time": 1.468075}
[0m15:59:42.038985 [debug] [MainThread]: Command `dbt run` failed at 15:59:42.038938 after 0.92 seconds
[0m15:59:42.039214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12299e120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120e9e6f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1215c6750>]}
[0m15:59:42.039419 [debug] [MainThread]: Flushing usage events
[0m15:59:42.641427 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:04:21.006837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ddcf20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135a0f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113624710>]}


============================== 16:04:21.009529 | 7d890ae6-9b07-4014-aa8e-68437a53721d ==============================
[0m16:04:21.009529 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:04:21.009878 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'target_path': 'None', 'cache_selected_only': 'False', 'quiet': 'False', 'partial_parse': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_cache_events': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'empty': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'write_json': 'True', 'version_check': 'True', 'no_print': 'None', 'printer_width': '80', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'use_experimental_parser': 'False', 'warn_error': 'None', 'indirect_selection': 'eager'}
[0m16:04:21.105386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7d890ae6-9b07-4014-aa8e-68437a53721d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112561700>]}
[0m16:04:21.137506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7d890ae6-9b07-4014-aa8e-68437a53721d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bec410>]}
[0m16:04:21.138116 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:04:21.207874 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:04:21.271687 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m16:04:21.272096 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:04:21.272316 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_long.sql
[0m16:04:21.399638 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m16:04:21.406908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d890ae6-9b07-4014-aa8e-68437a53721d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113edff20>]}
[0m16:04:21.456244 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:04:21.457638 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:04:21.465544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d890ae6-9b07-4014-aa8e-68437a53721d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b3aed0>]}
[0m16:04:21.465838 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m16:04:21.466031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d890ae6-9b07-4014-aa8e-68437a53721d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113edce60>]}
[0m16:04:21.467081 [info ] [MainThread]: 
[0m16:04:21.467298 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:04:21.467458 [info ] [MainThread]: 
[0m16:04:21.467730 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:04:21.470691 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:04:21.476156 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:04:21.818255 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:04:21.820086 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:04:21.828013 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__fundamentals)
[0m16:04:21.832069 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m16:04:21.835286 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:04:21.836219 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__fundamentals, now list__market)
[0m16:04:21.837775 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:04:21.840900 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:04:21.842034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d890ae6-9b07-4014-aa8e-68437a53721d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11489ca70>]}
[0m16:04:21.843159 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:04:21.843445 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m16:04:21.843686 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m16:04:21.843874 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:04:21.848104 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:04:21.848530 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:04:21.855982 [debug] [Thread-1 (]: Creating new relation key_ratios_quarterly_wide
[0m16:04:21.863727 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:04:21.864317 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  -- Pull the wide fundamentals into a scoped alias to avoid CH identifier quirks
  SELECT *
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT
  base.ticker,
  base.fiscal_date,
  base.currency,

  -- carry-through inputs
  base.total_revenue,
  base.gross_profit,
  base.operating_income,
  base.net_income,
  base.total_assets,
  base.total_liab,
  base.equity,
  base.current_assets,
  base.current_liab,
  base.cash_and_equiv,
  base.long_term_debt,
  base.cfo,
  base.capex,

  -- ratios (guard against div-by-zero)
  ifNull(base.gross_profit     / nullIf(base.total_revenue, 0), 0) AS gross_margin,
  ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin,
  ifNull(base.net_income       / nullIf(base.total_revenue, 0), 0) AS net_margin,

  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS current_ratio,
  -- Update to (current_assets - inventory) / current_liab once you add `inventory` to the wide view
  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS quick_ratio,

  ifNull(base.total_liab / nullIf(base.equity, 0), 0)              AS debt_to_equity,

  -- cash metric
  base.cfo - base.capex                                            AS fcf
FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:04:21.867228 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  -- Pull the wide fundamentals into a scoped alias to avoid CH identifier quirks
  SELECT *
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT
  base.ticker,
  base.fiscal_date,
  base.currency,

  -- carry-through inputs
  base.total_revenue,
  base.gross_profit,
  base.operating_income,
  base.net_income,
  base.total_assets,
  base.total_liab,
  base.equity,
  base.current_assets,
  base.current_liab,
  base.cash_and_equiv,
  base.long_term_debt,
  base.cfo,
  base.capex,

  -- ratios (guard against div-by-zero)
  ifNull(base.gross_profit     / nullIf(base.total_revenue, 0), 0) AS gross_margin,
  ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin,
  ifNull(base.net_income       / nullIf(base.total_revenue, 0), 0) AS net_margin,

  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS current_ratio,
  -- Update to (current_assets - inventory) / current_liab once you add `inventory` to the wide view
  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS quick_ratio,

  ifNull(base.total_liab / nullIf(base.equity, 0), 0)              AS debt_to_equity,

  -- cash metric
  base.cfo - base.capex                                            AS fcf
FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m16:04:21.869722 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'base.ticker' cannot be resolved from subquery with name base. In scope WITH base AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT base.ticker, base.fiscal_date, base.currency, base.total_revenue, base.gross_profit, base.operating_income, base.net_income, base.total_assets, base.total_liab, base.equity, base.current_assets, base.current_liab, base.cash_and_equiv, base.long_term_debt, base.cfo, base.capex, ifNull(base.gross_profit / nullIf(base.total_revenue, 0), 0) AS gross_margin, ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin, ifNull(base.net_income / nullIf(base.total_revenue, 0), 0) AS net_margin, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS current_ratio, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS quick_ratio, ifNull(base.total_liab / nullIf(base.equity, 0), 0) AS debt_to_equity, base.cfo - base.capex AS fcf FROM base. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:04:21.870678 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d890ae6-9b07-4014-aa8e-68437a53721d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122952360>]}
[0m16:04:21.871046 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_wide`  [[31mERROR[0m in 0.03s]
[0m16:04:21.871407 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:04:21.871696 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_wide' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'base.ticker' cannot be resolved from subquery with name base. In scope WITH base AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT base.ticker, base.fiscal_date, base.currency, base.total_revenue, base.gross_profit, base.operating_income, base.net_income, base.total_assets, base.total_liab, base.equity, base.current_assets, base.current_liab, base.cash_and_equiv, base.long_term_debt, base.cfo, base.capex, ifNull(base.gross_profit / nullIf(base.total_revenue, 0), 0) AS gross_margin, ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin, ifNull(base.net_income / nullIf(base.total_revenue, 0), 0) AS net_margin, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS current_ratio, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS quick_ratio, ifNull(base.total_liab / nullIf(base.equity, 0), 0) AS debt_to_equity, base.cfo - base.capex AS fcf FROM base. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql.
[0m16:04:21.872396 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:04:21.872683 [info ] [Thread-1 (]: 2 of 2 SKIP relation fundamentals.key_ratios_quarterly_long .................... [[33mSKIP[0m]
[0m16:04:21.872941 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:04:21.873462 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:04:21.873635 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_wide' was left open.
[0m16:04:21.873790 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_wide: Close
[0m16:04:21.874018 [info ] [MainThread]: 
[0m16:04:21.874185 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m16:04:21.874548 [debug] [MainThread]: Command end result
[0m16:04:21.893107 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:04:21.894271 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:04:21.897255 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:04:21.897438 [info ] [MainThread]: 
[0m16:04:21.897626 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:04:21.897780 [info ] [MainThread]: 
[0m16:04:21.897974 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)[0m
[0m16:04:21.898186 [error] [MainThread]:   Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'base.ticker' cannot be resolved from subquery with name base. In scope WITH base AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT base.ticker, base.fiscal_date, base.currency, base.total_revenue, base.gross_profit, base.operating_income, base.net_income, base.total_assets, base.total_liab, base.equity, base.current_assets, base.current_liab, base.cash_and_equiv, base.long_term_debt, base.cfo, base.capex, ifNull(base.gross_profit / nullIf(base.total_revenue, 0), 0) AS gross_margin, ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin, ifNull(base.net_income / nullIf(base.total_revenue, 0), 0) AS net_margin, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS current_ratio, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS quick_ratio, ifNull(base.total_liab / nullIf(base.equity, 0), 0) AS debt_to_equity, base.cfo - base.capex AS fcf FROM base. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:04:21.898503 [info ] [MainThread]: 
[0m16:04:21.898763 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:04:21.898944 [info ] [MainThread]: 
[0m16:04:21.899131 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m16:04:21.901526 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9332274, "process_in_blocks": "0", "process_kernel_time": 0.211536, "process_mem_max_rss": "197476352", "process_out_blocks": "0", "process_user_time": 1.457638}
[0m16:04:21.901816 [debug] [MainThread]: Command `dbt run` failed at 16:04:21.901774 after 0.93 seconds
[0m16:04:21.902016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133e02c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d471d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130cea20>]}
[0m16:04:21.902220 [debug] [MainThread]: Flushing usage events
[0m16:04:22.512231 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:08:06.422588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112289ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123e55e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116f34a0>]}


============================== 16:08:06.425079 | b0b9f168-d650-4c7d-9062-fcbd073ca6a0 ==============================
[0m16:08:06.425079 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:08:06.425418 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'target_path': 'None', 'fail_fast': 'False', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_wide', 'use_experimental_parser': 'False', 'static_parser': 'True', 'debug': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'quiet': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'empty': 'False', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'introspect': 'True', 'partial_parse': 'True', 'log_cache_events': 'False', 'printer_width': '80', 'log_format': 'default', 'write_json': 'True', 'warn_error': 'None'}
[0m16:08:06.515646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b0b9f168-d650-4c7d-9062-fcbd073ca6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113df470>]}
[0m16:08:06.547430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b0b9f168-d650-4c7d-9062-fcbd073ca6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112534560>]}
[0m16:08:06.548015 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:08:06.616923 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:08:06.679692 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:08:06.680092 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_wide.sql
[0m16:08:06.869295 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m16:08:06.876406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b0b9f168-d650-4c7d-9062-fcbd073ca6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ff9fa0>]}
[0m16:08:06.956753 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:08:06.957837 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:08:06.966089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b0b9f168-d650-4c7d-9062-fcbd073ca6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e73b30>]}
[0m16:08:06.966397 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m16:08:06.966594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0b9f168-d650-4c7d-9062-fcbd073ca6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112fa4650>]}
[0m16:08:06.967497 [info ] [MainThread]: 
[0m16:08:06.967702 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:08:06.967857 [info ] [MainThread]: 
[0m16:08:06.968118 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:08:06.968592 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:08:06.974038 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:08:07.283048 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:08:07.284895 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:08:07.295445 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__fundamentals)
[0m16:08:07.298870 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m16:08:07.304310 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:08:07.305194 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__fundamentals, now list__market)
[0m16:08:07.307136 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:08:07.309899 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:08:07.311112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0b9f168-d650-4c7d-9062-fcbd073ca6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117a474a0>]}
[0m16:08:07.312256 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:08:07.312540 [info ] [Thread-1 (]: 1 of 1 START sql view model `fundamentals`.`quarterly_fundamentals_wide` ....... [RUN]
[0m16:08:07.312777 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.quarterly_fundamentals_wide)
[0m16:08:07.312957 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:08:07.317162 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m16:08:07.317595 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:08:07.326071 [debug] [Thread-1 (]: Relation quarterly_fundamentals_wide already exists, replacing it
[0m16:08:07.366170 [debug] [Thread-1 (]: Model mvs to replace ['quarterly_fundamentals_wide_mv']
[0m16:08:07.367525 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.quarterly_fundamentals_wide'
  
  ...
[0m16:08:07.374343 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:08:07.382805 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m16:08:07.383426 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    anyLast(currency) AS currency
  FROM fundamentals.income_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

inc AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalRevenue')        AS total_revenue,
    maxIf(value, metric = 'CostOfRevenue')       AS cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')         AS gross_profit,
    maxIf(value, metric = 'OperatingIncome')     AS operating_income,
    maxIf(value, metric = 'NetIncome')           AS net_income
  FROM fundamentals.income_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

bs AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                 AS total_assets,
    maxIf(value, metric = 'TotalLiab')                   AS total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')      AS equity,
    maxIf(value, metric = 'TotalCurrentAssets')          AS current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')     AS current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')      AS cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')                AS long_term_debt
  FROM fundamentals.balance_sheet
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

cf AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') AS cfo,
    maxIf(value, metric = 'CapitalExpenditures')              AS capex,
    maxIf(value, metric = 'Depreciation')                     AS depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  AS issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    AS dividends_paid
  FROM fundamentals.cashflow_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
)

SELECT
  b.ticker            AS ticker,
  b.fiscal_date       AS fiscal_date,
  b.currency          AS currency,
  -- income
  inc.total_revenue   AS total_revenue,
  inc.cost_of_revenue AS cost_of_revenue,
  inc.gross_profit    AS gross_profit,
  inc.operating_income AS operating_income,
  inc.net_income      AS net_income,
  -- balance
  bs.total_assets     AS total_assets,
  bs.total_liab       AS total_liab,
  bs.equity           AS equity,
  bs.current_assets   AS current_assets,
  bs.current_liab     AS current_liab,
  bs.cash_and_equiv   AS cash_and_equiv,
  bs.long_term_debt   AS long_term_debt,
  -- cashflow
  cf.cfo              AS cfo,
  cf.capex            AS capex,
  cf.depreciation     AS depreciation,
  cf.issuance_of_stock AS issuance_of_stock,
  cf.dividends_paid   AS dividends_paid
FROM base b
LEFT JOIN inc ON (b.ticker = inc.ticker AND b.fiscal_date = inc.fiscal_date)
LEFT JOIN bs  ON (b.ticker = bs.ticker  AND b.fiscal_date = bs.fiscal_date)
LEFT JOIN cf  ON (b.ticker = cf.ticker  AND b.fiscal_date = cf.fiscal_date)
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:08:07.394235 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:08:07.406342 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b9f168-d650-4c7d-9062-fcbd073ca6a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054c3740>]}
[0m16:08:07.406745 [info ] [Thread-1 (]: 1 of 1 OK created sql view model `fundamentals`.`quarterly_fundamentals_wide` .. [[32mOK[0m in 0.09s]
[0m16:08:07.407056 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:08:07.407730 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:08:07.407896 [debug] [MainThread]: Connection 'model.qi_dbt_project.quarterly_fundamentals_wide' was left open.
[0m16:08:07.408046 [debug] [MainThread]: On model.qi_dbt_project.quarterly_fundamentals_wide: Close
[0m16:08:07.408256 [info ] [MainThread]: 
[0m16:08:07.408426 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.44 seconds (0.44s).
[0m16:08:07.408745 [debug] [MainThread]: Command end result
[0m16:08:07.426798 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:08:07.428114 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:08:07.431251 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:08:07.431455 [info ] [MainThread]: 
[0m16:08:07.431674 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:08:07.431840 [info ] [MainThread]: 
[0m16:08:07.432026 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m16:08:07.434579 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0480459, "process_in_blocks": "0", "process_kernel_time": 0.210642, "process_mem_max_rss": "196050944", "process_out_blocks": "0", "process_user_time": 1.553173}
[0m16:08:07.434857 [debug] [MainThread]: Command `dbt run` succeeded at 16:08:07.434811 after 1.05 seconds
[0m16:08:07.435063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125243b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fc5a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110230e60>]}
[0m16:08:07.435263 [debug] [MainThread]: Flushing usage events
[0m16:08:08.055498 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:09:03.629585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100da8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110115fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101160c0>]}


============================== 16:09:03.632024 | f651fe43-3bab-4d47-834e-f2b9f90c4be8 ==============================
[0m16:09:03.632024 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:09:03.632360 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'printer_width': '80', 'quiet': 'False', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'write_json': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'empty': 'False', 'static_parser': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'introspect': 'True', 'warn_error': 'None', 'target_path': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m16:09:03.723592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f651fe43-3bab-4d47-834e-f2b9f90c4be8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111ee0f0>]}
[0m16:09:03.754616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f651fe43-3bab-4d47-834e-f2b9f90c4be8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dd5a00>]}
[0m16:09:03.755191 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:09:03.823852 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:09:03.885822 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:09:03.886119 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:09:03.889562 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m16:09:03.910948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f651fe43-3bab-4d47-834e-f2b9f90c4be8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11158f470>]}
[0m16:09:03.960914 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:09:03.962159 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:09:03.970011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f651fe43-3bab-4d47-834e-f2b9f90c4be8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118c07a0>]}
[0m16:09:03.970280 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m16:09:03.970467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f651fe43-3bab-4d47-834e-f2b9f90c4be8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111911340>]}
[0m16:09:03.971460 [info ] [MainThread]: 
[0m16:09:03.971649 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:09:03.971794 [info ] [MainThread]: 
[0m16:09:03.972047 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:09:03.974789 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:09:03.980975 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:09:04.311376 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:09:04.313249 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:09:04.321475 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__fundamentals)
[0m16:09:04.325631 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m16:09:04.328750 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:09:04.329731 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__fundamentals, now list__market)
[0m16:09:04.331542 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:09:04.334425 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:09:04.335732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f651fe43-3bab-4d47-834e-f2b9f90c4be8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1201feb40>]}
[0m16:09:04.337046 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:09:04.337333 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m16:09:04.337588 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m16:09:04.337786 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:09:04.342267 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:09:04.342793 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:09:04.350421 [debug] [Thread-1 (]: Creating new relation key_ratios_quarterly_wide
[0m16:09:04.357890 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:09:04.358523 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  -- Pull the wide fundamentals into a scoped alias to avoid CH identifier quirks
  SELECT *
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT
  base.ticker,
  base.fiscal_date,
  base.currency,

  -- carry-through inputs
  base.total_revenue,
  base.gross_profit,
  base.operating_income,
  base.net_income,
  base.total_assets,
  base.total_liab,
  base.equity,
  base.current_assets,
  base.current_liab,
  base.cash_and_equiv,
  base.long_term_debt,
  base.cfo,
  base.capex,

  -- ratios (guard against div-by-zero)
  ifNull(base.gross_profit     / nullIf(base.total_revenue, 0), 0) AS gross_margin,
  ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin,
  ifNull(base.net_income       / nullIf(base.total_revenue, 0), 0) AS net_margin,

  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS current_ratio,
  -- Update to (current_assets - inventory) / current_liab once you add `inventory` to the wide view
  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS quick_ratio,

  ifNull(base.total_liab / nullIf(base.equity, 0), 0)              AS debt_to_equity,

  -- cash metric
  base.cfo - base.capex                                            AS fcf
FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:09:04.364583 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:09:04.375857 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f651fe43-3bab-4d47-834e-f2b9f90c4be8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11158e2d0>]}
[0m16:09:04.376273 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `fundamentals`.`key_ratios_quarterly_wide` .... [[32mOK[0m in 0.04s]
[0m16:09:04.376608 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:09:04.376990 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:09:04.377278 [info ] [Thread-1 (]: 2 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_long` ......... [RUN]
[0m16:09:04.377581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.key_ratios_quarterly_wide, now model.qi_dbt_project.key_ratios_quarterly_long)
[0m16:09:04.377798 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:09:04.379497 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:09:04.379979 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:09:04.381179 [debug] [Thread-1 (]: Creating new relation key_ratios_quarterly_long
[0m16:09:04.381592 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:09:04.381964 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT *
  FROM `fundamentals`.`key_ratios_quarterly_wide`
)
SELECT ticker, fiscal_date, 'gross_margin'     AS ratio, gross_margin     AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'operating_margin' AS ratio, operating_margin AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'net_margin'       AS ratio, net_margin       AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'current_ratio'    AS ratio, current_ratio    AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'quick_ratio'      AS ratio, quick_ratio      AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'debt_to_equity'   AS ratio, debt_to_equity   AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'fcf'              AS ratio, fcf              AS value FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:09:04.389627 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:09:04.390802 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f651fe43-3bab-4d47-834e-f2b9f90c4be8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a5faa0>]}
[0m16:09:04.391142 [info ] [Thread-1 (]: 2 of 2 OK created sql view model `fundamentals`.`key_ratios_quarterly_long` .... [[32mOK[0m in 0.01s]
[0m16:09:04.391440 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:09:04.392164 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:09:04.392370 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_long' was left open.
[0m16:09:04.392547 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_long: Close
[0m16:09:04.392795 [info ] [MainThread]: 
[0m16:09:04.392973 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.42 seconds (0.42s).
[0m16:09:04.393361 [debug] [MainThread]: Command end result
[0m16:09:04.412899 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:09:04.414302 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:09:04.417723 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:09:04.417934 [info ] [MainThread]: 
[0m16:09:04.418132 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:09:04.418286 [info ] [MainThread]: 
[0m16:09:04.418452 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m16:09:04.420793 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.825985, "process_in_blocks": "0", "process_kernel_time": 0.204665, "process_mem_max_rss": "191217664", "process_out_blocks": "0", "process_user_time": 1.340668}
[0m16:09:04.421051 [debug] [MainThread]: Command `dbt run` succeeded at 16:09:04.421005 after 0.83 seconds
[0m16:09:04.421261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119136b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c02990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11518bce0>]}
[0m16:09:04.421451 [debug] [MainThread]: Flushing usage events
[0m16:09:04.873314 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:15:01.294642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ed13a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aff3d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1242c0>]}


============================== 16:15:01.297151 | 7a1e7596-bd1a-4e38-a744-78b3ec8869d0 ==============================
[0m16:15:01.297151 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:15:01.297493 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'write_json': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'use_colors': 'True', 'empty': 'False', 'printer_width': '80', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_wide fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'warn_error': 'None', 'no_print': 'None', 'log_cache_events': 'False', 'partial_parse': 'True', 'version_check': 'True', 'target_path': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'quiet': 'False'}
[0m16:15:01.387906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065a04d0>]}
[0m16:15:01.417759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abf98b0>]}
[0m16:15:01.418235 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:15:01.486905 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:15:01.548903 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:15:01.549315 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_wide.sql
[0m16:15:01.742854 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m16:15:01.750507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb58bf0>]}
[0m16:15:01.827662 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:15:01.828717 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:15:01.836318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba8a000>]}
[0m16:15:01.836596 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m16:15:01.836784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbebd40>]}
[0m16:15:01.837823 [info ] [MainThread]: 
[0m16:15:01.838009 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:15:01.838159 [info ] [MainThread]: 
[0m16:15:01.838399 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:15:01.841187 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:15:01.846653 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:15:02.160887 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:15:02.162830 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:15:02.171132 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m16:15:02.174857 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:15:02.178022 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:15:02.178972 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m16:15:02.180563 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m16:15:02.183261 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:15:02.184787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1187c98b0>]}
[0m16:15:02.186144 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:15:02.186442 [info ] [Thread-1 (]: 1 of 3 START sql view model `fundamentals`.`quarterly_fundamentals_wide` ....... [RUN]
[0m16:15:02.186691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.quarterly_fundamentals_wide)
[0m16:15:02.186884 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:15:02.191326 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m16:15:02.191789 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:15:02.200539 [debug] [Thread-1 (]: Relation quarterly_fundamentals_wide already exists, replacing it
[0m16:15:02.206510 [debug] [Thread-1 (]: Model mvs to replace ['quarterly_fundamentals_wide_mv']
[0m16:15:02.207747 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.quarterly_fundamentals_wide'
  
  ...
[0m16:15:02.210704 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:15:02.253677 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m16:15:02.254404 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    anyLast(currency) AS currency
  FROM fundamentals.income_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

inc AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(toNullable(value), metric = 'TotalRevenue') AS total_revenue,
    maxIf(value, metric = 'CostOfRevenue')       AS cost_of_revenue,
    maxIf(value, metric = 'GrossProfit')         AS gross_profit,
    maxIf(value, metric = 'OperatingIncome')     AS operating_income,
    maxIf(value, metric = 'NetIncome')           AS net_income
  FROM fundamentals.income_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

bs AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalAssets')                 AS total_assets,
    maxIf(value, metric = 'TotalLiab')                   AS total_liab,
    maxIf(value, metric = 'TotalStockholderEquity')      AS equity,
    maxIf(value, metric = 'TotalCurrentAssets')          AS current_assets,
    maxIf(value, metric = 'TotalCurrentLiabilities')     AS current_liab,
    maxIf(value, metric = 'CashAndCashEquivalents')      AS cash_and_equiv,
    maxIf(value, metric = 'LongTermDebt')                AS long_term_debt
  FROM fundamentals.balance_sheet
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

cf AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(value, metric = 'TotalCashFromOperatingActivities') AS cfo,
    maxIf(value, metric = 'CapitalExpenditures')              AS capex,
    maxIf(value, metric = 'Depreciation')                     AS depreciation,
    maxIf(value, metric = 'IssuanceOfStock')                  AS issuance_of_stock,
    maxIf(value, metric = 'DividendsPaid')                    AS dividends_paid
  FROM fundamentals.cashflow_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
)

SELECT
  b.ticker            AS ticker,
  b.fiscal_date       AS fiscal_date,
  b.currency          AS currency,
  -- income
  inc.total_revenue   AS total_revenue,
  inc.cost_of_revenue AS cost_of_revenue,
  inc.gross_profit    AS gross_profit,
  inc.operating_income AS operating_income,
  inc.net_income      AS net_income,
  -- balance
  bs.total_assets     AS total_assets,
  bs.total_liab       AS total_liab,
  bs.equity           AS equity,
  bs.current_assets   AS current_assets,
  bs.current_liab     AS current_liab,
  bs.cash_and_equiv   AS cash_and_equiv,
  bs.long_term_debt   AS long_term_debt,
  -- cashflow
  cf.cfo              AS cfo,
  cf.capex            AS capex,
  cf.depreciation     AS depreciation,
  cf.issuance_of_stock AS issuance_of_stock,
  cf.dividends_paid   AS dividends_paid
FROM base b
LEFT JOIN inc ON (b.ticker = inc.ticker AND b.fiscal_date = inc.fiscal_date)
LEFT JOIN bs  ON (b.ticker = bs.ticker  AND b.fiscal_date = bs.fiscal_date)
LEFT JOIN cf  ON (b.ticker = cf.ticker  AND b.fiscal_date = cf.fiscal_date)
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:15:02.263890 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:15:02.275735 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b1c70>]}
[0m16:15:02.276113 [info ] [Thread-1 (]: 1 of 3 OK created sql view model `fundamentals`.`quarterly_fundamentals_wide` .. [[32mOK[0m in 0.09s]
[0m16:15:02.276409 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:15:02.276969 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:15:02.277312 [info ] [Thread-1 (]: 2 of 3 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m16:15:02.277566 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_fundamentals_wide, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m16:15:02.277760 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:15:02.279658 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:15:02.280147 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:15:02.281362 [debug] [Thread-1 (]: Relation key_ratios_quarterly_wide already exists, replacing it
[0m16:15:02.281597 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_wide_mv']
[0m16:15:02.281838 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_wide'
  
  ...
[0m16:15:02.286099 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:15:02.287269 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:15:02.287833 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  -- Pull the wide fundamentals into a scoped alias to avoid CH identifier quirks
  SELECT *
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT
  base.ticker,
  base.fiscal_date,
  base.currency,

  -- carry-through inputs
  base.total_revenue,
  base.gross_profit,
  base.operating_income,
  base.net_income,
  base.total_assets,
  base.total_liab,
  base.equity,
  base.current_assets,
  base.current_liab,
  base.cash_and_equiv,
  base.long_term_debt,
  base.cfo,
  base.capex,

  -- ratios (guard against div-by-zero)
  ifNull(base.gross_profit     / nullIf(base.total_revenue, 0), 0) AS gross_margin,
  ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin,
  ifNull(base.net_income       / nullIf(base.total_revenue, 0), 0) AS net_margin,

  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS current_ratio,
  -- Update to (current_assets - inventory) / current_liab once you add `inventory` to the wide view
  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS quick_ratio,

  ifNull(base.total_liab / nullIf(base.equity, 0), 0)              AS debt_to_equity,

  -- cash metric
  base.cfo - base.capex                                            AS fcf
FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:15:02.292316 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:15:02.293449 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083d74a0>]}
[0m16:15:02.293810 [info ] [Thread-1 (]: 2 of 3 OK created sql view model `fundamentals`.`key_ratios_quarterly_wide` .... [[32mOK[0m in 0.02s]
[0m16:15:02.294120 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:15:02.294492 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:15:02.294779 [info ] [Thread-1 (]: 3 of 3 START sql view model `fundamentals`.`key_ratios_quarterly_long` ......... [RUN]
[0m16:15:02.295019 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.key_ratios_quarterly_wide, now model.qi_dbt_project.key_ratios_quarterly_long)
[0m16:15:02.295210 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:15:02.297158 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:15:02.297617 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:15:02.298870 [debug] [Thread-1 (]: Relation key_ratios_quarterly_long already exists, replacing it
[0m16:15:02.299104 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_long_mv']
[0m16:15:02.299355 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_long'
  
  ...
[0m16:15:02.302246 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:15:02.303420 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:15:02.304031 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT *
  FROM `fundamentals`.`key_ratios_quarterly_wide`
)
SELECT ticker, fiscal_date, 'gross_margin'     AS ratio, gross_margin     AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'operating_margin' AS ratio, operating_margin AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'net_margin'       AS ratio, net_margin       AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'current_ratio'    AS ratio, current_ratio    AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'quick_ratio'      AS ratio, quick_ratio      AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'debt_to_equity'   AS ratio, debt_to_equity   AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, 'fcf'              AS ratio, fcf              AS value FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:15:02.308846 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:15:02.310008 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a1e7596-bd1a-4e38-a744-78b3ec8869d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab70980>]}
[0m16:15:02.310374 [info ] [Thread-1 (]: 3 of 3 OK created sql view model `fundamentals`.`key_ratios_quarterly_long` .... [[32mOK[0m in 0.01s]
[0m16:15:02.310678 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:15:02.311271 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:15:02.311467 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_long' was left open.
[0m16:15:02.311633 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_long: Close
[0m16:15:02.311883 [info ] [MainThread]: 
[0m16:15:02.312056 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 0.47 seconds (0.47s).
[0m16:15:02.312498 [debug] [MainThread]: Command end result
[0m16:15:02.331965 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:15:02.333152 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:15:02.336234 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:15:02.336414 [info ] [MainThread]: 
[0m16:15:02.336610 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:15:02.336761 [info ] [MainThread]: 
[0m16:15:02.336931 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m16:15:02.339312 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0797856, "process_in_blocks": "0", "process_kernel_time": 0.211879, "process_mem_max_rss": "197591040", "process_out_blocks": "0", "process_user_time": 1.577846}
[0m16:15:02.339554 [debug] [MainThread]: Command `dbt run` succeeded at 16:15:02.339513 after 1.08 seconds
[0m16:15:02.339740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b124620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11acbafc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad30f20>]}
[0m16:15:02.339920 [debug] [MainThread]: Flushing usage events
[0m16:15:02.990649 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:20:38.661696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a3d730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143248c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143242c0>]}


============================== 16:20:38.664134 | 8ca67623-73cb-4801-ad8c-66b26bb5add4 ==============================
[0m16:20:38.664134 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:20:38.664471 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_wide fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'log_cache_events': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'debug': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None', 'log_format': 'default', 'cache_selected_only': 'False', 'partial_parse': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'write_json': 'True', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'version_check': 'True'}
[0m16:20:38.756506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8ca67623-73cb-4801-ad8c-66b26bb5add4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143272f0>]}
[0m16:20:38.786703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8ca67623-73cb-4801-ad8c-66b26bb5add4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bdcf80>]}
[0m16:20:38.787185 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:20:38.856357 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:20:38.918993 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:20:38.919405 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_wide.sql
[0m16:20:39.109266 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m16:20:39.116677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8ca67623-73cb-4801-ad8c-66b26bb5add4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114dae7b0>]}
[0m16:20:39.194638 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:20:39.195773 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:20:39.203365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8ca67623-73cb-4801-ad8c-66b26bb5add4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e841a0>]}
[0m16:20:39.203627 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m16:20:39.203810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ca67623-73cb-4801-ad8c-66b26bb5add4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114ffa540>]}
[0m16:20:39.204848 [info ] [MainThread]: 
[0m16:20:39.205033 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:20:39.205187 [info ] [MainThread]: 
[0m16:20:39.205436 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:20:39.208182 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:20:39.214059 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:20:39.521413 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:20:39.523345 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:20:39.531660 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m16:20:39.535277 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:20:39.538352 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:20:39.539284 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m16:20:39.540877 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m16:20:39.543564 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:20:39.544875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8ca67623-73cb-4801-ad8c-66b26bb5add4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1154a3d10>]}
[0m16:20:39.546065 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:20:39.546349 [info ] [Thread-1 (]: 1 of 3 START sql view model `fundamentals`.`quarterly_fundamentals_wide` ....... [RUN]
[0m16:20:39.546588 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.quarterly_fundamentals_wide)
[0m16:20:39.546775 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:20:39.551261 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m16:20:39.551822 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:20:39.560413 [debug] [Thread-1 (]: Relation quarterly_fundamentals_wide already exists, replacing it
[0m16:20:39.566575 [debug] [Thread-1 (]: Model mvs to replace ['quarterly_fundamentals_wide_mv']
[0m16:20:39.567964 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.quarterly_fundamentals_wide'
  
  ...
[0m16:20:39.571050 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:20:39.611965 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m16:20:39.612690 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    anyLast(currency) AS currency
  FROM fundamentals.income_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

inc AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(toNullable(value), metric = 'Total Revenue')      AS total_revenue,
    maxIf(toNullable(value), metric = 'Cost Of Revenue')    AS cost_of_revenue,
    maxIf(toNullable(value), metric = 'Gross Profit')       AS gross_profit,
    maxIf(toNullable(value), metric = 'Operating Income')   AS operating_income,
    maxIf(toNullable(value), metric = 'Net Income')         AS net_income
  FROM fundamentals.income_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

bs AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(toNullable(value), metric = 'Total Assets')                 AS total_assets,
    maxIf(toNullable(value), metric = 'Total Liab')                   AS total_liab,
    maxIf(toNullable(value), metric = 'Total Stockholder Equity')     AS equity,
    maxIf(toNullable(value), metric = 'Total Current Assets')         AS current_assets,
    maxIf(toNullable(value), metric = 'Total Current Liabilities')    AS current_liab,
    maxIf(toNullable(value), metric = 'Cash And Cash Equivalents')    AS cash_and_equiv,
    maxIf(toNullable(value), metric = 'Long Term Debt')               AS long_term_debt
  FROM fundamentals.balance_sheet
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
),

cf AS (
  SELECT
    ticker,
    fiscal_date,
    maxIf(toNullable(value), metric = 'Total Cash From Operating Activities') AS cfo,
    maxIf(toNullable(value), metric = 'Capital Expenditures')                 AS capex,
    maxIf(toNullable(value), metric = 'Depreciation')                         AS depreciation,
    maxIf(toNullable(value), metric = 'Issuance Of Stock')                    AS issuance_of_stock,
    maxIf(toNullable(value), metric = 'Dividends Paid')                       AS dividends_paid
  FROM fundamentals.cashflow_statement
  WHERE period = 'Q' AND source = 'yfinance'
  GROUP BY ticker, fiscal_date
)

SELECT
  b.ticker,
  b.fiscal_date,
  b.currency,
  -- income
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  -- balance
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  -- cashflow
  cf.cfo,
  cf.capex,
  cf.depreciation,
  cf.issuance_of_stock,
  cf.dividends_paid
FROM base b
LEFT JOIN inc ON (b.ticker = inc.ticker AND b.fiscal_date = inc.fiscal_date)
LEFT JOIN bs  ON (b.ticker = bs.ticker  AND b.fiscal_date = bs.fiscal_date)
LEFT JOIN cf  ON (b.ticker = cf.ticker  AND b.fiscal_date = cf.fiscal_date)
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:20:39.622779 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:20:39.634698 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ca67623-73cb-4801-ad8c-66b26bb5add4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fb1e20>]}
[0m16:20:39.635081 [info ] [Thread-1 (]: 1 of 3 OK created sql view model `fundamentals`.`quarterly_fundamentals_wide` .. [[32mOK[0m in 0.09s]
[0m16:20:39.635387 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:20:39.635731 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:20:39.636057 [info ] [Thread-1 (]: 2 of 3 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m16:20:39.636330 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_fundamentals_wide, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m16:20:39.636531 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:20:39.638306 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:20:39.638748 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:20:39.640008 [debug] [Thread-1 (]: Relation key_ratios_quarterly_wide already exists, replacing it
[0m16:20:39.640237 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_wide_mv']
[0m16:20:39.640482 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_wide'
  
  ...
[0m16:20:39.643714 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:20:39.644720 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:20:39.645195 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  -- Pull the wide fundamentals into a scoped alias to avoid CH identifier quirks
  SELECT *
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT
  base.ticker,
  base.fiscal_date,
  base.currency,

  -- carry-through inputs
  base.total_revenue,
  base.gross_profit,
  base.operating_income,
  base.net_income,
  base.total_assets,
  base.total_liab,
  base.equity,
  base.current_assets,
  base.current_liab,
  base.cash_and_equiv,
  base.long_term_debt,
  base.cfo,
  base.capex,

  -- ratios (guard against div-by-zero)
  ifNull(base.gross_profit     / nullIf(base.total_revenue, 0), 0) AS gross_margin,
  ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin,
  ifNull(base.net_income       / nullIf(base.total_revenue, 0), 0) AS net_margin,

  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS current_ratio,
  -- Update to (current_assets - inventory) / current_liab once you add `inventory` to the wide view
  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS quick_ratio,

  ifNull(base.total_liab / nullIf(base.equity, 0), 0)              AS debt_to_equity,

  -- cash metric
  base.cfo - base.capex                                            AS fcf
FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:20:39.647613 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  -- Pull the wide fundamentals into a scoped alias to avoid CH identifier quirks
  SELECT *
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT
  base.ticker,
  base.fiscal_date,
  base.currency,

  -- carry-through inputs
  base.total_revenue,
  base.gross_profit,
  base.operating_income,
  base.net_income,
  base.total_assets,
  base.total_liab,
  base.equity,
  base.current_assets,
  base.current_liab,
  base.cash_and_equiv,
  base.long_term_debt,
  base.cfo,
  base.capex,

  -- ratios (guard against div-by-zero)
  ifNull(base.gross_profit     / nullIf(base.total_revenue, 0), 0) AS gross_margin,
  ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin,
  ifNull(base.net_income       / nullIf(base.total_revenue, 0), 0) AS net_margin,

  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS current_ratio,
  -- Update to (current_assets - inventory) / current_liab once you add `inventory` to the wide view
  ifNull(base.current_assets / nullIf(base.current_liab, 0), 0)    AS quick_ratio,

  ifNull(base.total_liab / nullIf(base.equity, 0), 0)              AS debt_to_equity,

  -- cash metric
  base.cfo - base.capex                                            AS fcf
FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m16:20:39.650098 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'base.ticker' cannot be resolved from subquery with name base. In scope WITH base AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT base.ticker, base.fiscal_date, base.currency, base.total_revenue, base.gross_profit, base.operating_income, base.net_income, base.total_assets, base.total_liab, base.equity, base.current_assets, base.current_liab, base.cash_and_equiv, base.long_term_debt, base.cfo, base.capex, ifNull(base.gross_profit / nullIf(base.total_revenue, 0), 0) AS gross_margin, ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin, ifNull(base.net_income / nullIf(base.total_revenue, 0), 0) AS net_margin, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS current_ratio, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS quick_ratio, ifNull(base.total_liab / nullIf(base.equity, 0), 0) AS debt_to_equity, base.cfo - base.capex AS fcf FROM base. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:20:39.650486 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8ca67623-73cb-4801-ad8c-66b26bb5add4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1145652e0>]}
[0m16:20:39.650837 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_wide`  [[31mERROR[0m in 0.01s]
[0m16:20:39.651200 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:20:39.651551 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_wide' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'base.ticker' cannot be resolved from subquery with name base. In scope WITH base AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT base.ticker, base.fiscal_date, base.currency, base.total_revenue, base.gross_profit, base.operating_income, base.net_income, base.total_assets, base.total_liab, base.equity, base.current_assets, base.current_liab, base.cash_and_equiv, base.long_term_debt, base.cfo, base.capex, ifNull(base.gross_profit / nullIf(base.total_revenue, 0), 0) AS gross_margin, ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin, ifNull(base.net_income / nullIf(base.total_revenue, 0), 0) AS net_margin, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS current_ratio, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS quick_ratio, ifNull(base.total_liab / nullIf(base.equity, 0), 0) AS debt_to_equity, base.cfo - base.capex AS fcf FROM base. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql.
[0m16:20:39.652282 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:20:39.652539 [info ] [Thread-1 (]: 3 of 3 SKIP relation fundamentals.key_ratios_quarterly_long .................... [[33mSKIP[0m]
[0m16:20:39.652797 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:20:39.653326 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:20:39.653499 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_wide' was left open.
[0m16:20:39.653648 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_wide: Close
[0m16:20:39.653886 [info ] [MainThread]: 
[0m16:20:39.654049 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m16:20:39.654462 [debug] [MainThread]: Command end result
[0m16:20:39.673453 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:20:39.674642 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:20:39.677835 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:20:39.678030 [info ] [MainThread]: 
[0m16:20:39.678235 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:20:39.678403 [info ] [MainThread]: 
[0m16:20:39.678609 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)[0m
[0m16:20:39.678831 [error] [MainThread]:   Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Identifier 'base.ticker' cannot be resolved from subquery with name base. In scope WITH base AS (SELECT * FROM fundamentals.quarterly_fundamentals_wide) SELECT base.ticker, base.fiscal_date, base.currency, base.total_revenue, base.gross_profit, base.operating_income, base.net_income, base.total_assets, base.total_liab, base.equity, base.current_assets, base.current_liab, base.cash_and_equiv, base.long_term_debt, base.cfo, base.capex, ifNull(base.gross_profit / nullIf(base.total_revenue, 0), 0) AS gross_margin, ifNull(base.operating_income / nullIf(base.total_revenue, 0), 0) AS operating_margin, ifNull(base.net_income / nullIf(base.total_revenue, 0), 0) AS net_margin, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS current_ratio, ifNull(base.current_assets / nullIf(base.current_liab, 0), 0) AS quick_ratio, ifNull(base.total_liab / nullIf(base.equity, 0), 0) AS debt_to_equity, base.cfo - base.capex AS fcf FROM base. Maybe you meant: ['b.ticker']. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:20:39.679026 [info ] [MainThread]: 
[0m16:20:39.679214 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:20:39.679373 [info ] [MainThread]: 
[0m16:20:39.679544 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=3
[0m16:20:39.682102 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0557971, "process_in_blocks": "0", "process_kernel_time": 0.212867, "process_mem_max_rss": "196526080", "process_out_blocks": "0", "process_user_time": 1.559325}
[0m16:20:39.682400 [debug] [MainThread]: Command `dbt run` failed at 16:20:39.682353 after 1.06 seconds
[0m16:20:39.682621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124032ba0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114324770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143248c0>]}
[0m16:20:39.682818 [debug] [MainThread]: Flushing usage events
[0m16:20:40.211051 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:23:34.746842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb2390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060555e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062efb90>]}


============================== 16:23:34.749467 | cc6d10fa-81c1-4327-9981-c65d7a686d37 ==============================
[0m16:23:34.749467 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:23:34.749819 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'debug': 'False', 'write_json': 'True', 'quiet': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_format': 'default', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'indirect_selection': 'eager', 'printer_width': '80', 'use_colors': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'no_print': 'None', 'static_parser': 'True', 'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'target_path': 'None', 'introspect': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'empty': 'False', 'use_experimental_parser': 'False'}
[0m16:23:34.847156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cc6d10fa-81c1-4327-9981-c65d7a686d37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064b5fd0>]}
[0m16:23:34.880022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cc6d10fa-81c1-4327-9981-c65d7a686d37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f895b0>]}
[0m16:23:34.880659 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:23:34.953357 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:23:35.018363 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m16:23:35.018814 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:23:35.019033 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_long.sql
[0m16:23:35.145927 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m16:23:35.153823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cc6d10fa-81c1-4327-9981-c65d7a686d37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c35f0>]}
[0m16:23:35.203353 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:23:35.204689 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:23:35.212596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc6d10fa-81c1-4327-9981-c65d7a686d37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069acb60>]}
[0m16:23:35.212869 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m16:23:35.213053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cc6d10fa-81c1-4327-9981-c65d7a686d37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068580e0>]}
[0m16:23:35.214027 [info ] [MainThread]: 
[0m16:23:35.214216 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:23:35.214360 [info ] [MainThread]: 
[0m16:23:35.214624 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:23:35.217510 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:23:35.222690 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:23:35.554525 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:23:35.556323 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:35.564226 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__fundamentals)
[0m16:23:35.568346 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m16:23:35.571535 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:35.572525 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__fundamentals, now list__market)
[0m16:23:35.574251 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:23:35.577115 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:35.578239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cc6d10fa-81c1-4327-9981-c65d7a686d37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106997e30>]}
[0m16:23:35.579362 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:23:35.579630 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_long` ......... [RUN]
[0m16:23:35.579855 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.key_ratios_quarterly_long)
[0m16:23:35.580045 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:23:35.584267 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:23:35.584708 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:23:35.592306 [debug] [Thread-1 (]: Relation key_ratios_quarterly_long already exists, replacing it
[0m16:23:35.598217 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_long_mv']
[0m16:23:35.599574 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_long'
  
  ...
[0m16:23:35.602744 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:35.612160 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:23:35.612874 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    currency,
    total_revenue, gross_profit, operating_income, net_income,
    total_assets, total_liab, equity, current_assets, current_liab,
    cash_and_equiv, long_term_debt, cfo, capex,
    ifNull(gross_profit    / nullIf(total_revenue, 0), 0) AS gross_margin,
    ifNull(operating_income/ nullIf(total_revenue, 0), 0) AS operating_margin,
    ifNull(net_income      / nullIf(total_revenue, 0), 0) AS net_margin,
    ifNull(current_assets  / nullIf(current_liab, 0), 0)  AS current_ratio,
    ifNull(total_liab      / nullIf(equity, 0), 0)        AS debt_to_equity,
    (cfo - capex)                                         AS fcf
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT ticker, fiscal_date, currency, 'gross_margin'     AS metric, toFloat64(gross_margin)     AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'operating_margin',           toFloat64(operating_margin)          FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'net_margin',                 toFloat64(net_margin)                 FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'current_ratio',              toFloat64(current_ratio)              FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'debt_to_equity',             toFloat64(debt_to_equity)             FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'fcf',                        toFloat64(fcf)                        FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:23:35.616836 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    currency,
    total_revenue, gross_profit, operating_income, net_income,
    total_assets, total_liab, equity, current_assets, current_liab,
    cash_and_equiv, long_term_debt, cfo, capex,
    ifNull(gross_profit    / nullIf(total_revenue, 0), 0) AS gross_margin,
    ifNull(operating_income/ nullIf(total_revenue, 0), 0) AS operating_margin,
    ifNull(net_income      / nullIf(total_revenue, 0), 0) AS net_margin,
    ifNull(current_assets  / nullIf(current_liab, 0), 0)  AS current_ratio,
    ifNull(total_liab      / nullIf(equity, 0), 0)        AS debt_to_equity,
    (cfo - capex)                                         AS fcf
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT ticker, fiscal_date, currency, 'gross_margin'     AS metric, toFloat64(gross_margin)     AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'operating_margin',           toFloat64(operating_margin)          FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'net_margin',                 toFloat64(net_margin)                 FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'current_ratio',              toFloat64(current_ratio)              FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'debt_to_equity',             toFloat64(debt_to_equity)             FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'fcf',                        toFloat64(fcf)                        FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m16:23:35.619432 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m16:23:35.620414 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc6d10fa-81c1-4327-9981-c65d7a686d37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070a57f0>]}
[0m16:23:35.620831 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_long`  [[31mERROR[0m in 0.04s]
[0m16:23:35.621180 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:23:35.621402 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:23:35.621685 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_long' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql.
[0m16:23:35.621967 [info ] [Thread-1 (]: 2 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m16:23:35.622555 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.key_ratios_quarterly_long, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m16:23:35.622750 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:23:35.624910 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:23:35.625497 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:23:35.626939 [debug] [Thread-1 (]: Relation key_ratios_quarterly_wide already exists, replacing it
[0m16:23:35.627243 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_wide_mv']
[0m16:23:35.627534 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_wide'
  
  ...
[0m16:23:35.630598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:35.631752 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:23:35.632315 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

SELECT
  ticker,
  fiscal_date,
  currency,
  -- carry-throughs
  total_revenue,
  gross_profit,
  operating_income,
  net_income,
  total_assets,
  total_liab,
  equity,
  current_assets,
  current_liab,
  cash_and_equiv,
  long_term_debt,
  cfo,
  capex,
  -- ratios
  ifNull(gross_profit    / nullIf(total_revenue, 0), 0) AS gross_margin,
  ifNull(operating_income/ nullIf(total_revenue, 0), 0) AS operating_margin,
  ifNull(net_income      / nullIf(total_revenue, 0), 0) AS net_margin,
  ifNull(current_assets  / nullIf(current_liab, 0), 0)  AS current_ratio,
  ifNull(total_liab      / nullIf(equity, 0), 0)        AS debt_to_equity,
  (cfo - capex)                                         AS fcf
FROM `fundamentals`.`quarterly_fundamentals_wide`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:23:35.635146 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

SELECT
  ticker,
  fiscal_date,
  currency,
  -- carry-throughs
  total_revenue,
  gross_profit,
  operating_income,
  net_income,
  total_assets,
  total_liab,
  equity,
  current_assets,
  current_liab,
  cash_and_equiv,
  long_term_debt,
  cfo,
  capex,
  -- ratios
  ifNull(gross_profit    / nullIf(total_revenue, 0), 0) AS gross_margin,
  ifNull(operating_income/ nullIf(total_revenue, 0), 0) AS operating_margin,
  ifNull(net_income      / nullIf(total_revenue, 0), 0) AS net_margin,
  ifNull(current_assets  / nullIf(current_liab, 0), 0)  AS current_ratio,
  ifNull(total_liab      / nullIf(equity, 0), 0)        AS debt_to_equity,
  (cfo - capex)                                         AS fcf
FROM `fundamentals`.`quarterly_fundamentals_wide`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m16:23:35.636787 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:23:35.637143 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc6d10fa-81c1-4327-9981-c65d7a686d37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051b1c40>]}
[0m16:23:35.637527 [error] [Thread-1 (]: 2 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_wide`  [[31mERROR[0m in 0.01s]
[0m16:23:35.637876 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:23:35.638212 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_wide' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql.
[0m16:23:35.639024 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:23:35.639243 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_wide' was left open.
[0m16:23:35.639418 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_wide: Close
[0m16:23:35.639683 [info ] [MainThread]: 
[0m16:23:35.640149 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.43 seconds (0.43s).
[0m16:23:35.640592 [debug] [MainThread]: Command end result
[0m16:23:35.659202 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:23:35.660497 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:23:35.663725 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:23:35.663924 [info ] [MainThread]: 
[0m16:23:35.664124 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m16:23:35.664281 [info ] [MainThread]: 
[0m16:23:35.664480 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)[0m
[0m16:23:35.664698 [error] [MainThread]:   Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m16:23:35.664882 [info ] [MainThread]: 
[0m16:23:35.665060 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m16:23:35.665203 [info ] [MainThread]: 
[0m16:23:35.665373 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)[0m
[0m16:23:35.665573 [error] [MainThread]:   Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:23:35.665746 [info ] [MainThread]: 
[0m16:23:35.665911 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:23:35.666048 [info ] [MainThread]: 
[0m16:23:35.666210 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=2
[0m16:23:35.668735 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.95960945, "process_in_blocks": "0", "process_kernel_time": 0.213034, "process_mem_max_rss": "195510272", "process_out_blocks": "0", "process_user_time": 1.481831}
[0m16:23:35.669030 [debug] [MainThread]: Command `dbt run` failed at 16:23:35.668981 after 0.96 seconds
[0m16:23:35.669248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060566f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107764aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051d4110>]}
[0m16:23:35.669441 [debug] [MainThread]: Flushing usage events
[0m16:23:36.245769 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:23:53.075599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ff6180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10712c770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10712c170>]}


============================== 16:23:53.078109 | 732b00a9-6651-4c35-b4d8-ab46e50644dd ==============================
[0m16:23:53.078109 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:23:53.078450 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'printer_width': '80', 'static_parser': 'True', 'introspect': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'partial_parse': 'True', 'empty': 'False', 'warn_error': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'fail_fast': 'False', 'version_check': 'True', 'debug': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'invocation_command': 'dbt run --select fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'log_cache_events': 'False', 'log_format': 'default', 'use_colors': 'True', 'indirect_selection': 'eager'}
[0m16:23:53.170782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '732b00a9-6651-4c35-b4d8-ab46e50644dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049dc7d0>]}
[0m16:23:53.202253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '732b00a9-6651-4c35-b4d8-ab46e50644dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10712f020>]}
[0m16:23:53.202820 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:23:53.272868 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:23:53.336282 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:23:53.336560 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:23:53.340339 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m16:23:53.362110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '732b00a9-6651-4c35-b4d8-ab46e50644dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a77b30>]}
[0m16:23:53.412227 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:23:53.413502 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:23:53.421471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '732b00a9-6651-4c35-b4d8-ab46e50644dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077a08c0>]}
[0m16:23:53.421786 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m16:23:53.421985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '732b00a9-6651-4c35-b4d8-ab46e50644dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10776f0b0>]}
[0m16:23:53.423115 [info ] [MainThread]: 
[0m16:23:53.423352 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:23:53.423511 [info ] [MainThread]: 
[0m16:23:53.423796 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:23:53.426834 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:23:53.433458 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:23:53.765333 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:23:53.767215 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:53.775261 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m16:23:53.779557 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:23:53.785621 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:23:53.786585 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__market, now list__fundamentals)
[0m16:23:53.788144 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m16:23:53.791210 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:53.792773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '732b00a9-6651-4c35-b4d8-ab46e50644dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116d72c00>]}
[0m16:23:53.794016 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:23:53.794328 [info ] [Thread-1 (]: 1 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_long` ......... [RUN]
[0m16:23:53.794578 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__fundamentals, now model.qi_dbt_project.key_ratios_quarterly_long)
[0m16:23:53.794770 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:23:53.799154 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:23:53.799583 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:23:53.807466 [debug] [Thread-1 (]: Relation key_ratios_quarterly_long already exists, replacing it
[0m16:23:53.813390 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_long_mv']
[0m16:23:53.814625 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_long'
  
  ...
[0m16:23:53.818371 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:53.827618 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:23:53.828349 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    currency,
    total_revenue, gross_profit, operating_income, net_income,
    total_assets, total_liab, equity, current_assets, current_liab,
    cash_and_equiv, long_term_debt, cfo, capex,
    ifNull(gross_profit    / nullIf(total_revenue, 0), 0) AS gross_margin,
    ifNull(operating_income/ nullIf(total_revenue, 0), 0) AS operating_margin,
    ifNull(net_income      / nullIf(total_revenue, 0), 0) AS net_margin,
    ifNull(current_assets  / nullIf(current_liab, 0), 0)  AS current_ratio,
    ifNull(total_liab      / nullIf(equity, 0), 0)        AS debt_to_equity,
    (cfo - capex)                                         AS fcf
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT ticker, fiscal_date, currency, 'gross_margin'     AS metric, toFloat64(gross_margin)     AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'operating_margin',           toFloat64(operating_margin)          FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'net_margin',                 toFloat64(net_margin)                 FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'current_ratio',              toFloat64(current_ratio)              FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'debt_to_equity',             toFloat64(debt_to_equity)             FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'fcf',                        toFloat64(fcf)                        FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:23:53.833695 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT
    ticker,
    fiscal_date,
    currency,
    total_revenue, gross_profit, operating_income, net_income,
    total_assets, total_liab, equity, current_assets, current_liab,
    cash_and_equiv, long_term_debt, cfo, capex,
    ifNull(gross_profit    / nullIf(total_revenue, 0), 0) AS gross_margin,
    ifNull(operating_income/ nullIf(total_revenue, 0), 0) AS operating_margin,
    ifNull(net_income      / nullIf(total_revenue, 0), 0) AS net_margin,
    ifNull(current_assets  / nullIf(current_liab, 0), 0)  AS current_ratio,
    ifNull(total_liab      / nullIf(equity, 0), 0)        AS debt_to_equity,
    (cfo - capex)                                         AS fcf
  FROM `fundamentals`.`quarterly_fundamentals_wide`
)

SELECT ticker, fiscal_date, currency, 'gross_margin'     AS metric, toFloat64(gross_margin)     AS value FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'operating_margin',           toFloat64(operating_margin)          FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'net_margin',                 toFloat64(net_margin)                 FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'current_ratio',              toFloat64(current_ratio)              FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'debt_to_equity',             toFloat64(debt_to_equity)             FROM base
UNION ALL
SELECT ticker, fiscal_date, currency, 'fcf',                        toFloat64(fcf)                        FROM base
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m16:23:53.836093 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m16:23:53.836992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '732b00a9-6651-4c35-b4d8-ab46e50644dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122a63e60>]}
[0m16:23:53.837355 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_long`  [[31mERROR[0m in 0.04s]
[0m16:23:53.837694 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:23:53.837917 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:23:53.838418 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_long' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql.
[0m16:23:53.838155 [info ] [Thread-1 (]: 2 of 2 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m16:23:53.839205 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.key_ratios_quarterly_long, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m16:23:53.839442 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:23:53.841691 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:23:53.842264 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:23:53.843594 [debug] [Thread-1 (]: Relation key_ratios_quarterly_wide already exists, replacing it
[0m16:23:53.843835 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_wide_mv']
[0m16:23:53.844095 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_wide'
  
  ...
[0m16:23:53.849028 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:23:53.850152 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:23:53.850620 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

SELECT
  ticker,
  fiscal_date,
  currency,
  -- carry-throughs
  total_revenue,
  gross_profit,
  operating_income,
  net_income,
  total_assets,
  total_liab,
  equity,
  current_assets,
  current_liab,
  cash_and_equiv,
  long_term_debt,
  cfo,
  capex,
  -- ratios
  ifNull(gross_profit    / nullIf(total_revenue, 0), 0) AS gross_margin,
  ifNull(operating_income/ nullIf(total_revenue, 0), 0) AS operating_margin,
  ifNull(net_income      / nullIf(total_revenue, 0), 0) AS net_margin,
  ifNull(current_assets  / nullIf(current_liab, 0), 0)  AS current_ratio,
  ifNull(total_liab      / nullIf(equity, 0), 0)        AS debt_to_equity,
  (cfo - capex)                                         AS fcf
FROM `fundamentals`.`quarterly_fundamentals_wide`
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:23:53.853935 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

SELECT
  ticker,
  fiscal_date,
  currency,
  -- carry-throughs
  total_revenue,
  gross_profit,
  operating_income,
  net_income,
  total_assets,
  total_liab,
  equity,
  current_assets,
  current_liab,
  cash_and_equiv,
  long_term_debt,
  cfo,
  capex,
  -- ratios
  ifNull(gross_profit    / nullIf(total_revenue, 0), 0) AS gross_margin,
  ifNull(operating_income/ nullIf(total_revenue, 0), 0) AS operating_margin,
  ifNull(net_income      / nullIf(total_revenue, 0), 0) AS net_margin,
  ifNull(current_assets  / nullIf(current_liab, 0), 0)  AS current_ratio,
  ifNull(total_liab      / nullIf(equity, 0), 0)        AS debt_to_equity,
  (cfo - capex)                                         AS fcf
FROM `fundamentals`.`quarterly_fundamentals_wide`
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m16:23:53.855606 [debug] [Thread-1 (]: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:23:53.855946 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '732b00a9-6651-4c35-b4d8-ab46e50644dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122ae6420>]}
[0m16:23:53.856319 [error] [Thread-1 (]: 2 of 2 ERROR creating sql view model `fundamentals`.`key_ratios_quarterly_wide`  [[31mERROR[0m in 0.02s]
[0m16:23:53.856756 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:23:53.857123 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.key_ratios_quarterly_wide' to be skipped because of status 'error'.  Reason: Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql.
[0m16:23:53.857902 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:23:53.858117 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_wide' was left open.
[0m16:23:53.858310 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_wide: Close
[0m16:23:53.858633 [info ] [MainThread]: 
[0m16:23:53.858805 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.43 seconds (0.43s).
[0m16:23:53.859220 [debug] [MainThread]: Command end result
[0m16:23:53.879103 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:23:53.880581 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:23:53.884047 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:23:53.884281 [info ] [MainThread]: 
[0m16:23:53.884514 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m16:23:53.884705 [info ] [MainThread]: 
[0m16:23:53.884925 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)[0m
[0m16:23:53.885147 [error] [MainThread]:   Database Error in model key_ratios_quarterly_long (models/fundamentals/key_ratios_quarterly_long.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m16:23:53.885356 [info ] [MainThread]: 
[0m16:23:53.885540 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_long.sql
[0m16:23:53.885788 [info ] [MainThread]: 
[0m16:23:53.886021 [error] [MainThread]: [31mFailure in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)[0m
[0m16:23:53.886265 [error] [MainThread]:   Database Error in model key_ratios_quarterly_wide (models/fundamentals/key_ratios_quarterly_wide.sql)
  Received ClickHouse exception, code: 47, server response: Code: 47. DB::Exception: Unknown expression identifier `ticker` in scope SELECT ticker, fiscal_date, currency, total_revenue, gross_profit, operating_income, net_income, total_assets, total_liab, equity, current_assets, current_liab, cash_and_equiv, long_term_debt, cfo, capex, ifNull(gross_profit / nullIf(total_revenue, 0), 0) AS gross_margin, ifNull(operating_income / nullIf(total_revenue, 0), 0) AS operating_margin, ifNull(net_income / nullIf(total_revenue, 0), 0) AS net_margin, ifNull(current_assets / nullIf(current_liab, 0), 0) AS current_ratio, ifNull(total_liab / nullIf(equity, 0), 0) AS debt_to_equity, cfo - capex AS fcf FROM fundamentals.quarterly_fundamentals_wide. (UNKNOWN_IDENTIFIER) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
  compiled code at target/run/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:23:53.886463 [info ] [MainThread]: 
[0m16:23:53.886649 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:23:53.886797 [info ] [MainThread]: 
[0m16:23:53.886993 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=2
[0m16:23:53.889592 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.850107, "process_in_blocks": "0", "process_kernel_time": 0.192708, "process_mem_max_rss": "191791104", "process_out_blocks": "0", "process_user_time": 1.362162}
[0m16:23:53.889895 [debug] [MainThread]: Command `dbt run` failed at 16:23:53.889848 after 0.85 seconds
[0m16:23:53.890127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075171a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063dcb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072de210>]}
[0m16:23:53.890341 [debug] [MainThread]: Flushing usage events
[0m16:23:54.427882 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:27:01.841125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101dcec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ef4830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110924110>]}


============================== 16:27:01.843675 | 67a1b0ba-84ed-4485-a769-e9021dfe22c9 ==============================
[0m16:27:01.843675 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:27:01.844018 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'version_check': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'warn_error': 'None', 'invocation_command': 'dbt run --select fundamentals.quarterly_fundamentals_wide fundamentals.key_ratios_quarterly_wide fundamentals.key_ratios_quarterly_long', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'indirect_selection': 'eager', 'fail_fast': 'False', 'static_parser': 'True', 'log_format': 'default', 'use_colors': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'printer_width': '80', 'introspect': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'empty': 'False', 'no_print': 'None', 'cache_selected_only': 'False'}
[0m16:27:01.934268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047ec530>]}
[0m16:27:01.964185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101adca0>]}
[0m16:27:01.964670 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:27:02.033574 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:27:02.101202 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m16:27:02.101691 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_long.sql
[0m16:27:02.101942 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/quarterly_fundamentals_wide.sql
[0m16:27:02.102141 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/fundamentals/key_ratios_quarterly_wide.sql
[0m16:27:02.299730 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m16:27:02.306841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111ca150>]}
[0m16:27:02.385461 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:27:02.386556 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:27:02.394364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10239f7d0>]}
[0m16:27:02.394634 [info ] [MainThread]: Found 8 models, 20 data tests, 1 source, 605 macros
[0m16:27:02.394821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113d25a0>]}
[0m16:27:02.395864 [info ] [MainThread]: 
[0m16:27:02.396048 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:27:02.396196 [info ] [MainThread]: 
[0m16:27:02.396443 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:27:02.399368 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:27:02.404667 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:27:02.709884 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:27:02.712008 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:27:02.720302 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__fundamentals)
[0m16:27:02.723901 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__fundamentals: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__fundamentals"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'fundamentals'
      

  ...
[0m16:27:02.727014 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:27:02.727962 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__fundamentals, now list__market)
[0m16:27:02.729715 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:27:02.732377 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:27:02.733533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf3620>]}
[0m16:27:02.734618 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:27:02.734881 [info ] [Thread-1 (]: 1 of 3 START sql view model `fundamentals`.`quarterly_fundamentals_wide` ....... [RUN]
[0m16:27:02.735103 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.quarterly_fundamentals_wide)
[0m16:27:02.735288 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:27:02.740033 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m16:27:02.740512 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:27:02.782420 [debug] [Thread-1 (]: Relation quarterly_fundamentals_wide already exists, replacing it
[0m16:27:02.787748 [debug] [Thread-1 (]: Model mvs to replace ['quarterly_fundamentals_wide_mv']
[0m16:27:02.788996 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.quarterly_fundamentals_wide'
  
  ...
[0m16:27:02.795394 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:27:02.803795 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_fundamentals_wide"
[0m16:27:02.804354 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_fundamentals_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_fundamentals_wide"} */


  create or replace view `fundamentals`.`quarterly_fundamentals_wide` 
  
    
  
  
    
    
  as (
    

WITH base AS (
  SELECT
    ticker      AS ticker,
    fiscal_date AS fiscal_date,
    argMax(currency, loaded_at) AS currency
  FROM `fundamentals`.`quarterly_fundamentals_long`
  GROUP BY ticker, fiscal_date
),
inc AS (
  SELECT
    ticker, fiscal_date,
    maxIf(value, metric = 'Total Revenue')    AS total_revenue,
    maxIf(value, metric = 'Cost Of Revenue')  AS cost_of_revenue,
    maxIf(value, metric = 'Gross Profit')     AS gross_profit,
    maxIf(value, metric = 'Operating Income') AS operating_income,
    maxIf(value, metric = 'Net Income')       AS net_income
  FROM `fundamentals`.`quarterly_fundamentals_long`
  WHERE statement = 'income_statement'
  GROUP BY ticker, fiscal_date
),
bs AS (
  SELECT
    ticker, fiscal_date,
    maxIf(value, metric = 'Total Assets')                  AS total_assets,
    maxIf(value, metric = 'Total Liab')                    AS total_liab,
    maxIf(value, metric = 'Total Stockholder Equity')      AS equity,
    maxIf(value, metric = 'Total Current Assets')          AS current_assets,
    maxIf(value, metric = 'Total Current Liabilities')     AS current_liab,
    maxIf(value, metric = 'Cash And Cash Equivalents')     AS cash_and_equiv,
    maxIf(value, metric = 'Long Term Debt')                AS long_term_debt
  FROM `fundamentals`.`quarterly_fundamentals_long`
  WHERE statement = 'balance_sheet'
  GROUP BY ticker, fiscal_date
),
cf AS (
  SELECT
    ticker, fiscal_date,
    maxIf(value, metric = 'Total Cash From Operating Activities') AS cfo,
    maxIf(value, metric = 'Capital Expenditures')                 AS capex
  FROM `fundamentals`.`quarterly_fundamentals_long`
  WHERE statement = 'cashflow_statement'
  GROUP BY ticker, fiscal_date
)

SELECT
  b.ticker       AS ticker,
  b.fiscal_date  AS fiscal_date,
  b.currency     AS currency,
  inc.total_revenue,
  inc.cost_of_revenue,
  inc.gross_profit,
  inc.operating_income,
  inc.net_income,
  bs.total_assets,
  bs.total_liab,
  bs.equity,
  bs.current_assets,
  bs.current_liab,
  bs.cash_and_equiv,
  bs.long_term_debt,
  cf.cfo,
  cf.capex
FROM base b
LEFT JOIN inc ON b.ticker = inc.ticker AND b.fiscal_date = inc.fiscal_date
LEFT JOIN bs  ON b.ticker = bs.ticker  AND b.fiscal_date = bs.fiscal_date
LEFT JOIN cf  ON b.ticker = cf.ticker  AND b.fiscal_date = cf.fiscal_date
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:27:02.813551 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:27:02.825550 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105927800>]}
[0m16:27:02.825980 [info ] [Thread-1 (]: 1 of 3 OK created sql view model `fundamentals`.`quarterly_fundamentals_wide` .. [[32mOK[0m in 0.09s]
[0m16:27:02.826290 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_fundamentals_wide
[0m16:27:02.826733 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:27:02.826962 [info ] [Thread-1 (]: 2 of 3 START sql view model `fundamentals`.`key_ratios_quarterly_long` ......... [RUN]
[0m16:27:02.827211 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_fundamentals_wide, now model.qi_dbt_project.key_ratios_quarterly_long)
[0m16:27:02.827429 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:27:02.829309 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:27:02.829773 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:27:02.830988 [debug] [Thread-1 (]: Relation key_ratios_quarterly_long already exists, replacing it
[0m16:27:02.831218 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_long_mv']
[0m16:27:02.831488 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_long'
  
  ...
[0m16:27:02.833939 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:27:02.834977 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_long"
[0m16:27:02.835458 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_long: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_long"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_long` 
  
    
  
  
    
    
  as (
    

WITH w AS (
  SELECT * FROM `fundamentals`.`quarterly_fundamentals_wide`
),
r AS (
  SELECT
    w.ticker, w.fiscal_date, w.currency,
    ifNull(w.gross_profit     / nullIf(w.total_revenue, 0), 0) AS gross_margin,
    ifNull(w.operating_income / nullIf(w.total_revenue, 0), 0) AS operating_margin,
    ifNull(w.net_income       / nullIf(w.total_revenue, 0), 0) AS net_margin,
    ifNull(w.current_assets   / nullIf(w.current_liab, 0), 0)  AS current_ratio,
    ifNull(w.total_liab       / nullIf(w.equity, 0), 0)        AS debt_to_equity,
    (w.cfo - w.capex)                                          AS fcf
  FROM w
)
SELECT ticker, fiscal_date, currency, 'gross_margin'     AS metric, toFloat64(gross_margin)     AS value FROM r
UNION ALL
SELECT ticker, fiscal_date, currency, 'operating_margin',          toFloat64(operating_margin)          FROM r
UNION ALL
SELECT ticker, fiscal_date, currency, 'net_margin',                toFloat64(net_margin)                FROM r
UNION ALL
SELECT ticker, fiscal_date, currency, 'current_ratio',             toFloat64(current_ratio)             FROM r
UNION ALL
SELECT ticker, fiscal_date, currency, 'debt_to_equity',            toFloat64(debt_to_equity)            FROM r
UNION ALL
SELECT ticker, fiscal_date, currency, 'fcf',                       toFloat64(fcf)                       FROM r
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:27:02.844089 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:27:02.845200 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111276d50>]}
[0m16:27:02.845551 [info ] [Thread-1 (]: 2 of 3 OK created sql view model `fundamentals`.`key_ratios_quarterly_long` .... [[32mOK[0m in 0.02s]
[0m16:27:02.845837 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_long
[0m16:27:02.846044 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:27:02.846306 [info ] [Thread-1 (]: 3 of 3 START sql view model `fundamentals`.`key_ratios_quarterly_wide` ......... [RUN]
[0m16:27:02.846522 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.key_ratios_quarterly_long, now model.qi_dbt_project.key_ratios_quarterly_wide)
[0m16:27:02.846706 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:27:02.848587 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:27:02.849094 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:27:02.850419 [debug] [Thread-1 (]: Relation key_ratios_quarterly_wide already exists, replacing it
[0m16:27:02.850841 [debug] [Thread-1 (]: Model mvs to replace ['key_ratios_quarterly_wide_mv']
[0m16:27:02.851139 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */

    
    select name
    from system.tables
    where engine = 'MaterializedView'
      and extract(create_table_query, 'TO\\s+([^\\s(]+)') = 'fundamentals.key_ratios_quarterly_wide'
  
  ...
[0m16:27:02.854236 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:27:02.855383 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.key_ratios_quarterly_wide"
[0m16:27:02.855878 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.key_ratios_quarterly_wide: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.key_ratios_quarterly_wide"} */


  create or replace view `fundamentals`.`key_ratios_quarterly_wide` 
  
    
  
  
    
    
  as (
    

SELECT
  w.ticker,
  w.fiscal_date,
  w.currency,
  w.total_revenue,
  w.gross_profit,
  w.operating_income,
  w.net_income,
  w.total_assets,
  w.total_liab,
  w.equity,
  w.current_assets,
  w.current_liab,
  w.cash_and_equiv,
  w.long_term_debt,
  w.cfo,
  w.capex,
  ifNull(w.gross_profit     / nullIf(w.total_revenue, 0), 0) AS gross_margin,
  ifNull(w.operating_income / nullIf(w.total_revenue, 0), 0) AS operating_margin,
  ifNull(w.net_income       / nullIf(w.total_revenue, 0), 0) AS net_margin,
  ifNull(w.current_assets   / nullIf(w.current_liab, 0), 0)  AS current_ratio,
  ifNull(w.total_liab       / nullIf(w.equity, 0), 0)        AS debt_to_equity,
  (w.cfo - w.capex)                                          AS fcf
FROM `fundamentals`.`quarterly_fundamentals_wide` AS w
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:27:02.859766 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:27:02.860944 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a1b0ba-84ed-4485-a769-e9021dfe22c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11771da90>]}
[0m16:27:02.861333 [info ] [Thread-1 (]: 3 of 3 OK created sql view model `fundamentals`.`key_ratios_quarterly_wide` .... [[32mOK[0m in 0.01s]
[0m16:27:02.861630 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.key_ratios_quarterly_wide
[0m16:27:02.862255 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:27:02.862460 [debug] [MainThread]: Connection 'model.qi_dbt_project.key_ratios_quarterly_wide' was left open.
[0m16:27:02.862638 [debug] [MainThread]: On model.qi_dbt_project.key_ratios_quarterly_wide: Close
[0m16:27:02.862907 [info ] [MainThread]: 
[0m16:27:02.863083 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 0.47 seconds (0.47s).
[0m16:27:02.863530 [debug] [MainThread]: Command end result
[0m16:27:02.882094 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:27:02.883446 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:27:02.886677 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:27:02.886888 [info ] [MainThread]: 
[0m16:27:02.887104 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:27:02.887275 [info ] [MainThread]: 
[0m16:27:02.887476 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m16:27:02.890071 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0839833, "process_in_blocks": "0", "process_kernel_time": 0.207687, "process_mem_max_rss": "197197824", "process_out_blocks": "0", "process_user_time": 1.571603}
[0m16:27:02.890353 [debug] [MainThread]: Command `dbt run` succeeded at 16:27:02.890305 after 1.08 seconds
[0m16:27:02.890569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11058a630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101dc5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108f3f50>]}
[0m16:27:02.890761 [debug] [MainThread]: Flushing usage events
[0m16:27:03.603762 [debug] [MainThread]: An error was encountered while trying to flush usage events
