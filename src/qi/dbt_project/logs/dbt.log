[0m04:07:22.591184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10791f260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093a0f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093a0b00>]}


============================== 04:07:22.597573 | 9cd73eaf-08f0-4375-be4a-a49072418480 ==============================
[0m04:07:22.597573 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:07:22.597897 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'indirect_selection': 'eager', 'version_check': 'True', 'partial_parse': 'True', 'quiet': 'False', 'no_print': 'None', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error': 'None', 'write_json': 'True', 'empty': 'None', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt debug', 'log_cache_events': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'static_parser': 'True'}
[0m04:07:22.602740 [info ] [MainThread]: dbt version: 1.10.13
[0m04:07:22.602932 [info ] [MainThread]: python version: 3.12.12
[0m04:07:22.603080 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:07:22.603221 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:07:22.604054 [info ] [MainThread]: target not specified in profile 'type', using 'default'
[0m04:07:22.604345 [info ] [MainThread]: target not specified in profile 'host', using 'default'
[0m04:07:22.604610 [error] [MainThread]: Encountered an error:
argument of type 'int' is not iterable
[0m04:07:22.605580 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/main.py", line 420, in debug
    results = task.run()
              ^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/debug.py", line 114, in run
    load_profile_status: SubtaskStatus = self._load_profile()
                                         ^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/debug.py", line 205, in _load_profile
    profile: Profile = Profile.render(
                       ^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 402, in render
    return cls.from_raw_profiles(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 368, in from_raw_profiles
    return cls.from_raw_profile_info(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 314, in from_raw_profile_info
    target_name, profile_data = cls.render_profile(
                                ^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 273, in render_profile
    elif "target" in raw_profile:
         ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'int' is not iterable

[0m04:07:22.720075 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.17592192, "process_in_blocks": "0", "process_kernel_time": 0.120137, "process_mem_max_rss": "113049600", "process_out_blocks": "0", "process_user_time": 0.828379}
[0m04:07:22.720430 [debug] [MainThread]: Command `dbt debug` failed at 04:07:22.720375 after 0.18 seconds
[0m04:07:22.720633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093a0dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091512e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10930ddf0>]}
[0m04:07:22.720829 [debug] [MainThread]: Flushing usage events
[0m04:07:23.266660 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:07:46.963472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d78980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046ff590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068f5220>]}


============================== 04:07:46.965903 | b251a2c9-c182-441e-b4d2-11b71be4b41a ==============================
[0m04:07:46.965903 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:07:46.966254 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'log_format': 'default', 'use_colors': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'warn_error': 'None', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'debug': 'False', 'target_path': 'None', 'printer_width': '80', 'fail_fast': 'False', 'partial_parse': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project'}
[0m04:07:46.971967 [info ] [MainThread]: dbt version: 1.10.13
[0m04:07:46.972223 [info ] [MainThread]: python version: 3.12.12
[0m04:07:46.972376 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:07:46.972522 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:07:46.973228 [info ] [MainThread]: target not specified in profile 'type', using 'default'
[0m04:07:46.973487 [info ] [MainThread]: target not specified in profile 'host', using 'default'
[0m04:07:46.973718 [error] [MainThread]: Encountered an error:
argument of type 'int' is not iterable
[0m04:07:46.974558 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/main.py", line 420, in debug
    results = task.run()
              ^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/debug.py", line 114, in run
    load_profile_status: SubtaskStatus = self._load_profile()
                                         ^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/task/debug.py", line 205, in _load_profile
    profile: Profile = Profile.render(
                       ^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 402, in render
    return cls.from_raw_profiles(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 368, in from_raw_profiles
    return cls.from_raw_profile_info(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 314, in from_raw_profile_info
    target_name, profile_data = cls.render_profile(
                                ^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/config/profile.py", line 273, in render_profile
    elif "target" in raw_profile:
         ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'int' is not iterable

[0m04:07:46.976186 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.047934376, "process_in_blocks": "0", "process_kernel_time": 0.087436, "process_mem_max_rss": "106971136", "process_out_blocks": "0", "process_user_time": 0.700834}
[0m04:07:46.976485 [debug] [MainThread]: Command `dbt debug` failed at 04:07:46.976433 after 0.05 seconds
[0m04:07:46.976684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f6dfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f0ef60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f0ede0>]}
[0m04:07:46.976912 [debug] [MainThread]: Flushing usage events
[0m04:07:47.562883 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:09:07.486256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10503a4b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c1e630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f18770>]}


============================== 04:09:07.489009 | c9e642bb-3b4b-4d76-acd8-bf859470d631 ==============================
[0m04:09:07.489009 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:09:07.489373 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'empty': 'None', 'target_path': 'None', 'use_colors': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'quiet': 'False', 'debug': 'False', 'fail_fast': 'False', 'version_check': 'True', 'write_json': 'True', 'introspect': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_format': 'default', 'warn_error': 'None'}
[0m04:09:07.494802 [info ] [MainThread]: dbt version: 1.10.13
[0m04:09:07.494989 [info ] [MainThread]: python version: 3.12.12
[0m04:09:07.495131 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:09:07.495268 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:09:07.498013 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'CLICKHOUSE_USER'
[0m04:09:07.499365 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.050758168, "process_in_blocks": "0", "process_kernel_time": 0.09559, "process_mem_max_rss": "107806720", "process_out_blocks": "0", "process_user_time": 0.697482}
[0m04:09:07.499631 [debug] [MainThread]: Command `dbt debug` failed at 04:09:07.499584 after 0.05 seconds
[0m04:09:07.499821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105171f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cec200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b12bd0>]}
[0m04:09:07.500008 [debug] [MainThread]: Flushing usage events
[0m04:09:08.091602 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:10:21.151133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b7f920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a31340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fbf920>]}


============================== 04:10:21.153535 | f1be4f76-fef1-430f-8688-4cef5bcae528 ==============================
[0m04:10:21.153535 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:10:21.153877 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'write_json': 'True', 'invocation_command': 'dbt debug', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'introspect': 'True', 'log_format': 'default', 'log_cache_events': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_colors': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'fail_fast': 'False', 'printer_width': '80', 'target_path': 'None', 'debug': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error': 'None'}
[0m04:10:21.158882 [info ] [MainThread]: dbt version: 1.10.13
[0m04:10:21.159096 [info ] [MainThread]: python version: 3.12.12
[0m04:10:21.159250 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:10:21.159390 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:10:21.162454 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'CLICKHOUSE_USER'
[0m04:10:21.163942 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.048605207, "process_in_blocks": "0", "process_kernel_time": 0.099443, "process_mem_max_rss": "106512384", "process_out_blocks": "0", "process_user_time": 0.698393}
[0m04:10:21.164238 [debug] [MainThread]: Command `dbt debug` failed at 04:10:21.164187 after 0.05 seconds
[0m04:10:21.164429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a75ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11244d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e4d700>]}
[0m04:10:21.164626 [debug] [MainThread]: Flushing usage events
[0m04:10:21.583599 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:13:05.234712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e7f830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11023ac60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104321e0>]}


============================== 04:13:05.237262 | 3d488704-0cba-4b9e-a07b-aa0d349af00f ==============================
[0m04:13:05.237262 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:13:05.237600 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'invocation_command': 'dbt debug', 'log_format': 'default', 'quiet': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'static_parser': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'empty': 'None', 'cache_selected_only': 'False', 'use_colors': 'True', 'debug': 'False', 'write_json': 'True', 'warn_error': 'None'}
[0m04:13:05.242711 [info ] [MainThread]: dbt version: 1.10.13
[0m04:13:05.242935 [info ] [MainThread]: python version: 3.12.12
[0m04:13:05.243097 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:13:05.243251 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:13:05.279183 [info ] [MainThread]: Using profiles dir at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project
[0m04:13:05.279495 [info ] [MainThread]: Using profiles.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/profiles.yml
[0m04:13:05.279648 [info ] [MainThread]: Using dbt_project.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/dbt_project.yml
[0m04:13:05.279938 [info ] [MainThread]: adapter type: clickhouse
[0m04:13:05.280077 [info ] [MainThread]: adapter version: 1.9.5
[0m04:13:05.281702 [info ] [MainThread]: Configuration:
[0m04:13:05.281877 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:13:05.282012 [info ] [MainThread]:   dbt_project.yml file [[31mERROR invalid[0m]
[0m04:13:05.282174 [info ] [MainThread]: Required dependencies:
[0m04:13:05.282350 [debug] [MainThread]: Executing "git --help"
[0m04:13:05.299549 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:13:05.300087 [debug] [MainThread]: STDERR: "b''"
[0m04:13:05.300286 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:13:05.300471 [info ] [MainThread]: Connection:
[0m04:13:05.300646 [info ] [MainThread]:   driver: None
[0m04:13:05.300788 [info ] [MainThread]:   host: localhost
[0m04:13:05.300923 [info ] [MainThread]:   port: 8124
[0m04:13:05.301051 [info ] [MainThread]:   user: qi
[0m04:13:05.301181 [info ] [MainThread]:   schema: default
[0m04:13:05.301317 [info ] [MainThread]:   retries: 1
[0m04:13:05.301442 [info ] [MainThread]:   cluster: None
[0m04:13:05.301572 [info ] [MainThread]:   database_engine: None
[0m04:13:05.301708 [info ] [MainThread]:   cluster_mode: False
[0m04:13:05.301825 [info ] [MainThread]:   secure: False
[0m04:13:05.301943 [info ] [MainThread]:   verify: True
[0m04:13:05.302063 [info ] [MainThread]:   client_cert: None
[0m04:13:05.302183 [info ] [MainThread]:   client_cert_key: None
[0m04:13:05.302311 [info ] [MainThread]:   connect_timeout: 10
[0m04:13:05.302426 [info ] [MainThread]:   send_receive_timeout: 300
[0m04:13:05.302543 [info ] [MainThread]:   sync_request_timeout: 5
[0m04:13:05.302660 [info ] [MainThread]:   compress_block_size: 1048576
[0m04:13:05.302778 [info ] [MainThread]:   compression: 
[0m04:13:05.302909 [info ] [MainThread]:   check_exchange: True
[0m04:13:05.303023 [info ] [MainThread]:   custom_settings: None
[0m04:13:05.303140 [info ] [MainThread]:   use_lw_deletes: False
[0m04:13:05.303255 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m04:13:05.303372 [info ] [MainThread]:   tcp_keepalive: False
[0m04:13:05.303771 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m04:13:05.367552 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m04:13:05.367997 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:13:11.445015 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m04:13:11.446942 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:13:11.455176 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:13:11.455452 [info ] [MainThread]: [31m1 check failed:[0m
[0m04:13:11.455636 [info ] [MainThread]: Project loading failed for the following reason:
Runtime Error
  Required "name" field not present in project

Error encountered in /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/dbt_project.yml


[0m04:13:11.458177 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 6.2596097, "process_in_blocks": "0", "process_kernel_time": 0.234971, "process_mem_max_rss": "157794304", "process_out_blocks": "0", "process_user_time": 1.138061}
[0m04:13:11.458501 [debug] [MainThread]: Command `dbt debug` failed at 04:13:11.458441 after 6.26 seconds
[0m04:13:11.458715 [debug] [MainThread]: Connection 'debug' was left open.
[0m04:13:11.458889 [debug] [MainThread]: On debug: Close
[0m04:13:11.459127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104f5e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e7d760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e7d700>]}
[0m04:13:11.459393 [debug] [MainThread]: Flushing usage events
[0m04:13:12.079455 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:15:01.053264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf3a4b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf3ac60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c130980>]}


============================== 04:15:01.056006 | 6775a7f6-5a7e-4708-ad4b-dee1f20e84e8 ==============================
[0m04:15:01.056006 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:15:01.056336 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'fail_fast': 'False', 'empty': 'None', 'no_print': 'None', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'use_colors': 'True', 'write_json': 'True', 'warn_error': 'None', 'target_path': 'None', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m04:15:01.061262 [info ] [MainThread]: dbt version: 1.10.13
[0m04:15:01.061451 [info ] [MainThread]: python version: 3.12.12
[0m04:15:01.061596 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:15:01.061737 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:15:01.094431 [info ] [MainThread]: Using profiles dir at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project
[0m04:15:01.094728 [info ] [MainThread]: Using profiles.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/profiles.yml
[0m04:15:01.094882 [info ] [MainThread]: Using dbt_project.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/dbt_project.yml
[0m04:15:01.095149 [info ] [MainThread]: adapter type: clickhouse
[0m04:15:01.095296 [info ] [MainThread]: adapter version: 1.9.5
[0m04:15:01.143822 [info ] [MainThread]: Configuration:
[0m04:15:01.144135 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:15:01.144289 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m04:15:01.144424 [info ] [MainThread]: Required dependencies:
[0m04:15:01.144632 [debug] [MainThread]: Executing "git --help"
[0m04:15:01.160662 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:15:01.161227 [debug] [MainThread]: STDERR: "b''"
[0m04:15:01.161431 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:15:01.161609 [info ] [MainThread]: Connection:
[0m04:15:01.161790 [info ] [MainThread]:   driver: None
[0m04:15:01.161921 [info ] [MainThread]:   host: localhost
[0m04:15:01.162045 [info ] [MainThread]:   port: 8124
[0m04:15:01.162166 [info ] [MainThread]:   user: qi
[0m04:15:01.162285 [info ] [MainThread]:   schema: default
[0m04:15:01.162406 [info ] [MainThread]:   retries: 1
[0m04:15:01.162528 [info ] [MainThread]:   cluster: None
[0m04:15:01.162645 [info ] [MainThread]:   database_engine: None
[0m04:15:01.162764 [info ] [MainThread]:   cluster_mode: False
[0m04:15:01.162883 [info ] [MainThread]:   secure: False
[0m04:15:01.163003 [info ] [MainThread]:   verify: True
[0m04:15:01.163126 [info ] [MainThread]:   client_cert: None
[0m04:15:01.163242 [info ] [MainThread]:   client_cert_key: None
[0m04:15:01.163362 [info ] [MainThread]:   connect_timeout: 10
[0m04:15:01.163478 [info ] [MainThread]:   send_receive_timeout: 300
[0m04:15:01.163596 [info ] [MainThread]:   sync_request_timeout: 5
[0m04:15:01.163713 [info ] [MainThread]:   compress_block_size: 1048576
[0m04:15:01.163831 [info ] [MainThread]:   compression: 
[0m04:15:01.163951 [info ] [MainThread]:   check_exchange: True
[0m04:15:01.164068 [info ] [MainThread]:   custom_settings: None
[0m04:15:01.164188 [info ] [MainThread]:   use_lw_deletes: False
[0m04:15:01.164305 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m04:15:01.164425 [info ] [MainThread]:   tcp_keepalive: False
[0m04:15:01.164775 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m04:15:01.226656 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m04:15:01.227065 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:15:01.509842 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m04:15:01.511602 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:15:01.519650 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:15:01.519916 [info ] [MainThread]: [32mAll checks passed![0m
[0m04:15:01.522379 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.5043327, "process_in_blocks": "0", "process_kernel_time": 0.185228, "process_mem_max_rss": "158384128", "process_out_blocks": "0", "process_user_time": 1.038287}
[0m04:15:01.522753 [debug] [MainThread]: Command `dbt debug` succeeded at 04:15:01.522689 after 0.50 seconds
[0m04:15:01.522943 [debug] [MainThread]: Connection 'debug' was left open.
[0m04:15:01.523107 [debug] [MainThread]: On debug: Close
[0m04:15:01.523393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8f9820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c459940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9f8590>]}
[0m04:15:01.523653 [debug] [MainThread]: Flushing usage events
[0m04:15:02.176815 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:15:16.322956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082243e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10905bb00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108353260>]}


============================== 04:15:16.325474 | ea107799-e309-4d2d-9e1b-2c466e56ddbd ==============================
[0m04:15:16.325474 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:15:16.325810 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'invocation_command': 'dbt debug', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'no_print': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'empty': 'None', 'printer_width': '80', 'warn_error': 'None', 'log_format': 'default', 'debug': 'False', 'quiet': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'fail_fast': 'False'}
[0m04:15:16.330500 [info ] [MainThread]: dbt version: 1.10.13
[0m04:15:16.330691 [info ] [MainThread]: python version: 3.12.12
[0m04:15:16.330837 [info ] [MainThread]: python path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/bin/python3.12
[0m04:15:16.330976 [info ] [MainThread]: os info: macOS-15.7.1-arm64-arm-64bit
[0m04:15:16.363815 [info ] [MainThread]: Using profiles dir at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project
[0m04:15:16.364101 [info ] [MainThread]: Using profiles.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/profiles.yml
[0m04:15:16.364257 [info ] [MainThread]: Using dbt_project.yml file at /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/dbt_project.yml
[0m04:15:16.364524 [info ] [MainThread]: adapter type: clickhouse
[0m04:15:16.364674 [info ] [MainThread]: adapter version: 1.9.5
[0m04:15:16.414694 [info ] [MainThread]: Configuration:
[0m04:15:16.414988 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:15:16.415139 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m04:15:16.415281 [info ] [MainThread]: Required dependencies:
[0m04:15:16.415497 [debug] [MainThread]: Executing "git --help"
[0m04:15:16.431303 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:15:16.431865 [debug] [MainThread]: STDERR: "b''"
[0m04:15:16.432068 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:15:16.432241 [info ] [MainThread]: Connection:
[0m04:15:16.432413 [info ] [MainThread]:   driver: None
[0m04:15:16.432547 [info ] [MainThread]:   host: localhost
[0m04:15:16.432679 [info ] [MainThread]:   port: 8124
[0m04:15:16.432806 [info ] [MainThread]:   user: qi
[0m04:15:16.432937 [info ] [MainThread]:   schema: default
[0m04:15:16.433062 [info ] [MainThread]:   retries: 1
[0m04:15:16.433192 [info ] [MainThread]:   cluster: None
[0m04:15:16.433318 [info ] [MainThread]:   database_engine: None
[0m04:15:16.433446 [info ] [MainThread]:   cluster_mode: False
[0m04:15:16.433572 [info ] [MainThread]:   secure: False
[0m04:15:16.433695 [info ] [MainThread]:   verify: True
[0m04:15:16.433984 [info ] [MainThread]:   client_cert: None
[0m04:15:16.434171 [info ] [MainThread]:   client_cert_key: None
[0m04:15:16.434314 [info ] [MainThread]:   connect_timeout: 10
[0m04:15:16.434444 [info ] [MainThread]:   send_receive_timeout: 300
[0m04:15:16.434571 [info ] [MainThread]:   sync_request_timeout: 5
[0m04:15:16.434696 [info ] [MainThread]:   compress_block_size: 1048576
[0m04:15:16.434821 [info ] [MainThread]:   compression: 
[0m04:15:16.434944 [info ] [MainThread]:   check_exchange: True
[0m04:15:16.435065 [info ] [MainThread]:   custom_settings: None
[0m04:15:16.435184 [info ] [MainThread]:   use_lw_deletes: False
[0m04:15:16.435304 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m04:15:16.435425 [info ] [MainThread]:   tcp_keepalive: False
[0m04:15:16.435852 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m04:15:16.497406 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m04:15:16.497839 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:15:16.764955 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m04:15:16.766646 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:15:16.774291 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:15:16.774547 [info ] [MainThread]: [32mAll checks passed![0m
[0m04:15:16.776806 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.48962462, "process_in_blocks": "0", "process_kernel_time": 0.16188, "process_mem_max_rss": "159285248", "process_out_blocks": "0", "process_user_time": 1.020862}
[0m04:15:16.777088 [debug] [MainThread]: Command `dbt debug` succeeded at 04:15:16.777037 after 0.49 seconds
[0m04:15:16.777293 [debug] [MainThread]: Connection 'debug' was left open.
[0m04:15:16.777572 [debug] [MainThread]: On debug: Close
[0m04:15:16.777851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b54f470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfb2cc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb00620>]}
[0m04:15:16.778084 [debug] [MainThread]: Flushing usage events
[0m04:15:17.381336 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:17:41.162439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10600fb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107176660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071760f0>]}


============================== 04:17:41.164943 | cce55ca9-b2b8-459e-8b4e-9763430d845f ==============================
[0m04:17:41.164943 [info ] [MainThread]: Running with dbt=1.10.13
[0m04:17:41.165275 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'no_print': 'None', 'debug': 'False', 'invocation_command': 'dbt run', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'empty': 'False', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default'}
[0m04:17:41.252601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f7a2a0>]}
[0m04:17:41.282111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10630a540>]}
[0m04:17:41.282614 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m04:17:41.348203 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m04:17:41.348705 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m04:17:41.348911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073b8d10>]}
[0m04:17:41.998360 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m04:17:42.001309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073acf50>]}
[0m04:17:42.040428 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m04:17:42.041523 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m04:17:42.052463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072cc4d0>]}
[0m04:17:42.052737 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m04:17:42.052922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107113bf0>]}
[0m04:17:42.053793 [info ] [MainThread]: 
[0m04:17:42.053975 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:17:42.054118 [info ] [MainThread]: 
[0m04:17:42.054370 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m04:17:42.057230 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m04:17:42.062676 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:17:42.346863 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m04:17:42.348658 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:17:42.356955 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m04:17:42.357263 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m04:17:42.361326 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m04:17:42.364021 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m04:17:42.365062 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m04:17:42.368311 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m04:17:42.376328 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m04:17:42.377220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107927ad0>]}
[0m04:17:42.380226 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m04:17:42.380531 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m04:17:42.380766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m04:17:42.380944 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m04:17:42.384534 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m04:17:42.385109 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m04:17:42.395935 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m04:17:42.411071 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.daily_prices
          )
        
        ...
[0m04:17:42.414377 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.daily_prices
          )
        
        
[0m04:17:42.418743 [debug] [Thread-1 (]: Database Error in model daily_prices (models/market/daily_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 557 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.419638 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107efbe90>]}
[0m04:17:42.420004 [error] [Thread-1 (]: 1 of 4 ERROR creating sql table model `default_market`.`daily_prices` .......... [[31mERROR[0m in 0.04s]
[0m04:17:42.420310 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m04:17:42.420502 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m04:17:42.420730 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m04:17:42.420954 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m04:17:42.421134 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m04:17:42.422115 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m04:17:42.422411 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.daily_prices' to be skipped because of status 'error'.  Reason: Database Error in model daily_prices (models/market/daily_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 557 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124).
[0m04:17:42.423305 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m04:17:42.424484 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m04:17:42.425085 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.monthly_prices
          )
        
        ...
[0m04:17:42.427108 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.monthly_prices
          )
        
        
[0m04:17:42.429714 [debug] [Thread-1 (]: Database Error in model monthly_prices (models/market/monthly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 563 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.430022 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa01310>]}
[0m04:17:42.430363 [error] [Thread-1 (]: 2 of 4 ERROR creating sql table model `default_market`.`monthly_prices` ........ [[31mERROR[0m in 0.01s]
[0m04:17:42.430664 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m04:17:42.430867 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m04:17:42.431108 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.monthly_prices' to be skipped because of status 'error'.  Reason: Database Error in model monthly_prices (models/market/monthly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 563 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124).
[0m04:17:42.431363 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m04:17:42.431653 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m04:17:42.431830 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m04:17:42.433012 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m04:17:42.433514 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m04:17:42.434714 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m04:17:42.435383 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.quarterly_prices
          )
        
        ...
[0m04:17:42.437420 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.quarterly_prices
          )
        
        
[0m04:17:42.440262 [debug] [Thread-1 (]: Database Error in model quarterly_prices (models/market/quarterly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 569 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.440635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9f3080>]}
[0m04:17:42.440995 [error] [Thread-1 (]: 3 of 4 ERROR creating sql table model `default_market`.`quarterly_prices` ...... [[31mERROR[0m in 0.01s]
[0m04:17:42.441521 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m04:17:42.441822 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m04:17:42.442171 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.quarterly_prices' to be skipped because of status 'error'.  Reason: Database Error in model quarterly_prices (models/market/quarterly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 569 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124).
[0m04:17:42.442708 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m04:17:42.443099 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m04:17:42.443394 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m04:17:42.444633 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m04:17:42.445166 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m04:17:42.446400 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m04:17:42.447053 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.weekly_prices
          )
        
        ...
[0m04:17:42.449170 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.weekly_prices
          )
        
        
[0m04:17:42.452014 [debug] [Thread-1 (]: Database Error in model weekly_prices (models/market/weekly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 560 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.452357 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cce55ca9-b2b8-459e-8b4e-9763430d845f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aab3920>]}
[0m04:17:42.452734 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model `default_market`.`weekly_prices` ......... [[31mERROR[0m in 0.01s]
[0m04:17:42.453201 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m04:17:42.453506 [debug] [Thread-4 (]: Marking all children of 'model.qi_dbt_project.weekly_prices' to be skipped because of status 'error'.  Reason: Database Error in model weekly_prices (models/market/weekly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 560 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124).
[0m04:17:42.454331 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:17:42.454563 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m04:17:42.454763 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m04:17:42.455013 [info ] [MainThread]: 
[0m04:17:42.455179 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.40 seconds (0.40s).
[0m04:17:42.455694 [debug] [MainThread]: Command end result
[0m04:17:42.469124 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m04:17:42.470465 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m04:17:42.473609 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m04:17:42.473785 [info ] [MainThread]: 
[0m04:17:42.473974 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m04:17:42.474141 [info ] [MainThread]: 
[0m04:17:42.474340 [error] [MainThread]: [31mFailure in model daily_prices (models/market/daily_prices.sql)[0m
[0m04:17:42.474532 [error] [MainThread]:   Database Error in model daily_prices (models/market/daily_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 557 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.474692 [info ] [MainThread]: 
[0m04:17:42.474860 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/market/daily_prices.sql
[0m04:17:42.475001 [info ] [MainThread]: 
[0m04:17:42.475171 [error] [MainThread]: [31mFailure in model monthly_prices (models/market/monthly_prices.sql)[0m
[0m04:17:42.475348 [error] [MainThread]:   Database Error in model monthly_prices (models/market/monthly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 563 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.475493 [info ] [MainThread]: 
[0m04:17:42.475652 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/market/monthly_prices.sql
[0m04:17:42.475783 [info ] [MainThread]: 
[0m04:17:42.475945 [error] [MainThread]: [31mFailure in model quarterly_prices (models/market/quarterly_prices.sql)[0m
[0m04:17:42.476113 [error] [MainThread]:   Database Error in model quarterly_prices (models/market/quarterly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 569 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.476253 [info ] [MainThread]: 
[0m04:17:42.476410 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/market/quarterly_prices.sql
[0m04:17:42.476543 [info ] [MainThread]: 
[0m04:17:42.476703 [error] [MainThread]: [31mFailure in model weekly_prices (models/market/weekly_prices.sql)[0m
[0m04:17:42.476872 [error] [MainThread]:   Database Error in model weekly_prices (models/market/weekly_prices.sql)
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 560 ()) (line 24, col 11): )
          
          . Expected one of: SELECT query, possibly with UNION, list of union elements, SELECT query, subquery, possibly with UNION, SELECT subquery, SELECT query, WITH, FROM, SELECT, EXPLAIN, EXPLAIN. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m04:17:42.477010 [info ] [MainThread]: 
[0m04:17:42.477161 [info ] [MainThread]:   compiled code at target/compiled/qi_dbt_project/models/market/weekly_prices.sql
[0m04:17:42.477288 [info ] [MainThread]: 
[0m04:17:42.477443 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 NO-OP=0 TOTAL=4
[0m04:17:42.479763 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.3532338, "process_in_blocks": "0", "process_kernel_time": 0.200707, "process_mem_max_rss": "170328064", "process_out_blocks": "0", "process_user_time": 1.868252}
[0m04:17:42.480182 [debug] [MainThread]: Command `dbt run` failed at 04:17:42.480136 after 1.35 seconds
[0m04:17:42.480417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071133e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078bbd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108331610>]}
[0m04:17:42.480607 [debug] [MainThread]: Flushing usage events
[0m04:17:43.126162 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:35:36.056253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109377bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096666c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109666180>]}


============================== 11:35:36.059607 | d9e844e0-2113-48e6-a6ca-278776d966d1 ==============================
[0m11:35:36.059607 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:35:36.059960 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'target_path': 'None', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'quiet': 'False', 'invocation_command': 'dbt run', 'static_parser': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'printer_width': '80', 'write_json': 'True', 'debug': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_experimental_parser': 'False', 'no_print': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'log_format': 'default', 'use_colors': 'True', 'indirect_selection': 'eager', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False'}
[0m11:35:36.155243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c22690>]}
[0m11:35:36.184787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10969b830>]}
[0m11:35:36.185369 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:35:36.253227 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:35:36.315296 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m11:35:36.315658 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/weekly_prices.sql
[0m11:35:36.315875 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/monthly_prices.sql
[0m11:35:36.316084 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/daily_prices.sql
[0m11:35:36.316286 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/quarterly_prices.sql
[0m11:35:36.526956 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m11:35:36.530226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109cd0590>]}
[0m11:35:36.568042 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:35:36.569914 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:35:36.581961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a7f020>]}
[0m11:35:36.582256 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:35:36.582455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109eea060>]}
[0m11:35:36.583460 [info ] [MainThread]: 
[0m11:35:36.583676 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:35:36.583830 [info ] [MainThread]: 
[0m11:35:36.584113 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:35:36.587356 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:35:36.592883 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:37.034546 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:35:37.036440 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.047989 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__default_market)
[0m11:35:37.051680 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:35:37.055709 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.056517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098446e0>]}
[0m11:35:37.058128 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:35:37.058410 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:35:37.058636 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:35:37.058816 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:35:37.063278 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:35:37.063810 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:35:37.074398 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:35:37.090489 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:35:37.096046 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:35:37.105095 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:35:37.107977 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.110119 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:35:37.110830 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:35:37.113383 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.124184 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fdd160>]}
[0m11:35:37.124551 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.07s]
[0m11:35:37.124881 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:35:37.125084 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:35:37.125317 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:35:37.125529 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:35:37.125700 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:35:37.126731 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:35:37.127169 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:35:37.128386 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:35:37.129007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:35:37.134354 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:35:37.136033 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:35:37.138247 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.139450 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:35:37.139943 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:35:37.142598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.143823 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097ecda0>]}
[0m11:35:37.144188 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:35:37.144472 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:35:37.144661 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:35:37.144994 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:35:37.145288 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:35:37.145479 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:35:37.147466 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:35:37.147914 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:35:37.149107 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:35:37.149740 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:35:37.157490 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:35:37.159264 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:35:37.161757 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.163086 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:35:37.163609 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:35:37.166006 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.166998 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cfd8410>]}
[0m11:35:37.167317 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:35:37.167581 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:35:37.167765 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:35:37.168143 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:35:37.168505 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:35:37.168702 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:35:37.169892 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:35:37.170345 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:35:37.171551 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:35:37.172202 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:35:37.177312 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.179050 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:35:37.181801 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.183155 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:35:37.183683 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:35:37.186226 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:37.187323 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e844e0-2113-48e6-a6ca-278776d966d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cec2870>]}
[0m11:35:37.187674 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:35:37.187960 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:35:37.188544 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:35:37.188732 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:35:37.188894 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:35:37.189126 [info ] [MainThread]: 
[0m11:35:37.189296 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.61 seconds (0.61s).
[0m11:35:37.189786 [debug] [MainThread]: Command end result
[0m11:35:37.202920 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:35:37.204005 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:35:37.207153 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:35:37.207332 [info ] [MainThread]: 
[0m11:35:37.207526 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:35:37.207678 [info ] [MainThread]: 
[0m11:35:37.207847 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:35:37.210746 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1947646, "process_in_blocks": "0", "process_kernel_time": 0.256685, "process_mem_max_rss": "169902080", "process_out_blocks": "0", "process_user_time": 1.52261}
[0m11:35:37.211014 [debug] [MainThread]: Command `dbt run` succeeded at 11:35:37.210967 after 1.20 seconds
[0m11:35:37.211216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096665d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093771d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d534a0>]}
[0m11:35:37.211408 [debug] [MainThread]: Flushing usage events
[0m11:35:37.735516 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:41:46.143651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a1970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1e570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1e000>]}


============================== 11:41:46.146895 | 44423d54-f36c-496a-a0d1-33df90e28ea0 ==============================
[0m11:41:46.146895 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:41:46.147249 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'debug': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'introspect': 'True', 'partial_parse': 'True', 'static_parser': 'True', 'warn_error': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'invocation_command': 'dbt run --full-refresh', 'fail_fast': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'write_json': 'True', 'log_format': 'default', 'use_colors': 'True'}
[0m11:41:46.241983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e1d970>]}
[0m11:41:46.272152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064f6240>]}
[0m11:41:46.273136 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:41:46.343223 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:41:46.406977 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:41:46.407255 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:41:46.410558 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
[0m11:41:46.428622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074db500>]}
[0m11:41:46.465975 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:41:46.467229 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:41:46.478680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107738ad0>]}
[0m11:41:46.478962 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:41:46.479145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741ce90>]}
[0m11:41:46.480107 [info ] [MainThread]: 
[0m11:41:46.480306 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:41:46.480453 [info ] [MainThread]: 
[0m11:41:46.480712 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:41:46.483741 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:41:46.490683 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:41:46.826293 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:41:46.828157 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.837910 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m11:41:46.838269 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m11:41:46.842539 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m11:41:46.845047 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.846100 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m11:41:46.849362 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:41:46.852126 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.852926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a000770>]}
[0m11:41:46.854388 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:41:46.854680 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:41:46.854912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:41:46.855094 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:41:46.858652 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:41:46.859114 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:41:46.870707 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:41:46.886336 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:41:46.891051 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.900362 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:41:46.903316 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.905593 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:41:46.906125 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:41:46.908877 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.919815 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104799130>]}
[0m11:41:46.920215 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.06s]
[0m11:41:46.920520 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:41:46.920730 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:41:46.920960 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:41:46.921174 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:41:46.921421 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:41:46.922600 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:41:46.923027 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:41:46.924232 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:41:46.924878 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:41:46.931462 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:41:46.933107 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:41:46.935485 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.936700 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:41:46.937180 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:41:46.939879 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.941008 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d099280>]}
[0m11:41:46.941352 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:41:46.941677 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:41:46.942050 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:41:46.942418 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:41:46.942741 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:41:46.942951 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:41:46.944138 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:41:46.944582 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:41:46.945761 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:41:46.946378 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:41:46.952777 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:41:46.955371 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:41:46.957812 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.959057 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:41:46.959521 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:41:46.962127 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.963240 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0c6a20>]}
[0m11:41:46.963603 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:41:46.963890 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:41:46.964092 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:41:46.964370 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:41:46.964637 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:41:46.964833 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:41:46.965987 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:41:46.966424 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:41:46.967648 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:41:46.968293 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:41:46.976618 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:41:46.978407 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:41:46.981004 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.982153 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:41:46.982664 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:41:46.985102 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:41:46.986165 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44423d54-f36c-496a-a0d1-33df90e28ea0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c783440>]}
[0m11:41:46.986504 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:41:46.986777 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:41:46.987370 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:41:46.987526 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:41:46.987679 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:41:46.987911 [info ] [MainThread]: 
[0m11:41:46.988063 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m11:41:46.988540 [debug] [MainThread]: Command end result
[0m11:41:47.001254 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:41:47.002375 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:41:47.005499 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:41:47.005690 [info ] [MainThread]: 
[0m11:41:47.005884 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:41:47.006038 [info ] [MainThread]: 
[0m11:41:47.006204 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:41:47.008647 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.90499693, "process_in_blocks": "0", "process_kernel_time": 0.220099, "process_mem_max_rss": "165134336", "process_out_blocks": "0", "process_user_time": 1.332627}
[0m11:41:47.008916 [debug] [MainThread]: Command `dbt run` succeeded at 11:41:47.008874 after 0.91 seconds
[0m11:41:47.009124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10611edb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10741d2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071d74a0>]}
[0m11:41:47.009320 [debug] [MainThread]: Flushing usage events
[0m11:41:47.573415 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:45:26.995745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bd41d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce65a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce6060>]}


============================== 11:45:26.998747 | 744d8abe-ebde-4f6b-971c-9018fa0fa188 ==============================
[0m11:45:26.998747 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:45:26.999080 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'empty': 'False', 'log_format': 'default', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'target_path': 'None', 'quiet': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'invocation_command': 'dbt run --full-refresh', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'introspect': 'True', 'partial_parse': 'True', 'no_print': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project'}
[0m11:45:27.091803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cc4140>]}
[0m11:45:27.122771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10855e780>]}
[0m11:45:27.123824 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:45:27.190620 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:45:27.234435 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:45:27.234730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109196ea0>]}
[0m11:45:27.884670 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m11:45:27.887534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109369a60>]}
[0m11:45:27.924306 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:45:27.925445 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:45:27.936509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca1b20>]}
[0m11:45:27.936775 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:45:27.936957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109369b50>]}
[0m11:45:27.937853 [info ] [MainThread]: 
[0m11:45:27.938041 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:45:27.938191 [info ] [MainThread]: 
[0m11:45:27.938445 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:45:27.941456 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:45:27.946995 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:45:28.275036 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:45:28.276863 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.287203 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_)
[0m11:45:28.287549 [debug] [ThreadPool]: Creating schema "schema: "default_"
"
[0m11:45:28.291560 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_"} */
create database if not exists `default_`
        
  
        
  ...
[0m11:45:28.293945 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.294992 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_, now list__default_)
[0m11:45:28.298337 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_'
      

  ...
[0m11:45:28.304093 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.305098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094bf6b0>]}
[0m11:45:28.307065 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:45:28.307381 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_`.`daily_prices` ......................... [RUN]
[0m11:45:28.307625 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_, now model.qi_dbt_project.daily_prices)
[0m11:45:28.307804 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:45:28.311438 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:45:28.311879 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:45:28.322545 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:45:28.337832 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:45:28.345043 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.354578 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_'
      
    
    order by position
  ...
[0m11:45:28.360409 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.362723 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:45:28.363231 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:45:28.367292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.379426 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9288c0>]}
[0m11:45:28.379896 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_`.`daily_prices` .................... [[32mOK[0m in 0.07s]
[0m11:45:28.380234 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:45:28.380469 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:45:28.380767 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_`.`monthly_prices` ....................... [RUN]
[0m11:45:28.381004 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:45:28.381193 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:45:28.383291 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:45:28.383711 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:45:28.384957 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:45:28.385631 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:45:28.395252 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.397087 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_'
      
    
    order by position
  ...
[0m11:45:28.399653 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.400810 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:45:28.401236 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:45:28.404117 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.405378 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c254cb0>]}
[0m11:45:28.405775 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_`.`monthly_prices` .................. [[32mOK[0m in 0.02s]
[0m11:45:28.406081 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:45:28.406297 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:45:28.406561 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_`.`quarterly_prices` ..................... [RUN]
[0m11:45:28.406774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:45:28.406943 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:45:28.408163 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:45:28.408534 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:45:28.409701 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:45:28.410406 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:45:28.415594 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.417317 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_'
      
    
    order by position
  ...
[0m11:45:28.420068 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.421188 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:45:28.421636 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:45:28.424336 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.425450 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c24e390>]}
[0m11:45:28.425797 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_`.`quarterly_prices` ................ [[32mOK[0m in 0.02s]
[0m11:45:28.426069 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:45:28.426257 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:45:28.426594 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_`.`weekly_prices` ........................ [RUN]
[0m11:45:28.426953 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:45:28.427159 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:45:28.428414 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:45:28.428849 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:45:28.430038 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:45:28.430774 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:45:28.436075 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:45:28.438039 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_'
      
    
    order by position
  ...
[0m11:45:28.440833 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.442237 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:45:28.442762 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:45:28.445587 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:45:28.446781 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '744d8abe-ebde-4f6b-971c-9018fa0fa188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2d0da0>]}
[0m11:45:28.447166 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_`.`weekly_prices` ................... [[32mOK[0m in 0.02s]
[0m11:45:28.447458 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:45:28.448128 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:45:28.448332 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:45:28.448498 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:45:28.448767 [info ] [MainThread]: 
[0m11:45:28.448951 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m11:45:28.449476 [debug] [MainThread]: Command end result
[0m11:45:28.463541 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:45:28.464699 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:45:28.468277 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:45:28.468513 [info ] [MainThread]: 
[0m11:45:28.468711 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:45:28.468869 [info ] [MainThread]: 
[0m11:45:28.469037 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:45:28.471504 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.513519, "process_in_blocks": "0", "process_kernel_time": 0.231999, "process_mem_max_rss": "170098688", "process_out_blocks": "0", "process_user_time": 1.964992}
[0m11:45:28.471744 [debug] [MainThread]: Command `dbt run` succeeded at 11:45:28.471702 after 1.51 seconds
[0m11:45:28.471934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ce6330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109375340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093763c0>]}
[0m11:45:28.472114 [debug] [MainThread]: Flushing usage events
[0m11:45:28.934601 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:47:42.249879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e52330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8e540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8dee0>]}


============================== 11:47:42.253011 | 761ca6ac-137a-4541-a3f1-acad3e674270 ==============================
[0m11:47:42.253011 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:47:42.253377 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'debug': 'False', 'version_check': 'True', 'empty': 'False', 'target_path': 'None', 'static_parser': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'introspect': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'write_json': 'True', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run --full-refresh', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'printer_width': '80'}
[0m11:47:42.348067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10713af60>]}
[0m11:47:42.380546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058c20f0>]}
[0m11:47:42.381663 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:47:42.450359 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:47:42.497020 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:47:42.497371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10690d5b0>]}
[0m11:47:43.165519 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
[0m11:47:43.168441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f498e0>]}
[0m11:47:43.204616 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:47:43.205775 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:47:43.216621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107752960>]}
[0m11:47:43.216897 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:47:43.217081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077602f0>]}
[0m11:47:43.217961 [info ] [MainThread]: 
[0m11:47:43.218150 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:47:43.218293 [info ] [MainThread]: 
[0m11:47:43.218541 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:47:43.221553 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:47:43.226562 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:47:43.556379 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:47:43.558177 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.568335 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m11:47:43.568643 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m11:47:43.572680 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m11:47:43.574965 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.576004 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m11:47:43.579351 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:47:43.584637 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:47:43.585494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ca420>]}
[0m11:47:43.587691 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:47:43.588032 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:47:43.588293 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:47:43.588478 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:47:43.592127 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:47:43.592576 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:47:43.603088 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:47:43.618805 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:47:43.627643 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:47:43.637110 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:47:43.639902 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.642091 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:47:43.642627 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:47:43.645304 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.656935 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104900da0>]}
[0m11:47:43.657371 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.07s]
[0m11:47:43.657687 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:47:43.657909 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:47:43.658157 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:47:43.658445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:47:43.658626 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:47:43.660553 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:47:43.661030 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:47:43.662208 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:47:43.662840 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:47:43.667673 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.669557 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:47:43.672194 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.673349 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:47:43.673811 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:47:43.676599 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.677989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bff680>]}
[0m11:47:43.678393 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:47:43.678688 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:47:43.678901 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:47:43.679182 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:47:43.679423 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:47:43.679613 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:47:43.680894 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:47:43.681362 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:47:43.682653 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:47:43.683315 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:47:43.689191 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:47:43.690956 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:47:43.693566 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.694769 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:47:43.695257 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:47:43.697902 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.698975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4c5dc0>]}
[0m11:47:43.699305 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:47:43.699571 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:47:43.699755 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:47:43.700091 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:47:43.700417 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:47:43.700625 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:47:43.701858 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:47:43.702318 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:47:43.703615 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:47:43.704333 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:47:43.709787 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:47:43.711528 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:47:43.713945 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.715024 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:47:43.715481 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:47:43.718147 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:47:43.719358 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '761ca6ac-137a-4541-a3f1-acad3e674270', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b43fda0>]}
[0m11:47:43.719701 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:47:43.719988 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:47:43.720589 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:47:43.720775 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:47:43.720929 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:47:43.721164 [info ] [MainThread]: 
[0m11:47:43.721322 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.50 seconds (0.50s).
[0m11:47:43.721792 [debug] [MainThread]: Command end result
[0m11:47:43.735126 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:47:43.736214 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:47:43.739333 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:47:43.739523 [info ] [MainThread]: 
[0m11:47:43.739722 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:47:43.739875 [info ] [MainThread]: 
[0m11:47:43.740035 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:47:43.742771 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.5320599, "process_in_blocks": "0", "process_kernel_time": 0.222844, "process_mem_max_rss": "169885696", "process_out_blocks": "0", "process_user_time": 1.948479}
[0m11:47:43.743110 [debug] [MainThread]: Command `dbt run` succeeded at 11:47:43.743064 after 1.53 seconds
[0m11:47:43.743314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8e450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8e3f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10751fad0>]}
[0m11:47:43.743510 [debug] [MainThread]: Flushing usage events
[0m11:47:44.208391 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:48:24.170580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086004a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67a570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67a030>]}


============================== 11:48:24.173065 | 41f289a2-a322-40fe-b8c1-273507295a03 ==============================
[0m11:48:24.173065 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:48:24.173399 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'target_path': 'None', 'fail_fast': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_format': 'default', 'quiet': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'invocation_command': 'dbt run --full-refresh', 'version_check': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error': 'None', 'empty': 'False', 'static_parser': 'True', 'no_print': 'None', 'use_colors': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'partial_parse': 'True', 'printer_width': '80'}
[0m11:48:24.258962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7bb9b0>]}
[0m11:48:24.288912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6a8d70>]}
[0m11:48:24.289384 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:48:24.353689 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:48:24.405140 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:48:24.405375 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:48:24.408465 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m11:48:24.425738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abc77a0>]}
[0m11:48:24.461614 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:48:24.462804 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:48:24.470016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae38ef0>]}
[0m11:48:24.470291 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:48:24.470465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8d7500>]}
[0m11:48:24.471342 [info ] [MainThread]: 
[0m11:48:24.471532 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:48:24.471679 [info ] [MainThread]: 
[0m11:48:24.471938 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:48:24.474837 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:48:24.480736 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:48:24.764903 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:48:24.766660 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.774363 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m11:48:24.774698 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m11:48:24.778924 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m11:48:24.781429 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.782498 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m11:48:24.785810 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:48:24.788523 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.789365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8578c0>]}
[0m11:48:24.790765 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:48:24.791066 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:48:24.791301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:48:24.791486 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:48:24.795048 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:48:24.795509 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:48:24.807258 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:48:24.822216 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:48:24.830389 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:48:24.839618 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:48:24.844513 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.846970 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:48:24.847526 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:48:24.852412 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.863444 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e85280>]}
[0m11:48:24.863821 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.07s]
[0m11:48:24.864120 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:48:24.864323 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:48:24.864550 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:48:24.864821 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:48:24.865043 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:48:24.866182 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:48:24.866588 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:48:24.867730 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:48:24.868369 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:48:24.879612 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:48:24.881420 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:48:24.883794 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.885015 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:48:24.885545 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:48:24.888130 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.889284 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1183956d0>]}
[0m11:48:24.889630 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:48:24.889973 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:48:24.890191 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:48:24.890446 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:48:24.890652 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:48:24.890829 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:48:24.891966 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:48:24.892336 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:48:24.893511 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:48:24.894163 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:48:24.901344 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:48:24.903863 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:48:24.906301 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.907462 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:48:24.907917 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:48:24.910819 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.912028 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1183c3590>]}
[0m11:48:24.912378 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:48:24.912659 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:48:24.912861 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:48:24.913101 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:48:24.913296 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:48:24.913461 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:48:24.914582 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:48:24.914985 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:48:24.916155 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:48:24.916777 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:48:24.924533 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:48:24.926352 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:48:24.928925 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.930161 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:48:24.930726 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:48:24.933161 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:48:24.934263 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41f289a2-a322-40fe-b8c1-273507295a03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118347890>]}
[0m11:48:24.934604 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:48:24.934885 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:48:24.935525 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:48:24.935720 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:48:24.935888 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:48:24.936137 [info ] [MainThread]: 
[0m11:48:24.936304 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m11:48:24.936808 [debug] [MainThread]: Command end result
[0m11:48:24.950000 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:48:24.951097 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:48:24.954229 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:48:24.954412 [info ] [MainThread]: 
[0m11:48:24.954601 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:48:24.954749 [info ] [MainThread]: 
[0m11:48:24.954909 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:48:24.957127 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8221957, "process_in_blocks": "0", "process_kernel_time": 0.201959, "process_mem_max_rss": "165806080", "process_out_blocks": "0", "process_user_time": 1.299101}
[0m11:48:24.957392 [debug] [MainThread]: Command `dbt run` succeeded at 11:48:24.957346 after 0.82 seconds
[0m11:48:24.957588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67a420>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a278b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c3aba0>]}
[0m11:48:24.957781 [debug] [MainThread]: Flushing usage events
[0m11:48:25.373877 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:51:15.731020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10225d160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106472480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106471e20>]}


============================== 11:51:15.733419 | 5db0157a-41a3-4545-9122-6b9e1decf29b ==============================
[0m11:51:15.733419 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:51:15.733766 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'fail_fast': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'target_path': 'None', 'log_format': 'default', 'empty': 'False', 'partial_parse': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --full-refresh', 'version_check': 'True', 'printer_width': '80', 'no_print': 'None', 'quiet': 'False', 'use_colors': 'True', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m11:51:15.819301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5db0157a-41a3-4545-9122-6b9e1decf29b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10656c800>]}
[0m11:51:15.848454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5db0157a-41a3-4545-9122-6b9e1decf29b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10225d160>]}
[0m11:51:15.848920 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:51:15.913224 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:51:15.964701 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:51:15.964996 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://macros/naming.sql
[0m11:51:15.966564 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m11:51:16.572277 [error] [MainThread]: Encountered an error:
can not serialize 'Undefined' object
[0m11:51:16.574480 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 272, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 303, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 373, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 350, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 389, in wrapper
    setup_manifest(ctx, write=write, write_perf_info=write_perf_info)
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 416, in setup_manifest
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 2123, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 320, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 518, in load
    self.write_manifest_for_partial_parse()
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 826, in write_manifest_for_partial_parse
    manifest_msgpack = self.manifest.to_msgpack(extended_mashumaro_encoder)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 3, in __mashumaro_to_msgpack__
  File "<string>", line 91, in __mashumaro_to_msgpack__
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 141, in extended_mashumaro_encoder
    return msgpack.packb(data, default=extended_msgpack_encoder, use_bin_type=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/msgpack/__init__.py", line 36, in packb
    return Packer(**kwargs).pack(o)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "msgpack/_packer.pyx", line 279, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 276, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 270, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 257, in msgpack._cmsgpack.Packer._pack_inner
TypeError: can not serialize 'Undefined' object

[0m11:51:16.576388 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.8818909, "process_in_blocks": "0", "process_kernel_time": 0.138178, "process_mem_max_rss": "122454016", "process_out_blocks": "0", "process_user_time": 1.493102}
[0m11:51:16.576840 [debug] [MainThread]: Command `dbt run` failed at 11:51:16.576684 after 0.88 seconds
[0m11:51:16.577124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053900e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106542840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10644a510>]}
[0m11:51:16.577342 [debug] [MainThread]: Flushing usage events
[0m11:51:17.079221 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:51:38.430235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e6cc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f765a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f76060>]}


============================== 11:51:38.432938 | 14ec5218-e80b-4590-a2b5-9a8d7ffbd81f ==============================
[0m11:51:38.432938 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:51:38.433286 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'static_parser': 'True', 'log_cache_events': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'introspect': 'True', 'warn_error': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'indirect_selection': 'eager', 'write_json': 'True', 'empty': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'target_path': 'None', 'printer_width': '80', 'fail_fast': 'False', 'quiet': 'False', 'invocation_command': 'dbt run --full-refresh'}
[0m11:51:38.522972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c188c0>]}
[0m11:51:38.554684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff3710>]}
[0m11:51:38.555225 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:51:38.622874 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:51:38.677149 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:51:38.677512 [debug] [MainThread]: Partial parsing: added file: qi_dbt_project://macros/naming.sql
[0m11:51:38.711117 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m11:51:38.714097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110429850>]}
[0m11:51:38.751485 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:51:38.752795 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:51:38.760636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11048b200>]}
[0m11:51:38.760938 [info ] [MainThread]: Found 4 models, 3 data tests, 485 macros
[0m11:51:38.761119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110068830>]}
[0m11:51:38.762057 [info ] [MainThread]: 
[0m11:51:38.762265 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:51:38.762419 [info ] [MainThread]: 
[0m11:51:38.762694 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:51:38.766288 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:51:38.772637 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:51:39.050760 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:51:39.052538 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.060848 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_market)
[0m11:51:39.061160 [debug] [ThreadPool]: Creating schema "schema: "default_market"
"
[0m11:51:39.065366 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__default_market"} */
create database if not exists `default_market`
        
  
        
  ...
[0m11:51:39.067949 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.068988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_market, now list__default_market)
[0m11:51:39.072313 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__default_market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_market'
      

  ...
[0m11:51:39.074977 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.075753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11000c890>]}
[0m11:51:39.077042 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:51:39.077333 [info ] [Thread-1 (]: 1 of 4 START sql table model `default_market`.`daily_prices` ................... [RUN]
[0m11:51:39.077562 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_market, now model.qi_dbt_project.daily_prices)
[0m11:51:39.077741 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:51:39.081187 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:51:39.081605 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:51:39.091925 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:51:39.107055 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `default_market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:51:39.115250 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:39.124529 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:51:39.128871 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.131001 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:51:39.131526 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:51:39.136276 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.147007 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f2d1f0>]}
[0m11:51:39.147378 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default_market`.`daily_prices` .............. [[32mOK[0m in 0.07s]
[0m11:51:39.147675 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:51:39.147876 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:51:39.148100 [info ] [Thread-1 (]: 2 of 4 START sql table model `default_market`.`monthly_prices` ................. [RUN]
[0m11:51:39.148308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:51:39.148476 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:51:39.149502 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:51:39.149937 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:51:39.151863 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:51:39.152476 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `default_market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:51:39.162294 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:39.163969 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:51:39.166505 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.167615 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:51:39.168080 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:51:39.170633 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.171719 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148f7ce0>]}
[0m11:51:39.172058 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default_market`.`monthly_prices` ............ [[32mOK[0m in 0.02s]
[0m11:51:39.172333 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:51:39.172522 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:51:39.172871 [info ] [Thread-1 (]: 3 of 4 START sql table model `default_market`.`quarterly_prices` ............... [RUN]
[0m11:51:39.173203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:51:39.173403 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:51:39.174622 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:51:39.175075 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:51:39.176246 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:51:39.176915 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `default_market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:51:39.187215 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:39.189093 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:51:39.191802 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.192952 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:51:39.193428 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:51:39.195925 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.197046 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147eed50>]}
[0m11:51:39.197385 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default_market`.`quarterly_prices` .......... [[32mOK[0m in 0.02s]
[0m11:51:39.197662 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:51:39.197854 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:51:39.198100 [info ] [Thread-1 (]: 4 of 4 START sql table model `default_market`.`weekly_prices` .................. [RUN]
[0m11:51:39.198301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:51:39.198468 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:51:39.199566 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:51:39.199970 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:51:39.201155 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:51:39.202036 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `default_market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:51:39.210952 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:39.212837 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'default_market'
      
    
    order by position
  ...
[0m11:51:39.215431 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.216538 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:51:39.217003 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `default_market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:51:39.219205 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:39.220437 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14ec5218-e80b-4590-a2b5-9a8d7ffbd81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11493b560>]}
[0m11:51:39.220790 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default_market`.`weekly_prices` ............. [[32mOK[0m in 0.02s]
[0m11:51:39.221081 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:51:39.221711 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:51:39.221904 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:51:39.222073 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:51:39.222319 [info ] [MainThread]: 
[0m11:51:39.222487 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m11:51:39.223015 [debug] [MainThread]: Command end result
[0m11:51:39.236472 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:51:39.237577 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:51:39.240590 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:51:39.240766 [info ] [MainThread]: 
[0m11:51:39.240962 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:51:39.241109 [info ] [MainThread]: 
[0m11:51:39.241271 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:51:39.243541 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8513326, "process_in_blocks": "0", "process_kernel_time": 0.199076, "process_mem_max_rss": "167804928", "process_out_blocks": "0", "process_user_time": 1.330064}
[0m11:51:39.243784 [debug] [MainThread]: Command `dbt run` succeeded at 11:51:39.243742 after 0.85 seconds
[0m11:51:39.243984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e94050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1149507d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114951130>]}
[0m11:51:39.244165 [debug] [MainThread]: Flushing usage events
[0m11:51:39.650284 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:53:56.269017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103937b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106914dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106487ef0>]}


============================== 11:53:56.271732 | a329feb5-7c90-49c3-8b1e-562f3e5ca819 ==============================
[0m11:53:56.271732 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:53:56.272090 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'invocation_command': 'dbt clean', 'write_json': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'target_path': 'None', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'log_cache_events': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'printer_width': '80', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'no_print': 'None', 'empty': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m11:53:56.331080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a329feb5-7c90-49c3-8b1e-562f3e5ca819', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106914dd0>]}
[0m11:53:56.340690 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.11157, "process_in_blocks": "0", "process_kernel_time": 0.107164, "process_mem_max_rss": "110723072", "process_out_blocks": "0", "process_user_time": 0.768911}
[0m11:53:56.341028 [debug] [MainThread]: Command `dbt clean` succeeded at 11:53:56.340975 after 0.11 seconds
[0m11:53:56.341241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047a2e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e96f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106caf320>]}
[0m11:53:56.341431 [debug] [MainThread]: Flushing usage events
[0m11:53:56.841573 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:54:09.601187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e8410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098f24e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098f1f70>]}


============================== 11:54:09.603956 | 580dcf39-ff95-4a15-ba8c-2c917e79e6d5 ==============================
[0m11:54:09.603956 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:54:09.604296 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'empty': 'False', 'debug': 'False', 'invocation_command': 'dbt run --full-refresh', 'warn_error': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_cache_events': 'False', 'no_print': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'target_path': 'None', 'static_parser': 'True', 'use_colors': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'log_format': 'default', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'use_experimental_parser': 'False'}
[0m11:54:09.694717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '580dcf39-ff95-4a15-ba8c-2c917e79e6d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a3f6b0>]}
[0m11:54:09.725574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '580dcf39-ff95-4a15-ba8c-2c917e79e6d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109893e00>]}
[0m11:54:09.726118 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:54:09.793286 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:54:09.793847 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:54:09.794063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '580dcf39-ff95-4a15-ba8c-2c917e79e6d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b30830>]}
[0m11:54:10.459051 [error] [MainThread]: Encountered an error:
can not serialize 'Undefined' object
[0m11:54:10.460365 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 178, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 272, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 303, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 373, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 350, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 389, in wrapper
    setup_manifest(ctx, write=write, write_perf_info=write_perf_info)
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/cli/requires.py", line 416, in setup_manifest
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 2123, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 320, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 518, in load
    self.write_manifest_for_partial_parse()
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 826, in write_manifest_for_partial_parse
    manifest_msgpack = self.manifest.to_msgpack(extended_mashumaro_encoder)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 3, in __mashumaro_to_msgpack__
  File "<string>", line 91, in __mashumaro_to_msgpack__
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/dbt/parser/manifest.py", line 141, in extended_mashumaro_encoder
    return msgpack.packb(data, default=extended_msgpack_encoder, use_bin_type=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/deucalion/Developer/Python/Ademola/Family Office/qi/venv/lib/python3.12/site-packages/msgpack/__init__.py", line 36, in packb
    return Packer(**kwargs).pack(o)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "msgpack/_packer.pyx", line 279, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 276, in msgpack._cmsgpack.Packer.pack
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 265, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 213, in msgpack._cmsgpack.Packer._pack_inner
  File "msgpack/_packer.pyx", line 270, in msgpack._cmsgpack.Packer._pack
  File "msgpack/_packer.pyx", line 257, in msgpack._cmsgpack.Packer._pack_inner
TypeError: can not serialize 'Undefined' object

[0m11:54:10.462068 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.8996778, "process_in_blocks": "0", "process_kernel_time": 0.150504, "process_mem_max_rss": "123830272", "process_out_blocks": "0", "process_user_time": 1.525401}
[0m11:54:10.462334 [debug] [MainThread]: Command `dbt run` failed at 11:54:10.462284 after 0.90 seconds
[0m11:54:10.462544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098f24e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fb5550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f8a600>]}
[0m11:54:10.462727 [debug] [MainThread]: Flushing usage events
[0m11:54:10.902474 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:57:02.036328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058241d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e12e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074bf950>]}


============================== 11:57:02.039087 | 45f88efa-78b4-440e-8a91-303f0371f39c ==============================
[0m11:57:02.039087 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:57:02.039431 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt clean', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'empty': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'fail_fast': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'target_path': 'None', 'quiet': 'False', 'printer_width': '80', 'static_parser': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'use_colors': 'True'}
[0m11:57:02.101103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '45f88efa-78b4-440e-8a91-303f0371f39c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102cdf8f0>]}
[0m11:57:02.107751 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.109522335, "process_in_blocks": "0", "process_kernel_time": 0.104884, "process_mem_max_rss": "110149632", "process_out_blocks": "0", "process_user_time": 0.753536}
[0m11:57:02.108127 [debug] [MainThread]: Command `dbt clean` succeeded at 11:57:02.108067 after 0.11 seconds
[0m11:57:02.108354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e57da0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e12ff0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110010fb0>]}
[0m11:57:02.108578 [debug] [MainThread]: Flushing usage events
[0m11:57:02.581119 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:57:25.638165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fa8830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079765a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107976060>]}


============================== 11:57:25.641016 | 9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d ==============================
[0m11:57:25.641016 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:57:25.641341 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run --full-refresh', 'send_anonymous_usage_stats': 'True', 'empty': 'False', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'printer_width': '80', 'debug': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'no_print': 'None', 'quiet': 'False', 'version_check': 'True', 'fail_fast': 'False', 'introspect': 'True', 'use_colors': 'True', 'log_format': 'default', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project'}
[0m11:57:25.734275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a13770>]}
[0m11:57:25.766306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069be300>]}
[0m11:57:25.766955 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:57:25.831691 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:57:25.832173 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:57:25.832375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bd36b0>]}
[0m11:57:26.493491 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m11:57:26.496452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b60ec0>]}
[0m11:57:26.535836 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:57:26.537013 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:57:26.544005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a27bc0>]}
[0m11:57:26.544272 [info ] [MainThread]: Found 4 models, 3 data tests, 487 macros
[0m11:57:26.544453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9fe4ceab-0bfe-4797-89e4-0ea10dc9ee0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b62ab0>]}
[0m11:57:26.545335 [info ] [MainThread]: 
[0m11:57:26.545534 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:57:26.545686 [info ] [MainThread]: 
[0m11:57:26.545945 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:57:26.549390 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:57:26.555257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:57:26.849858 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:57:26.851630 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:57:26.860119 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__)
[0m11:57:26.860450 [debug] [ThreadPool]: Creating schema ""
[0m11:57:26.864743 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__"} */
create database if not exists ``
        
  
        
  ...
[0m11:57:26.867178 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__"} */
create database if not exists ``
        
  
        
  
[0m11:57:26.867674 [debug] [ThreadPool]: dbt_clickhouse adapter: Error running SQL: macro create_schema
[0m11:57:26.868169 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:57:26.868481 [debug] [MainThread]: Connection 'create__' was left open.
[0m11:57:26.868659 [debug] [MainThread]: On create__: Close
[0m11:57:26.868829 [info ] [MainThread]: 
[0m11:57:26.869023 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.32 seconds (0.32s).
[0m11:57:26.869393 [error] [MainThread]: Encountered an error:
Database Error
  Received ClickHouse exception, code: 62, server response: Code: 62. DB::Exception: Syntax error: failed at position 165 (``) (line 2, col 31): ``
          
    
          
    . Expected identifier. (SYNTAX_ERROR) (version 25.9.2.1 (official build)) (for url http://localhost:8124)
[0m11:57:26.872412 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.2763425, "process_in_blocks": "0", "process_kernel_time": 0.203752, "process_mem_max_rss": "168542208", "process_out_blocks": "0", "process_user_time": 1.808775}
[0m11:57:26.872727 [debug] [MainThread]: Command `dbt run` failed at 11:57:26.872675 after 1.28 seconds
[0m11:57:26.872944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107976480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131ccef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e003e0>]}
[0m11:57:26.873624 [debug] [MainThread]: Flushing usage events
[0m11:57:27.316291 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:59:33.034623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bd9d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073307d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd4e30>]}


============================== 11:59:33.037415 | 9606066d-8b8f-46e2-b472-8eec599e15e4 ==============================
[0m11:59:33.037415 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:59:33.037788 [debug] [MainThread]: running dbt with arguments {'empty': 'None', 'use_colors': 'True', 'version_check': 'True', 'write_json': 'True', 'static_parser': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'debug': 'False', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_cache_events': 'False', 'quiet': 'False', 'introspect': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'no_print': 'None', 'invocation_command': 'dbt clean', 'log_format': 'default', 'warn_error': 'None'}
[0m11:59:33.095627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9606066d-8b8f-46e2-b472-8eec599e15e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c75580>]}
[0m11:59:33.102822 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.10881804, "process_in_blocks": "0", "process_kernel_time": 0.110678, "process_mem_max_rss": "109772800", "process_out_blocks": "0", "process_user_time": 0.779027}
[0m11:59:33.103122 [debug] [MainThread]: Command `dbt clean` succeeded at 11:59:33.103070 after 0.11 seconds
[0m11:59:33.103317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071d20f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a3af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a3b6b0>]}
[0m11:59:33.103592 [debug] [MainThread]: Flushing usage events
[0m11:59:33.625113 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:59:42.303833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089f6f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10936e5a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10936e060>]}


============================== 11:59:42.306494 | 49c87960-4d62-402c-9df5-85611293de76 ==============================
[0m11:59:42.306494 [info ] [MainThread]: Running with dbt=1.10.13
[0m11:59:42.306845 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'invocation_command': 'dbt run --full-refresh', 'fail_fast': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'partial_parse': 'True', 'version_check': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'static_parser': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'write_json': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'introspect': 'True', 'empty': 'False', 'log_format': 'default', 'no_print': 'None'}
[0m11:59:42.395842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10648dca0>]}
[0m11:59:42.425255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094bbce0>]}
[0m11:59:42.425740 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m11:59:42.491305 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m11:59:42.491844 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:59:42.492056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10954e6c0>]}
[0m11:59:43.137423 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m11:59:43.140260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a331f40>]}
[0m11:59:43.178779 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:59:43.179937 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:59:43.186967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3fc1d0>]}
[0m11:59:43.187247 [info ] [MainThread]: Found 4 models, 3 data tests, 487 macros
[0m11:59:43.187428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4131a0>]}
[0m11:59:43.188325 [info ] [MainThread]: 
[0m11:59:43.188514 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:59:43.188654 [info ] [MainThread]: 
[0m11:59:43.188898 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:59:43.191746 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:59:43.197157 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:59:43.475651 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:59:43.477438 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.486071 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__market)
[0m11:59:43.486419 [debug] [ThreadPool]: Creating schema "schema: "market"
"
[0m11:59:43.490635 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__market"} */
create database if not exists `market`
        
  
        
  ...
[0m11:59:43.492968 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.494075 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__market, now list__market)
[0m11:59:43.497305 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m11:59:43.509761 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:59:43.510625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3df4a0>]}
[0m11:59:43.512002 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m11:59:43.512312 [info ] [Thread-1 (]: 1 of 4 START sql table model `market`.`daily_prices` ........................... [RUN]
[0m11:59:43.512564 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.daily_prices)
[0m11:59:43.512756 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m11:59:43.516381 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m11:59:43.517015 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m11:59:43.527898 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m11:59:43.542289 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:59:43.550182 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:59:43.560181 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m11:59:43.563429 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.565515 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m11:59:43.566200 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:59:43.570972 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.581622 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b248800>]}
[0m11:59:43.581996 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `market`.`daily_prices` ...................... [[32mOK[0m in 0.07s]
[0m11:59:43.582291 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m11:59:43.582494 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m11:59:43.582706 [info ] [Thread-1 (]: 2 of 4 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m11:59:43.582914 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m11:59:43.583094 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m11:59:43.584155 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m11:59:43.584598 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m11:59:43.586020 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m11:59:43.586738 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:59:43.597626 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:59:43.599331 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m11:59:43.601887 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.602992 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m11:59:43.603520 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:59:43.606283 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.607375 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7827e0>]}
[0m11:59:43.607709 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.02s]
[0m11:59:43.607990 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m11:59:43.608189 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m11:59:43.608434 [info ] [Thread-1 (]: 3 of 4 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m11:59:43.608630 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m11:59:43.608802 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m11:59:43.609953 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m11:59:43.610419 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m11:59:43.611575 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m11:59:43.612132 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:59:43.616769 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.618304 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m11:59:43.620927 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.622176 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m11:59:43.622740 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:59:43.625442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.626443 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7ed9d0>]}
[0m11:59:43.626767 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.02s]
[0m11:59:43.627039 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m11:59:43.627234 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m11:59:43.627465 [info ] [Thread-1 (]: 4 of 4 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m11:59:43.627659 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m11:59:43.627819 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m11:59:43.628937 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m11:59:43.629352 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m11:59:43.630537 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m11:59:43.631985 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
          )
        
        ...
[0m11:59:43.640506 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:59:43.642199 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m11:59:43.644634 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.645809 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m11:59:43.646317 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume")select
    '' as ticker,
    '' as short_name,
    toDate('1999-12-31') as date,
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume
where 1 = 0
  ...
[0m11:59:43.649048 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:59:43.650120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49c87960-4d62-402c-9df5-85611293de76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7f59d0>]}
[0m11:59:43.650470 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.02s]
[0m11:59:43.650759 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m11:59:43.651426 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:59:43.651659 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m11:59:43.651820 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m11:59:43.652066 [info ] [MainThread]: 
[0m11:59:43.652240 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m11:59:43.652748 [debug] [MainThread]: Command end result
[0m11:59:43.665576 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m11:59:43.666711 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m11:59:43.669816 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m11:59:43.669999 [info ] [MainThread]: 
[0m11:59:43.670192 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:59:43.670347 [info ] [MainThread]: 
[0m11:59:43.670518 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m11:59:43.672893 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.4048234, "process_in_blocks": "0", "process_kernel_time": 0.207177, "process_mem_max_rss": "169459712", "process_out_blocks": "0", "process_user_time": 1.871413}
[0m11:59:43.673177 [debug] [MainThread]: Command `dbt run` succeeded at 11:59:43.673134 after 1.41 seconds
[0m11:59:43.673376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10904fb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089f7fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c564a10>]}
[0m11:59:43.673570 [debug] [MainThread]: Flushing usage events
[0m11:59:44.120441 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:19:57.325685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c86870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728f1a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069e11f0>]}


============================== 12:19:57.328921 | c972e173-e7a8-42b8-b7da-bfb72d8d5942 ==============================
[0m12:19:57.328921 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:19:57.329243 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'no_print': 'None', 'log_format': 'default', 'indirect_selection': 'eager', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'log_cache_events': 'False', 'fail_fast': 'False', 'warn_error': 'None', 'cache_selected_only': 'False', 'quiet': 'False', 'partial_parse': 'True', 'empty': 'None'}
[0m12:19:57.389013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c972e173-e7a8-42b8-b7da-bfb72d8d5942', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ae990>]}
[0m12:19:57.401008 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.112340875, "process_in_blocks": "0", "process_kernel_time": 0.125841, "process_mem_max_rss": "109199360", "process_out_blocks": "0", "process_user_time": 0.774779}
[0m12:19:57.401326 [debug] [MainThread]: Command `dbt clean` succeeded at 12:19:57.401267 after 0.11 seconds
[0m12:19:57.401537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ee150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c77f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dc5850>]}
[0m12:19:57.401732 [debug] [MainThread]: Flushing usage events
[0m12:19:57.886316 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:20:04.121913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107428560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108976360>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108975df0>]}


============================== 12:20:04.124473 | ea88ac6c-4ee1-4470-92cf-564f4f6a0dae ==============================
[0m12:20:04.124473 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:20:04.124811 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'indirect_selection': 'eager', 'no_print': 'None', 'empty': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt run --full-refresh', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_format': 'default', 'printer_width': '80', 'target_path': 'None', 'use_experimental_parser': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error': 'None', 'log_cache_events': 'False'}
[0m12:20:04.214713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077a2660>]}
[0m12:20:04.243920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087dce30>]}
[0m12:20:04.244886 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:20:04.315725 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:20:04.316234 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:20:04.316444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4e600>]}
[0m12:20:04.943128 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `unique`. Arguments to generic tests should be
nested under the `arguments` property.`
[0m12:20:04.944392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bf9460>]}
[0m12:20:05.051174 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m12:20:05.056737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109667410>]}
[0m12:20:05.104808 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:20:05.106339 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:20:05.115577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b7ad0>]}
[0m12:20:05.115876 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 487 macros
[0m12:20:05.116067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4d8e0>]}
[0m12:20:05.117150 [info ] [MainThread]: 
[0m12:20:05.117343 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:20:05.117492 [info ] [MainThread]: 
[0m12:20:05.117754 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:20:05.120666 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:20:05.125783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:05.502123 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:20:05.503930 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.513922 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__market)
[0m12:20:05.514231 [debug] [ThreadPool]: Creating schema "schema: "market"
"
[0m12:20:05.518182 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "create__market"} */
create database if not exists `market`
        
  
        
  ...
[0m12:20:05.520482 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.521520 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__market, now list__market)
[0m12:20:05.524688 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m12:20:05.527383 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.528181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fc63c0>]}
[0m12:20:05.530321 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.daily_prices
[0m12:20:05.530599 [info ] [Thread-1 (]: 1 of 4 START sql table model `market`.`daily_prices` ........................... [RUN]
[0m12:20:05.530830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.daily_prices)
[0m12:20:05.531013 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.daily_prices
[0m12:20:05.534452 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.daily_prices"
[0m12:20:05.535106 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.daily_prices
[0m12:20:05.545866 [debug] [Thread-1 (]: Creating new relation daily_prices
[0m12:20:05.561162 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

            

    
        create table `market`.`daily_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.daily_prices (schema only)
select
    ''  as ticker,                  -- String
    ''  as short_name,              -- String
    toDate('2000-01-01') as date,   -- Date
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDateTime64('2000-01-01 00:00:00', 3) as ingested_at,  -- DateTime64(3)
    '' as batch_id,                 -- String (UUID or run id when you load)
    'yfinance' as source            -- LowCardinality(String) at load time
where 1 = 0
          )
        
        ...
[0m12:20:05.570451 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:20:05.579485 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

    select name, type from system.columns where table = 'daily_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:20:05.584060 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.586529 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.daily_prices"
[0m12:20:05.587281 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.daily_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.daily_prices"} */

  
    
    
    
        
         


        insert into `market`.`daily_prices`
        ("ticker", "short_name", "date", "open", "high", "low", "close", "adj_close", "volume", "ingested_at", "batch_id", "source")-- placeholder model: market.daily_prices (schema only)
select
    ''  as ticker,                  -- String
    ''  as short_name,              -- String
    toDate('2000-01-01') as date,   -- Date
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDateTime64('2000-01-01 00:00:00', 3) as ingested_at,  -- DateTime64(3)
    '' as batch_id,                 -- String (UUID or run id when you load)
    'yfinance' as source            -- LowCardinality(String) at load time
where 1 = 0
  ...
[0m12:20:05.591950 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.602860 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051451f0>]}
[0m12:20:05.603293 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `market`.`daily_prices` ...................... [[32mOK[0m in 0.07s]
[0m12:20:05.603609 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.daily_prices
[0m12:20:05.603820 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m12:20:05.604053 [info ] [Thread-1 (]: 2 of 4 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m12:20:05.604288 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.daily_prices, now model.qi_dbt_project.monthly_prices)
[0m12:20:05.604467 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m12:20:05.605659 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m12:20:05.606266 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m12:20:05.607692 [debug] [Thread-1 (]: Creating new relation monthly_prices
[0m12:20:05.608269 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.monthly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-31') as month_ending, -- Date (last trading day of month)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
          )
        
        ...
[0m12:20:05.618478 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:20:05.620338 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:20:05.623247 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.624512 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m12:20:05.625007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.monthly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-31') as month_ending, -- Date (last trading day of month)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
  ...
[0m12:20:05.627945 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.628990 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9707d0>]}
[0m12:20:05.629319 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.02s]
[0m12:20:05.629603 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m12:20:05.629807 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m12:20:05.630044 [info ] [Thread-1 (]: 3 of 4 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m12:20:05.630239 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m12:20:05.630419 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m12:20:05.632525 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m12:20:05.633060 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m12:20:05.634233 [debug] [Thread-1 (]: Creating new relation quarterly_prices
[0m12:20:05.634783 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.quarterly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-03-31') as quarter_ending, -- Date (last trading day of quarter)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
          )
        
        ...
[0m12:20:05.640628 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:20:05.642314 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:20:05.645119 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.646406 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m12:20:05.646985 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.quarterly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-03-31') as quarter_ending, -- Date (last trading day of quarter)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
  ...
[0m12:20:05.649862 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.650875 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f909490>]}
[0m12:20:05.651194 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.02s]
[0m12:20:05.651464 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m12:20:05.651663 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m12:20:05.651904 [info ] [Thread-1 (]: 4 of 4 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m12:20:05.652101 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m12:20:05.652274 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m12:20:05.653428 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m12:20:05.653873 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m12:20:05.655047 [debug] [Thread-1 (]: Creating new relation weekly_prices
[0m12:20:05.655759 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.weekly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-07') as week_ending,  -- Date (last trading day of week)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,                 -- max daily date used
    toDateTime64('2000-01-01 00:00:00', 3) as built_at        -- when built
where 1 = 0
          )
        
        ...
[0m12:20:05.661263 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:20:05.662920 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m12:20:05.665889 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.667241 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m12:20:05.667798 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.weekly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-07') as week_ending,  -- Date (last trading day of week)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,                 -- max daily date used
    toDateTime64('2000-01-01 00:00:00', 3) as built_at        -- when built
where 1 = 0
  ...
[0m12:20:05.670607 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:20:05.671637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea88ac6c-4ee1-4470-92cf-564f4f6a0dae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8690a0>]}
[0m12:20:05.672081 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.02s]
[0m12:20:05.672430 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m12:20:05.673146 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:20:05.673366 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m12:20:05.673539 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m12:20:05.673811 [info ] [MainThread]: 
[0m12:20:05.673994 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m12:20:05.674513 [debug] [MainThread]: Command end result
[0m12:20:05.689528 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:20:05.690680 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:20:05.693815 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m12:20:05.694068 [info ] [MainThread]: 
[0m12:20:05.694279 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:20:05.694456 [info ] [MainThread]: 
[0m12:20:05.694636 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m12:20:05.694943 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 4 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m12:20:05.697342 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.6109853, "process_in_blocks": "0", "process_kernel_time": 0.219126, "process_mem_max_rss": "171999232", "process_out_blocks": "0", "process_user_time": 1.966634}
[0m12:20:05.697608 [debug] [MainThread]: Command `dbt run` succeeded at 12:20:05.697563 after 1.61 seconds
[0m12:20:05.697808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a940e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10965b920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8c6570>]}
[0m12:20:05.697994 [debug] [MainThread]: Flushing usage events
[0m12:20:06.124563 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:24:09.847704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10733a0c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d6660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d6150>]}


============================== 12:24:09.850120 | 0f886ab3-fa50-42b7-8190-603ff5e65494 ==============================
[0m12:24:09.850120 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:24:09.850457 [debug] [MainThread]: running dbt with arguments {'empty': 'None', 'invocation_command': 'dbt test', 'debug': 'False', 'partial_parse': 'True', 'use_colors': 'True', 'quiet': 'False', 'printer_width': '80', 'version_check': 'True', 'static_parser': 'True', 'warn_error': 'None', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'indirect_selection': 'eager', 'write_json': 'True', 'introspect': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m12:24:09.937362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107656a20>]}
[0m12:24:09.967006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10761baa0>]}
[0m12:24:09.967490 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:24:10.032261 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:24:10.091035 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:24:10.091300 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:24:10.094635 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
[0m12:24:10.116092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10771a180>]}
[0m12:24:10.164918 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:24:10.166353 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:24:10.182656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcd9d0>]}
[0m12:24:10.183014 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 487 macros
[0m12:24:10.183209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107719c10>]}
[0m12:24:10.184517 [info ] [MainThread]: 
[0m12:24:10.184740 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:24:10.184892 [info ] [MainThread]: 
[0m12:24:10.185189 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:24:10.188841 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__market'
[0m12:24:10.195420 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:24:10.481117 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m12:24:10.485059 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.493411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f886ab3-fa50-42b7-8190-603ff5e65494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b02000>]}
[0m12:24:10.494629 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m12:24:10.494853 [info ] [Thread-1 (]: 1 of 14 START test not_null_daily_prices_date .................................. [RUN]
[0m12:24:10.495095 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now test.qi_dbt_project.not_null_daily_prices_date.287ad299aa)
[0m12:24:10.495279 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m12:24:10.504223 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m12:24:10.504994 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m12:24:10.514959 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m12:24:10.515796 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_date.287ad299aa: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from `market`.`daily_prices`
where date is null



  
  
    ) dbt_internal_test...
[0m12:24:10.519986 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.522393 [info ] [Thread-1 (]: 1 of 14 PASS not_null_daily_prices_date ........................................ [[32mPASS[0m in 0.03s]
[0m12:24:10.522723 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m12:24:10.522936 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m12:24:10.523189 [info ] [Thread-1 (]: 2 of 14 START test not_null_daily_prices_ingested_at ........................... [RUN]
[0m12:24:10.523455 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_date.287ad299aa, now test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837)
[0m12:24:10.523654 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m12:24:10.525963 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m12:24:10.526438 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m12:24:10.528436 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m12:24:10.529054 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ingested_at
from `market`.`daily_prices`
where ingested_at is null



  
  
    ) dbt_internal_test...
[0m12:24:10.532582 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.533622 [info ] [Thread-1 (]: 2 of 14 PASS not_null_daily_prices_ingested_at ................................. [[32mPASS[0m in 0.01s]
[0m12:24:10.533923 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m12:24:10.534132 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m12:24:10.534367 [info ] [Thread-1 (]: 3 of 14 START test not_null_daily_prices_short_name ............................ [RUN]
[0m12:24:10.534612 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837, now test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52)
[0m12:24:10.534790 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m12:24:10.537027 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m12:24:10.537456 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m12:24:10.538642 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m12:24:10.539173 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select short_name
from `market`.`daily_prices`
where short_name is null



  
  
    ) dbt_internal_test...
[0m12:24:10.542556 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.543526 [info ] [Thread-1 (]: 3 of 14 PASS not_null_daily_prices_short_name .................................. [[32mPASS[0m in 0.01s]
[0m12:24:10.543837 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m12:24:10.544071 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m12:24:10.544257 [info ] [Thread-1 (]: 4 of 14 START test not_null_daily_prices_ticker ................................ [RUN]
[0m12:24:10.544627 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52, now test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1)
[0m12:24:10.544914 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m12:24:10.547154 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m12:24:10.547912 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m12:24:10.549339 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m12:24:10.550172 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`daily_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m12:24:10.553655 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.554782 [info ] [Thread-1 (]: 4 of 14 PASS not_null_daily_prices_ticker ...................................... [[32mPASS[0m in 0.01s]
[0m12:24:10.555141 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m12:24:10.555341 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m12:24:10.555609 [info ] [Thread-1 (]: 5 of 14 START test not_null_monthly_prices_month_ending ........................ [RUN]
[0m12:24:10.555920 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1, now test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274)
[0m12:24:10.556124 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m12:24:10.558340 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"
[0m12:24:10.559091 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m12:24:10.560483 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"
[0m12:24:10.560946 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month_ending
from `market`.`monthly_prices`
where month_ending is null



  
  
    ) dbt_internal_test...
[0m12:24:10.564138 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.565198 [info ] [Thread-1 (]: 5 of 14 PASS not_null_monthly_prices_month_ending .............................. [[32mPASS[0m in 0.01s]
[0m12:24:10.565548 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m12:24:10.565757 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m12:24:10.565995 [info ] [Thread-1 (]: 6 of 14 START test not_null_monthly_prices_ticker .............................. [RUN]
[0m12:24:10.566270 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274, now test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2)
[0m12:24:10.566468 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m12:24:10.568875 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"
[0m12:24:10.569551 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m12:24:10.570730 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"
[0m12:24:10.571078 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`monthly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m12:24:10.574396 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.575411 [info ] [Thread-1 (]: 6 of 14 PASS not_null_monthly_prices_ticker .................................... [[32mPASS[0m in 0.01s]
[0m12:24:10.575719 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m12:24:10.575920 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m12:24:10.576127 [info ] [Thread-1 (]: 7 of 14 START test not_null_quarterly_prices_quarter_ending .................... [RUN]
[0m12:24:10.576342 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2, now test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab)
[0m12:24:10.576519 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m12:24:10.578781 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"
[0m12:24:10.579263 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m12:24:10.581464 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"
[0m12:24:10.582106 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select quarter_ending
from `market`.`quarterly_prices`
where quarter_ending is null



  
  
    ) dbt_internal_test...
[0m12:24:10.585447 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.586495 [info ] [Thread-1 (]: 7 of 14 PASS not_null_quarterly_prices_quarter_ending .......................... [[32mPASS[0m in 0.01s]
[0m12:24:10.586822 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m12:24:10.587024 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m12:24:10.587240 [info ] [Thread-1 (]: 8 of 14 START test not_null_quarterly_prices_ticker ............................ [RUN]
[0m12:24:10.587447 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab, now test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137)
[0m12:24:10.587628 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m12:24:10.590013 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"
[0m12:24:10.590474 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m12:24:10.591839 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"
[0m12:24:10.592575 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`quarterly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m12:24:10.595778 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.596654 [info ] [Thread-1 (]: 8 of 14 PASS not_null_quarterly_prices_ticker .................................. [[32mPASS[0m in 0.01s]
[0m12:24:10.596935 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m12:24:10.597121 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m12:24:10.597402 [info ] [Thread-1 (]: 9 of 14 START test not_null_weekly_prices_ticker ............................... [RUN]
[0m12:24:10.597734 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137, now test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469)
[0m12:24:10.597946 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m12:24:10.600498 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"
[0m12:24:10.600964 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m12:24:10.602216 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"
[0m12:24:10.602911 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`weekly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m12:24:10.606115 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.607166 [info ] [Thread-1 (]: 9 of 14 PASS not_null_weekly_prices_ticker ..................................... [[32mPASS[0m in 0.01s]
[0m12:24:10.607509 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m12:24:10.607723 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m12:24:10.607942 [info ] [Thread-1 (]: 10 of 14 START test not_null_weekly_prices_week_ending ......................... [RUN]
[0m12:24:10.608187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469, now test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de)
[0m12:24:10.608370 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m12:24:10.610742 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"
[0m12:24:10.611390 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m12:24:10.612784 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"
[0m12:24:10.613224 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select week_ending
from `market`.`weekly_prices`
where week_ending is null



  
  
    ) dbt_internal_test...
[0m12:24:10.616579 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:24:10.617517 [info ] [Thread-1 (]: 10 of 14 PASS not_null_weekly_prices_week_ending ............................... [[32mPASS[0m in 0.01s]
[0m12:24:10.617801 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m12:24:10.617992 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303
[0m12:24:10.618283 [info ] [Thread-1 (]: 11 of 14 START test unique_daily_prices_date__ticker__date ..................... [RUN]
[0m12:24:10.618665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de, now test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303)
[0m12:24:10.618881 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303
[0m12:24:10.627789 [debug] [Thread-1 (]: Compilation Error in test unique_daily_prices_date__ticker__date (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.628130 [error] [Thread-1 (]: 11 of 14 ERROR unique_daily_prices_date__ticker__date .......................... [[31mERROR[0m in 0.01s]
[0m12:24:10.628404 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303
[0m12:24:10.628612 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164
[0m12:24:10.628835 [debug] [Thread-4 (]: Marking all children of 'test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303' to be skipped because of status 'error'.  Reason: Compilation Error in test unique_daily_prices_date__ticker__date (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'.
[0m12:24:10.629068 [info ] [Thread-1 (]: 12 of 14 START test unique_monthly_prices_month_ending__ticker__month_ending ... [RUN]
[0m12:24:10.629928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.unique_daily_prices_date__ticker__date.0b403d6303, now test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164)
[0m12:24:10.630185 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164
[0m12:24:10.633570 [debug] [Thread-1 (]: Compilation Error in test unique_monthly_prices_month_ending__ticker__month_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.633961 [error] [Thread-1 (]: 12 of 14 ERROR unique_monthly_prices_month_ending__ticker__month_ending ........ [[31mERROR[0m in 0.00s]
[0m12:24:10.634235 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164
[0m12:24:10.634443 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5
[0m12:24:10.634675 [debug] [Thread-4 (]: Marking all children of 'test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164' to be skipped because of status 'error'.  Reason: Compilation Error in test unique_monthly_prices_month_ending__ticker__month_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'.
[0m12:24:10.634881 [info ] [Thread-1 (]: 13 of 14 START test unique_quarterly_prices_quarter_ending__ticker__quarter_ending  [RUN]
[0m12:24:10.635216 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.unique_monthly_prices_month_ending__ticker__month_ending.c3fd418164, now test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5)
[0m12:24:10.635433 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5
[0m12:24:10.638493 [debug] [Thread-1 (]: Compilation Error in test unique_quarterly_prices_quarter_ending__ticker__quarter_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.638739 [error] [Thread-1 (]: 13 of 14 ERROR unique_quarterly_prices_quarter_ending__ticker__quarter_ending .. [[31mERROR[0m in 0.00s]
[0m12:24:10.638976 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5
[0m12:24:10.639160 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04
[0m12:24:10.639354 [debug] [Thread-4 (]: Marking all children of 'test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5' to be skipped because of status 'error'.  Reason: Compilation Error in test unique_quarterly_prices_quarter_ending__ticker__quarter_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'.
[0m12:24:10.639540 [info ] [Thread-1 (]: 14 of 14 START test unique_weekly_prices_week_ending__ticker__week_ending ...... [RUN]
[0m12:24:10.639787 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.unique_quarterly_prices_quarter_ending__ticker__quarter_ending.cdc64869c5, now test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04)
[0m12:24:10.639960 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04
[0m12:24:10.644212 [debug] [Thread-1 (]: Compilation Error in test unique_weekly_prices_week_ending__ticker__week_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.644504 [error] [Thread-1 (]: 14 of 14 ERROR unique_weekly_prices_week_ending__ticker__week_ending ........... [[31mERROR[0m in 0.00s]
[0m12:24:10.644765 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04
[0m12:24:10.644977 [debug] [Thread-4 (]: Marking all children of 'test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04' to be skipped because of status 'error'.  Reason: Compilation Error in test unique_weekly_prices_week_ending__ticker__week_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'.
[0m12:24:10.645687 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:24:10.645859 [debug] [MainThread]: Connection 'test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04' was left open.
[0m12:24:10.646015 [debug] [MainThread]: On test.qi_dbt_project.unique_weekly_prices_week_ending__ticker__week_ending.ff02f0cf04: Close
[0m12:24:10.646285 [info ] [MainThread]: 
[0m12:24:10.646512 [info ] [MainThread]: Finished running 14 data tests in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m12:24:10.647472 [debug] [MainThread]: Command end result
[0m12:24:10.661570 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m12:24:10.662919 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m12:24:10.667074 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m12:24:10.667287 [info ] [MainThread]: 
[0m12:24:10.667471 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m12:24:10.667626 [info ] [MainThread]: 
[0m12:24:10.667815 [error] [MainThread]: [31mFailure in test unique_daily_prices_date__ticker__date (models/market/schema.yml)[0m
[0m12:24:10.667992 [error] [MainThread]:   Compilation Error in test unique_daily_prices_date__ticker__date (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.668132 [info ] [MainThread]: 
[0m12:24:10.668298 [error] [MainThread]: [31mFailure in test unique_monthly_prices_month_ending__ticker__month_ending (models/market/schema.yml)[0m
[0m12:24:10.668463 [error] [MainThread]:   Compilation Error in test unique_monthly_prices_month_ending__ticker__month_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.668595 [info ] [MainThread]: 
[0m12:24:10.668760 [error] [MainThread]: [31mFailure in test unique_quarterly_prices_quarter_ending__ticker__quarter_ending (models/market/schema.yml)[0m
[0m12:24:10.669098 [error] [MainThread]:   Compilation Error in test unique_quarterly_prices_quarter_ending__ticker__quarter_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.669371 [info ] [MainThread]: 
[0m12:24:10.669573 [error] [MainThread]: [31mFailure in test unique_weekly_prices_week_ending__ticker__week_ending (models/market/schema.yml)[0m
[0m12:24:10.669759 [error] [MainThread]:   Compilation Error in test unique_weekly_prices_week_ending__ticker__week_ending (models/market/schema.yml)
  macro 'dbt_macro__test_unique' takes no keyword argument 'combination_of_columns'
[0m12:24:10.669911 [info ] [MainThread]: 
[0m12:24:10.670077 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=4 SKIP=0 NO-OP=0 TOTAL=14
[0m12:24:10.672371 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 0.8604604, "process_in_blocks": "0", "process_kernel_time": 0.197659, "process_mem_max_rss": "168263680", "process_out_blocks": "0", "process_user_time": 1.347708}
[0m12:24:10.672693 [debug] [MainThread]: Command `dbt test` failed at 12:24:10.672642 after 0.86 seconds
[0m12:24:10.672900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cfe630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10714d2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d5fa0>]}
[0m12:24:10.673120 [debug] [MainThread]: Flushing usage events
[0m12:24:11.125528 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:52:21.353231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081345c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d0c110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a4d880>]}


============================== 16:52:21.356532 | 9699f629-9d04-4d2d-a8e7-bdd90da69add ==============================
[0m16:52:21.356532 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:52:21.356883 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'use_colors': 'True', 'empty': 'None', 'log_cache_events': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'debug': 'False', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'no_print': 'None', 'indirect_selection': 'eager', 'version_check': 'True', 'fail_fast': 'False', 'printer_width': '80', 'warn_error': 'None', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m16:52:21.425883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9699f629-9d04-4d2d-a8e7-bdd90da69add', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109832870>]}
[0m16:52:21.437581 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-54jv47a3'
[0m16:52:21.437893 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m16:52:21.539211 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m16:52:21.540093 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m16:52:21.583621 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m16:52:21.592974 [info ] [MainThread]: Updating lock file in file path: /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/package-lock.yml
[0m16:52:21.595085 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-e8a0_11n'
[0m16:52:21.597213 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m16:52:21.949878 [info ] [MainThread]: Installed from version 1.3.1
[0m16:52:21.950207 [info ] [MainThread]: Up to date!
[0m16:52:21.950451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '9699f629-9d04-4d2d-a8e7-bdd90da69add', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109948860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10994b170>]}
[0m16:52:21.953162 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.64053786, "process_in_blocks": "0", "process_kernel_time": 0.178269, "process_mem_max_rss": "114163712", "process_out_blocks": "0", "process_user_time": 0.824509}
[0m16:52:21.953576 [debug] [MainThread]: Command `dbt deps` succeeded at 16:52:21.953509 after 0.64 seconds
[0m16:52:21.954026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093cc2c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c59a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096eeff0>]}
[0m16:52:21.954306 [debug] [MainThread]: Flushing usage events
[0m16:52:22.419711 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:54:31.421152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10932d3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093e5bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088fe7e0>]}


============================== 16:54:31.423682 | 0d854234-2b0e-4c05-b49e-79f47f3a7676 ==============================
[0m16:54:31.423682 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:54:31.424023 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'version_check': 'True', 'fail_fast': 'False', 'debug': 'False', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'empty': 'None', 'use_colors': 'True', 'target_path': 'None', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'quiet': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'invocation_command': 'dbt clean', 'partial_parse': 'True'}
[0m16:54:31.487417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0d854234-2b0e-4c05-b49e-79f47f3a7676', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e53cb0>]}
[0m16:54:31.500792 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.1147455, "process_in_blocks": "0", "process_kernel_time": 0.109589, "process_mem_max_rss": "110297088", "process_out_blocks": "0", "process_user_time": 0.763312}
[0m16:54:31.501105 [debug] [MainThread]: Command `dbt clean` succeeded at 16:54:31.501049 after 0.12 seconds
[0m16:54:31.501322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b94140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106345d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a94ef0>]}
[0m16:54:31.501529 [debug] [MainThread]: Flushing usage events
[0m16:54:31.966885 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:54:40.651665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060711f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061230b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065b6180>]}


============================== 16:54:40.654214 | dd5621fc-116a-42b8-91f4-6c28c216da42 ==============================
[0m16:54:40.654214 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:54:40.654569 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'indirect_selection': 'eager', 'fail_fast': 'False', 'use_colors': 'True', 'invocation_command': 'dbt deps', 'version_check': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'target_path': 'None', 'warn_error': 'None', 'cache_selected_only': 'False', 'partial_parse': 'True', 'empty': 'None', 'quiet': 'False', 'introspect': 'True'}
[0m16:54:40.717849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd5621fc-116a-42b8-91f4-6c28c216da42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ebbc80>]}
[0m16:54:40.740751 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-ton4_ejo'
[0m16:54:40.741018 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m16:54:40.829845 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m16:54:40.830767 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m16:54:40.885985 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m16:54:40.889497 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m16:54:41.402891 [info ] [MainThread]: Installed from version 1.3.1
[0m16:54:41.403185 [info ] [MainThread]: Up to date!
[0m16:54:41.403411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'dd5621fc-116a-42b8-91f4-6c28c216da42', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d7af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e90fe0>]}
[0m16:54:41.405376 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.78944796, "process_in_blocks": "0", "process_kernel_time": 0.146405, "process_mem_max_rss": "114180096", "process_out_blocks": "0", "process_user_time": 0.811004}
[0m16:54:41.405792 [debug] [MainThread]: Command `dbt deps` succeeded at 16:54:41.405732 after 0.79 seconds
[0m16:54:41.406029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106072750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068b1640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106de1c10>]}
[0m16:54:41.406238 [debug] [MainThread]: Flushing usage events
[0m16:54:41.837035 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:54:51.471016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10476e8a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10547a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10547a2a0>]}


============================== 16:54:51.473488 | 7b10cba7-bd23-4423-b3ee-7b28bce9cc32 ==============================
[0m16:54:51.473488 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:54:51.473852 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'write_json': 'True', 'printer_width': '80', 'target_path': 'None', 'empty': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'quiet': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt test', 'log_format': 'default', 'cache_selected_only': 'False', 'no_print': 'None', 'use_colors': 'True', 'debug': 'False'}
[0m16:54:51.570341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b10cba7-bd23-4423-b3ee-7b28bce9cc32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055bbc80>]}
[0m16:54:51.600538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b10cba7-bd23-4423-b3ee-7b28bce9cc32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10374f230>]}
[0m16:54:51.601189 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:54:51.676070 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:54:51.676604 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:54:51.676810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7b10cba7-bd23-4423-b3ee-7b28bce9cc32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b6480>]}
[0m16:54:52.399009 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `dbt_utils.unique_combination_of_columns`.
Arguments to generic tests should be nested under the `arguments` property.`
[0m16:54:52.399358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '7b10cba7-bd23-4423-b3ee-7b28bce9cc32', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b04cb0>]}
[0m16:54:52.409396 [error] [MainThread]: Encountered an error:
Compilation Error in test dbt_utils_unique_combination_of_columns_daily_prices_date__ticker__date (models/market/schema.yml)
  macro 'dbt_macro__test_unique_combination_of_columns' takes no keyword argument 'column_name'
[0m16:54:52.409761 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m16:54:52.411282 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 0.9782215, "process_in_blocks": "0", "process_kernel_time": 0.148857, "process_mem_max_rss": "123551744", "process_out_blocks": "0", "process_user_time": 1.560365}
[0m16:54:52.411634 [debug] [MainThread]: Command `dbt test` failed at 16:54:52.411582 after 0.98 seconds
[0m16:54:52.411857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ec4e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ad4fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c0c770>]}
[0m16:54:52.412069 [debug] [MainThread]: Flushing usage events
[0m16:54:52.933275 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:56:26.414994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060f8fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f0f320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106ffe90>]}


============================== 16:56:26.417558 | 2b1b5772-3d1f-4c7d-8af1-c36c80eb547c ==============================
[0m16:56:26.417558 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:56:26.417900 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'target_path': 'None', 'log_format': 'default', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'debug': 'False', 'no_print': 'None', 'cache_selected_only': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'warn_error': 'None', 'invocation_command': 'dbt clean', 'version_check': 'True', 'quiet': 'False', 'printer_width': '80', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'empty': 'None'}
[0m16:56:26.480816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b1b5772-3d1f-4c7d-8af1-c36c80eb547c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110aee240>]}
[0m16:56:26.487878 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.10828979, "process_in_blocks": "0", "process_kernel_time": 0.101855, "process_mem_max_rss": "111378432", "process_out_blocks": "0", "process_user_time": 0.764041}
[0m16:56:26.488163 [debug] [MainThread]: Command `dbt clean` succeeded at 16:56:26.488112 after 0.11 seconds
[0m16:56:26.488353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f760f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062e1f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f0ef60>]}
[0m16:56:26.488530 [debug] [MainThread]: Flushing usage events
[0m16:56:26.971589 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:56:36.304559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107698d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053be7e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053be840>]}


============================== 16:56:36.307212 | 77c89f11-8a1f-4b2b-a549-b4b4bcd7c2d1 ==============================
[0m16:56:36.307212 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:56:36.307556 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt deps', 'partial_parse': 'True', 'fail_fast': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'use_colors': 'True', 'write_json': 'True', 'debug': 'False', 'quiet': 'False', 'log_format': 'default', 'empty': 'None', 'warn_error': 'None', 'log_cache_events': 'False', 'target_path': 'None'}
[0m16:56:36.369953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '77c89f11-8a1f-4b2b-a549-b4b4bcd7c2d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079743b0>]}
[0m16:56:36.391399 [debug] [MainThread]: Set downloads directory='/var/folders/tf/lr49688s3sz7sp0s0dt7yhn40000gn/T/dbt-downloads-jgdmhnas'
[0m16:56:36.391643 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m16:56:36.481526 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m16:56:36.482416 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m16:56:36.523759 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m16:56:36.527204 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m16:56:37.030199 [info ] [MainThread]: Installed from version 1.3.1
[0m16:56:37.030495 [info ] [MainThread]: Up to date!
[0m16:56:37.030720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '77c89f11-8a1f-4b2b-a549-b4b4bcd7c2d1', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10780f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a12180>]}
[0m16:56:37.032685 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.76502454, "process_in_blocks": "0", "process_kernel_time": 0.159857, "process_mem_max_rss": "116211712", "process_out_blocks": "0", "process_user_time": 0.829765}
[0m16:56:37.032985 [debug] [MainThread]: Command `dbt deps` succeeded at 16:56:37.032932 after 0.77 seconds
[0m16:56:37.033199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053bd430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105470200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078761e0>]}
[0m16:56:37.033396 [debug] [MainThread]: Flushing usage events
[0m16:56:37.450343 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:56:46.895096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a4e570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10747a5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107479f70>]}


============================== 16:56:46.897466 | 30b3496b-344e-407b-b8a1-baf69285879e ==============================
[0m16:56:46.897466 [info ] [MainThread]: Running with dbt=1.10.13
[0m16:56:46.897796 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'version_check': 'True', 'write_json': 'True', 'target_path': 'None', 'invocation_command': 'dbt test', 'cache_selected_only': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'printer_width': '80', 'static_parser': 'True', 'use_experimental_parser': 'False', 'quiet': 'False'}
[0m16:56:46.991626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074ae150>]}
[0m16:56:47.022806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c7cfb0>]}
[0m16:56:47.023394 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m16:56:47.092402 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m16:56:47.092970 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:56:47.093191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076cc470>]}
[0m16:56:47.916014 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
[0m16:56:47.921323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108515b80>]}
[0m16:56:47.970115 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:56:47.971759 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:56:47.986437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108848b00>]}
[0m16:56:47.986739 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m16:56:47.986929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10825f080>]}
[0m16:56:47.988067 [info ] [MainThread]: 
[0m16:56:47.988249 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:56:47.988390 [info ] [MainThread]: 
[0m16:56:47.988628 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:56:47.991536 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__market'
[0m16:56:47.997142 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:48.381270 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m16:56:48.383929 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.394882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30b3496b-344e-407b-b8a1-baf69285879e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b3e60>]}
[0m16:56:48.396431 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m16:56:48.396651 [info ] [Thread-1 (]: 1 of 14 START test dbt_utils_unique_combination_of_columns_daily_prices_ticker__date  [RUN]
[0m16:56:48.396873 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3)
[0m16:56:48.397050 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m16:56:48.402638 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"
[0m16:56:48.403648 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m16:56:48.413989 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"
[0m16:56:48.415068 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, date
    from `market`.`daily_prices`
    group by ticker, date
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m16:56:48.422386 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.424923 [info ] [Thread-1 (]: 1 of 14 PASS dbt_utils_unique_combination_of_columns_daily_prices_ticker__date . [[32mPASS[0m in 0.03s]
[0m16:56:48.425278 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m16:56:48.425502 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd
[0m16:56:48.425707 [info ] [Thread-1 (]: 2 of 14 START test dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending  [RUN]
[0m16:56:48.425996 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd)
[0m16:56:48.426231 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd
[0m16:56:48.428941 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd"
[0m16:56:48.429646 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd
[0m16:56:48.431054 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd"
[0m16:56:48.431631 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, month_ending
    from `market`.`monthly_prices`
    group by ticker, month_ending
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m16:56:48.437508 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.438505 [info ] [Thread-1 (]: 2 of 14 PASS dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending  [[32mPASS[0m in 0.01s]
[0m16:56:48.438840 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd
[0m16:56:48.439056 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325
[0m16:56:48.439281 [info ] [Thread-1 (]: 3 of 14 START test dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending  [RUN]
[0m16:56:48.439641 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_monthly_prices_ticker__month_ending.49db5807dd, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325)
[0m16:56:48.439921 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325
[0m16:56:48.442408 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325"
[0m16:56:48.443159 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325
[0m16:56:48.444706 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325"
[0m16:56:48.445155 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, quarter_ending
    from `market`.`quarterly_prices`
    group by ticker, quarter_ending
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m16:56:48.449017 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.450035 [info ] [Thread-1 (]: 3 of 14 PASS dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending  [[32mPASS[0m in 0.01s]
[0m16:56:48.450372 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325
[0m16:56:48.450605 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20
[0m16:56:48.450915 [info ] [Thread-1 (]: 4 of 14 START test dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending  [RUN]
[0m16:56:48.451267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_quarterly_prices_ticker__quarter_ending.e147e2c325, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20)
[0m16:56:48.451470 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20
[0m16:56:48.454008 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20"
[0m16:56:48.454486 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20
[0m16:56:48.455840 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20"
[0m16:56:48.456443 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, week_ending
    from `market`.`weekly_prices`
    group by ticker, week_ending
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m16:56:48.463886 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.464928 [info ] [Thread-1 (]: 4 of 14 PASS dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending  [[32mPASS[0m in 0.01s]
[0m16:56:48.465229 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20
[0m16:56:48.465425 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m16:56:48.465598 [info ] [Thread-1 (]: 5 of 14 START test not_null_daily_prices_date .................................. [RUN]
[0m16:56:48.465802 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_weekly_prices_ticker__week_ending.05b9c0ea20, now test.qi_dbt_project.not_null_daily_prices_date.287ad299aa)
[0m16:56:48.465979 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m16:56:48.470736 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m16:56:48.471367 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m16:56:48.472855 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m16:56:48.473603 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_date.287ad299aa: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from `market`.`daily_prices`
where date is null



  
  
    ) dbt_internal_test...
[0m16:56:48.479156 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.480177 [info ] [Thread-1 (]: 5 of 14 PASS not_null_daily_prices_date ........................................ [[32mPASS[0m in 0.01s]
[0m16:56:48.480489 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m16:56:48.480692 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m16:56:48.480913 [info ] [Thread-1 (]: 6 of 14 START test not_null_daily_prices_ingested_at ........................... [RUN]
[0m16:56:48.481164 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_date.287ad299aa, now test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837)
[0m16:56:48.481350 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m16:56:48.483869 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m16:56:48.484728 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m16:56:48.486216 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m16:56:48.486869 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ingested_at
from `market`.`daily_prices`
where ingested_at is null



  
  
    ) dbt_internal_test...
[0m16:56:48.492263 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.493229 [info ] [Thread-1 (]: 6 of 14 PASS not_null_daily_prices_ingested_at ................................. [[32mPASS[0m in 0.01s]
[0m16:56:48.493529 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m16:56:48.493741 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m16:56:48.493962 [info ] [Thread-1 (]: 7 of 14 START test not_null_daily_prices_short_name ............................ [RUN]
[0m16:56:48.494175 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837, now test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52)
[0m16:56:48.494343 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m16:56:48.496552 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m16:56:48.497016 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m16:56:48.498279 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m16:56:48.498643 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select short_name
from `market`.`daily_prices`
where short_name is null



  
  
    ) dbt_internal_test...
[0m16:56:48.503993 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.505059 [info ] [Thread-1 (]: 7 of 14 PASS not_null_daily_prices_short_name .................................. [[32mPASS[0m in 0.01s]
[0m16:56:48.505414 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m16:56:48.505632 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m16:56:48.505930 [info ] [Thread-1 (]: 8 of 14 START test not_null_daily_prices_ticker ................................ [RUN]
[0m16:56:48.506271 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52, now test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1)
[0m16:56:48.506464 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m16:56:48.508739 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m16:56:48.509224 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m16:56:48.510621 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m16:56:48.511309 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`daily_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m16:56:48.517627 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.518594 [info ] [Thread-1 (]: 8 of 14 PASS not_null_daily_prices_ticker ...................................... [[32mPASS[0m in 0.01s]
[0m16:56:48.518875 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m16:56:48.519066 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m16:56:48.519356 [info ] [Thread-1 (]: 9 of 14 START test not_null_monthly_prices_month_ending ........................ [RUN]
[0m16:56:48.519733 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1, now test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274)
[0m16:56:48.519949 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m16:56:48.522382 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"
[0m16:56:48.523130 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m16:56:48.525645 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"
[0m16:56:48.526144 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month_ending
from `market`.`monthly_prices`
where month_ending is null



  
  
    ) dbt_internal_test...
[0m16:56:48.530757 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.531843 [info ] [Thread-1 (]: 9 of 14 PASS not_null_monthly_prices_month_ending .............................. [[32mPASS[0m in 0.01s]
[0m16:56:48.532157 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274
[0m16:56:48.532353 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m16:56:48.532618 [info ] [Thread-1 (]: 10 of 14 START test not_null_monthly_prices_ticker ............................. [RUN]
[0m16:56:48.532924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_monthly_prices_month_ending.63079ad274, now test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2)
[0m16:56:48.533118 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m16:56:48.535660 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"
[0m16:56:48.536125 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m16:56:48.537335 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"
[0m16:56:48.537955 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`monthly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m16:56:48.541605 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.542552 [info ] [Thread-1 (]: 10 of 14 PASS not_null_monthly_prices_ticker ................................... [[32mPASS[0m in 0.01s]
[0m16:56:48.542847 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2
[0m16:56:48.543040 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m16:56:48.543323 [info ] [Thread-1 (]: 11 of 14 START test not_null_quarterly_prices_quarter_ending ................... [RUN]
[0m16:56:48.543664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_monthly_prices_ticker.6f879395e2, now test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab)
[0m16:56:48.543858 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m16:56:48.546122 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"
[0m16:56:48.546824 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m16:56:48.548412 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"
[0m16:56:48.549055 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select quarter_ending
from `market`.`quarterly_prices`
where quarter_ending is null



  
  
    ) dbt_internal_test...
[0m16:56:48.554662 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.555721 [info ] [Thread-1 (]: 11 of 14 PASS not_null_quarterly_prices_quarter_ending ......................... [[32mPASS[0m in 0.01s]
[0m16:56:48.556062 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab
[0m16:56:48.556344 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m16:56:48.556695 [info ] [Thread-1 (]: 12 of 14 START test not_null_quarterly_prices_ticker ........................... [RUN]
[0m16:56:48.557002 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_quarterly_prices_quarter_ending.bc6e4297ab, now test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137)
[0m16:56:48.557202 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m16:56:48.559594 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"
[0m16:56:48.560275 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m16:56:48.561568 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"
[0m16:56:48.561933 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`quarterly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m16:56:48.567077 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:56:48.568119 [info ] [Thread-1 (]: 12 of 14 PASS not_null_quarterly_prices_ticker ................................. [[32mPASS[0m in 0.01s]
[0m16:56:48.568437 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137
[0m16:56:48.568633 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m16:56:48.568916 [info ] [Thread-1 (]: 13 of 14 START test not_null_weekly_prices_ticker .............................. [RUN]
[0m16:56:48.569260 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_quarterly_prices_ticker.a4f0b0d137, now test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469)
[0m16:56:48.569456 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m16:56:48.571756 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"
[0m16:56:48.572189 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m16:56:48.573406 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"
[0m16:56:48.573816 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`weekly_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m16:56:48.580205 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.581210 [info ] [Thread-1 (]: 13 of 14 PASS not_null_weekly_prices_ticker .................................... [[32mPASS[0m in 0.01s]
[0m16:56:48.581496 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469
[0m16:56:48.581693 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m16:56:48.581895 [info ] [Thread-1 (]: 14 of 14 START test not_null_weekly_prices_week_ending ......................... [RUN]
[0m16:56:48.582091 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_weekly_prices_ticker.e525680469, now test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de)
[0m16:56:48.582259 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m16:56:48.585793 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"
[0m16:56:48.586304 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m16:56:48.624553 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"
[0m16:56:48.625150 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select week_ending
from `market`.`weekly_prices`
where week_ending is null



  
  
    ) dbt_internal_test...
[0m16:56:48.631561 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:56:48.632574 [info ] [Thread-1 (]: 14 of 14 PASS not_null_weekly_prices_week_ending ............................... [[32mPASS[0m in 0.05s]
[0m16:56:48.632918 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de
[0m16:56:48.633564 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:56:48.633766 [debug] [MainThread]: Connection 'test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de' was left open.
[0m16:56:48.633931 [debug] [MainThread]: On test.qi_dbt_project.not_null_weekly_prices_week_ending.1078b135de: Close
[0m16:56:48.634152 [info ] [MainThread]: 
[0m16:56:48.634322 [info ] [MainThread]: Finished running 14 data tests in 0 hours 0 minutes and 0.65 seconds (0.65s).
[0m16:56:48.635332 [debug] [MainThread]: Command end result
[0m16:56:48.652485 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m16:56:48.653678 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m16:56:48.657714 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m16:56:48.657953 [info ] [MainThread]: 
[0m16:56:48.658147 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:56:48.658306 [info ] [MainThread]: 
[0m16:56:48.658480 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=14
[0m16:56:48.660965 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.8028938, "process_in_blocks": "0", "process_kernel_time": 0.226894, "process_mem_max_rss": "175423488", "process_out_blocks": "0", "process_user_time": 2.15768}
[0m16:56:48.661234 [debug] [MainThread]: Command `dbt test` succeeded at 16:56:48.661190 after 1.80 seconds
[0m16:56:48.661430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063961b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083008c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b624b0>]}
[0m16:56:48.661623 [debug] [MainThread]: Flushing usage events
[0m16:56:49.109451 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:35:20.859107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cafb00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11117d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137e6f0>]}


============================== 18:35:20.862124 | d9a20fa1-f653-4752-81d3-eda441d12856 ==============================
[0m18:35:20.862124 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:35:20.862463 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'empty': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'fail_fast': 'False', 'printer_width': '80', 'debug': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'static_parser': 'True', 'target_path': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'quiet': 'False'}
[0m18:35:20.961871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111330140>]}
[0m18:35:20.992329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113f3ec0>]}
[0m18:35:20.992926 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:35:21.063953 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:35:21.141724 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:35:21.141978 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:35:21.145176 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
[0m18:35:21.165959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11172a000>]}
[0m18:35:21.212574 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m18:35:21.214416 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m18:35:21.226682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ad0d70>]}
[0m18:35:21.226954 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m18:35:21.227139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11153eb70>]}
[0m18:35:21.228136 [info ] [MainThread]: 
[0m18:35:21.228318 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:35:21.228459 [info ] [MainThread]: 
[0m18:35:21.228698 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:35:21.231438 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:35:21.237632 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:35:21.729939 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:35:21.731772 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.743293 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m18:35:21.746895 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m18:35:21.750018 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.751232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116a53bc0>]}
[0m18:35:21.753058 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m18:35:21.753359 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m18:35:21.753602 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m18:35:21.753788 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m18:35:21.757416 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m18:35:21.757854 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m18:35:21.787305 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.monthly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-31') as month_ending, -- Date (last trading day of month)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
          )
        
        ...
[0m18:35:21.795589 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:35:21.804640 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:35:21.809784 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.812288 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m18:35:21.813080 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.monthly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-31') as month_ending, -- Date (last trading day of month)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
  ...
[0m18:35:21.818128 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.820752 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m18:35:21.823190 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.836257 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m18:35:21.840432 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.842242 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a44f50>]}
[0m18:35:21.842597 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.09s]
[0m18:35:21.842900 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m18:35:21.843111 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m18:35:21.843332 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m18:35:21.843578 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m18:35:21.843770 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m18:35:21.844904 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m18:35:21.845329 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m18:35:21.847020 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.quarterly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-03-31') as quarter_ending, -- Date (last trading day of quarter)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
          )
        
        ...
[0m18:35:21.854308 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:35:21.856070 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:35:21.858873 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.860117 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m18:35:21.860612 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.quarterly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-03-31') as quarter_ending, -- Date (last trading day of quarter)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,
    toDateTime64('2000-01-01 00:00:00', 3) as built_at
where 1 = 0
  ...
[0m18:35:21.863573 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.864256 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m18:35:21.866474 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.868382 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m18:35:21.869723 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.870519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a44f50>]}
[0m18:35:21.870844 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.03s]
[0m18:35:21.871135 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m18:35:21.871331 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m18:35:21.871544 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m18:35:21.871800 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m18:35:21.871998 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m18:35:21.873127 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m18:35:21.873547 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m18:35:21.876227 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- placeholder model: market.weekly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-07') as week_ending,  -- Date (last trading day of week)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,                 -- max daily date used
    toDateTime64('2000-01-01 00:00:00', 3) as built_at        -- when built
where 1 = 0
          )
        
        ...
[0m18:35:21.884683 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:35:21.886396 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:35:21.889405 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.890653 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m18:35:21.891209 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- placeholder model: market.weekly_prices (schema only)
select
    '' as ticker,
    '' as short_name,
    toDate('2000-01-07') as week_ending,  -- Date (last trading day of week)
    toFloat64(0) as open,
    toFloat64(0) as high,
    toFloat64(0) as low,
    toFloat64(0) as close,
    toFloat64(0) as adj_close,
    toUInt64(0) as volume,
    toDate('2000-01-01') as source_max_date,                 -- max daily date used
    toDateTime64('2000-01-01 00:00:00', 3) as built_at        -- when built
where 1 = 0
  ...
[0m18:35:21.893978 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.894708 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m18:35:21.897368 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.899390 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m18:35:21.900779 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:35:21.901590 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9a20fa1-f653-4752-81d3-eda441d12856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117fbd370>]}
[0m18:35:21.901948 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.03s]
[0m18:35:21.902243 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m18:35:21.902915 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:35:21.903079 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m18:35:21.903228 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m18:35:21.903462 [info ] [MainThread]: 
[0m18:35:21.903621 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.67 seconds (0.67s).
[0m18:35:21.904041 [debug] [MainThread]: Command end result
[0m18:35:21.921050 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m18:35:21.922194 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m18:35:21.925610 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m18:35:21.925813 [info ] [MainThread]: 
[0m18:35:21.926011 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:35:21.926160 [info ] [MainThread]: 
[0m18:35:21.926325 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m18:35:21.928908 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1084697, "process_in_blocks": "0", "process_kernel_time": 0.235839, "process_mem_max_rss": "189890560", "process_out_blocks": "0", "process_user_time": 1.382548}
[0m18:35:21.929144 [debug] [MainThread]: Command `dbt run` succeeded at 18:35:21.929104 after 1.11 seconds
[0m18:35:21.929324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11131b530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11119b230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113f3d70>]}
[0m18:35:21.929503 [debug] [MainThread]: Flushing usage events
[0m18:35:22.425702 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:39:12.227899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab54d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c47aa80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c47a540>]}


============================== 18:39:12.230790 | bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79 ==============================
[0m18:39:12.230790 [info ] [MainThread]: Running with dbt=1.10.13
[0m18:39:12.231126 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'log_format': 'default', 'debug': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'no_print': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'log_cache_events': 'False', 'introspect': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'warn_error': 'None'}
[0m18:39:12.323119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b929fa0>]}
[0m18:39:12.353192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c07e480>]}
[0m18:39:12.354111 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m18:39:12.426262 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m18:39:12.501536 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m18:39:12.501922 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/weekly_prices.sql
[0m18:39:12.502143 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/quarterly_prices.sql
[0m18:39:12.502350 [debug] [MainThread]: Partial parsing: updated file: qi_dbt_project://models/market/monthly_prices.sql
[0m18:39:12.712000 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
[0m18:39:12.718853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ccc15e0>]}
[0m18:39:12.799793 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m18:39:12.801114 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m18:39:12.812496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cef2120>]}
[0m18:39:12.812766 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m18:39:12.812953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cfeb2c0>]}
[0m18:39:12.813958 [info ] [MainThread]: 
[0m18:39:12.814159 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:39:12.814304 [info ] [MainThread]: 
[0m18:39:12.814544 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m18:39:12.817482 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m18:39:12.823307 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:39:13.219738 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m18:39:13.221500 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.232386 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m18:39:13.236068 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m18:39:13.239097 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.240331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d8251f0>]}
[0m18:39:13.241931 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m18:39:13.242212 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m18:39:13.242444 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m18:39:13.242630 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m18:39:13.246415 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m18:39:13.246948 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m18:39:13.276559 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m18:39:13.284933 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m18:39:13.327049 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:39:13.330101 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.332475 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m18:39:13.333027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m18:39:13.355285 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:39:13.358129 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m18:39:13.360596 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.374452 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m18:39:13.376283 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.378110 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c45190>]}
[0m18:39:13.378464 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.14s]
[0m18:39:13.378771 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m18:39:13.378981 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m18:39:13.379273 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m18:39:13.379540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m18:39:13.379741 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m18:39:13.380965 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m18:39:13.381401 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m18:39:13.383113 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m18:39:13.387428 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.389147 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:39:13.391851 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.393001 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m18:39:13.393509 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m18:39:13.410554 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m18:39:13.411337 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m18:39:13.414452 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.416617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m18:39:13.418039 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.419010 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12d6ebda0>]}
[0m18:39:13.419367 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m18:39:13.419670 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m18:39:13.419886 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m18:39:13.420104 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m18:39:13.420386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m18:39:13.420623 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m18:39:13.421983 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m18:39:13.422434 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m18:39:13.425205 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m18:39:13.429824 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.431604 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m18:39:13.434212 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.435441 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m18:39:13.435958 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m18:39:13.465974 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m18:39:13.466807 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m18:39:13.469621 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.471670 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m18:39:13.473271 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m18:39:13.474117 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdf52e08-e2d5-437d-a1f3-81b9ab7c5f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12d6fe420>]}
[0m18:39:13.474456 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m18:39:13.474748 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m18:39:13.475411 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:39:13.475614 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m18:39:13.475776 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m18:39:13.476013 [info ] [MainThread]: 
[0m18:39:13.476186 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.66 seconds (0.66s).
[0m18:39:13.476618 [debug] [MainThread]: Command end result
[0m18:39:13.494281 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m18:39:13.495466 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m18:39:13.498869 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m18:39:13.499094 [info ] [MainThread]: 
[0m18:39:13.499289 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:39:13.499439 [info ] [MainThread]: 
[0m18:39:13.499602 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m18:39:13.502501 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3112717, "process_in_blocks": "0", "process_kernel_time": 0.24293, "process_mem_max_rss": "195739648", "process_out_blocks": "0", "process_user_time": 1.624045}
[0m18:39:13.502875 [debug] [MainThread]: Command `dbt run` succeeded at 18:39:13.502819 after 1.31 seconds
[0m18:39:13.503121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107edf980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b4b3bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d80b290>]}
[0m18:39:13.503340 [debug] [MainThread]: Flushing usage events
[0m18:39:13.966164 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:01:00.965375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11419b980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112038ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114824200>]}


============================== 23:01:00.968438 | 8d855564-0f2f-410e-9099-3462909e6a6e ==============================
[0m23:01:00.968438 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:01:00.968873 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'write_json': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'target_path': 'None', 'empty': 'False', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'static_parser': 'True', 'quiet': 'False', 'printer_width': '80', 'use_colors': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'log_format': 'default', 'introspect': 'True', 'version_check': 'True', 'no_print': 'None', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices'}
[0m23:01:01.067000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eec650>]}
[0m23:01:01.097472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bbb920>]}
[0m23:01:01.098086 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m23:01:01.171503 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:01:01.253601 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:01:01.253905 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:01:01.257371 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
[0m23:01:01.280510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114dc4ce0>]}
[0m23:01:01.331846 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:01:01.333171 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:01:01.344764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114e29df0>]}
[0m23:01:01.345053 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m23:01:01.345239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11489fb00>]}
[0m23:01:01.346280 [info ] [MainThread]: 
[0m23:01:01.346483 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:01:01.346639 [info ] [MainThread]: 
[0m23:01:01.346919 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m23:01:01.349814 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m23:01:01.355852 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:01:01.692546 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m23:01:01.694316 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.705233 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m23:01:01.708854 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m23:01:01.714615 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m23:01:01.716066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221195e0>]}
[0m23:01:01.718018 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m23:01:01.718373 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m23:01:01.718656 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m23:01:01.718860 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m23:01:01.722685 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m23:01:01.723193 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m23:01:01.752855 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m23:01:01.757696 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.766838 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:01:01.769401 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.771867 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m23:01:01.772390 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m23:01:01.821132 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m23:01:01.824420 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m23:01:01.827271 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.842143 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m23:01:01.843834 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.845798 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1236f3710>]}
[0m23:01:01.846176 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.13s]
[0m23:01:01.846521 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m23:01:01.846748 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m23:01:01.847055 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m23:01:01.847328 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m23:01:01.847546 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m23:01:01.848885 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m23:01:01.849460 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m23:01:01.851450 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m23:01:01.856298 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.858238 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:01:01.860897 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.862208 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m23:01:01.862740 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m23:01:01.889804 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m23:01:01.890603 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m23:01:01.893339 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.896385 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m23:01:01.897884 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.898893 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237267e0>]}
[0m23:01:01.899285 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.05s]
[0m23:01:01.899610 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m23:01:01.899855 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m23:01:01.900094 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m23:01:01.900335 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m23:01:01.900546 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m23:01:01.901841 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m23:01:01.902403 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m23:01:01.904431 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m23:01:01.909140 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.910998 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:01:01.913509 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.914793 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m23:01:01.915302 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m23:01:01.955637 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m23:01:01.956485 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m23:01:01.959070 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.961181 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m23:01:01.962727 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:01:01.963644 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d855564-0f2f-410e-9099-3462909e6a6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123737620>]}
[0m23:01:01.964006 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.06s]
[0m23:01:01.964306 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m23:01:01.965025 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:01:01.965226 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m23:01:01.965386 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m23:01:01.965634 [info ] [MainThread]: 
[0m23:01:01.965886 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.62 seconds (0.62s).
[0m23:01:01.966393 [debug] [MainThread]: Command end result
[0m23:01:01.984873 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:01:01.986202 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:01:01.990084 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m23:01:01.990324 [info ] [MainThread]: 
[0m23:01:01.990545 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:01:01.990716 [info ] [MainThread]: 
[0m23:01:01.990899 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m23:01:01.993810 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0672667, "process_in_blocks": "0", "process_kernel_time": 0.234066, "process_mem_max_rss": "192692224", "process_out_blocks": "0", "process_user_time": 1.404802}
[0m23:01:01.994080 [debug] [MainThread]: Command `dbt run` succeeded at 23:01:01.994036 after 1.07 seconds
[0m23:01:01.994292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115a5dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c60200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114c60d70>]}
[0m23:01:01.994504 [debug] [MainThread]: Flushing usage events
[0m23:01:08.275850 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:24:45.773412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10800e780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109144a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109144440>]}


============================== 23:24:45.776613 | 41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6 ==============================
[0m23:24:45.776613 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:24:45.776980 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'no_print': 'None', 'target_path': 'None', 'fail_fast': 'False', 'partial_parse': 'True', 'empty': 'False', 'introspect': 'True', 'warn_error': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'indirect_selection': 'eager', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'static_parser': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'use_colors': 'True', 'quiet': 'False', 'write_json': 'True', 'log_format': 'default'}
[0m23:24:45.882002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109144920>]}
[0m23:24:45.912236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087c61e0>]}
[0m23:24:45.912815 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m23:24:45.985057 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:24:46.067828 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:24:46.068110 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:24:46.071662 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m23:24:46.092785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109381d90>]}
[0m23:24:46.141323 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:24:46.142863 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:24:46.154585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092f3260>]}
[0m23:24:46.154860 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m23:24:46.155052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109786000>]}
[0m23:24:46.156046 [info ] [MainThread]: 
[0m23:24:46.156238 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:24:46.156385 [info ] [MainThread]: 
[0m23:24:46.156636 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m23:24:46.159450 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m23:24:46.165556 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:24:46.671138 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m23:24:46.672882 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.684360 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m23:24:46.688119 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m23:24:46.691611 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.692910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a00c4d0>]}
[0m23:24:46.694800 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m23:24:46.695099 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m23:24:46.695357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m23:24:46.695563 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m23:24:46.699382 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m23:24:46.699804 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m23:24:46.728882 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m23:24:46.736029 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m23:24:46.744954 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:24:46.749223 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.751445 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m23:24:46.751988 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m23:24:46.774281 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m23:24:46.777380 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m23:24:46.779899 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.794525 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m23:24:46.796118 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.798096 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a277a0>]}
[0m23:24:46.798481 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.10s]
[0m23:24:46.798798 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m23:24:46.799012 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m23:24:46.799239 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m23:24:46.799480 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m23:24:46.799667 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m23:24:46.800901 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m23:24:46.801415 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m23:24:46.803303 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m23:24:46.808222 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.809963 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:24:46.812381 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.813648 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m23:24:46.815037 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m23:24:46.833198 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m23:24:46.833989 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m23:24:46.836664 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.839762 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m23:24:46.841369 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.842231 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f23ea20>]}
[0m23:24:46.842601 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m23:24:46.842916 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m23:24:46.843132 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m23:24:46.843362 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m23:24:46.843586 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m23:24:46.843780 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m23:24:46.844952 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m23:24:46.845472 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m23:24:46.847307 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m23:24:46.852143 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.853926 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:24:46.856411 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.857632 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m23:24:46.858129 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m23:24:46.885777 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m23:24:46.886664 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m23:24:46.889319 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.891783 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m23:24:46.893361 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:24:46.894365 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41a8cf3e-da7c-4e2d-ba25-4cfda34f4fd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f220560>]}
[0m23:24:46.894769 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m23:24:46.895111 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m23:24:46.895830 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:24:46.896071 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m23:24:46.896271 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m23:24:46.896565 [info ] [MainThread]: 
[0m23:24:46.896772 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m23:24:46.897288 [debug] [MainThread]: Command end result
[0m23:24:46.916833 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:24:46.918060 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:24:46.921232 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m23:24:46.921426 [info ] [MainThread]: 
[0m23:24:46.921630 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:24:46.921789 [info ] [MainThread]: 
[0m23:24:46.921963 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m23:24:46.924966 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1895678, "process_in_blocks": "0", "process_kernel_time": 0.248707, "process_mem_max_rss": "191791104", "process_out_blocks": "0", "process_user_time": 1.401782}
[0m23:24:46.925263 [debug] [MainThread]: Command `dbt run` succeeded at 23:24:46.925216 after 1.19 seconds
[0m23:24:46.925474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109113f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090c0ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc32b40>]}
[0m23:24:46.925675 [debug] [MainThread]: Flushing usage events
[0m23:24:47.428278 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:25:05.792635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ece180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b246e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b241a0>]}


============================== 23:25:05.795063 | cf75953a-0a4a-4f6a-ae60-edaa06294b19 ==============================
[0m23:25:05.795063 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:25:05.795398 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'warn_error': 'None', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'no_print': 'None', 'cache_selected_only': 'False', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'debug': 'False', 'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'use_colors': 'True', 'printer_width': '80', 'quiet': 'False', 'invocation_command': 'dbt test --select market.daily_prices', 'log_cache_events': 'False'}
[0m23:25:05.885914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105896d20>]}
[0m23:25:05.916470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b35400>]}
[0m23:25:05.916983 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m23:25:05.986830 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:25:06.048671 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:25:06.048939 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:25:06.052262 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m23:25:06.075056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc4620>]}
[0m23:25:06.124906 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:25:06.126254 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:25:06.139676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf6a50>]}
[0m23:25:06.139955 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m23:25:06.140136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b19280>]}
[0m23:25:06.141066 [info ] [MainThread]: 
[0m23:25:06.141254 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:25:06.141396 [info ] [MainThread]: 
[0m23:25:06.141658 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m23:25:06.144629 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__market'
[0m23:25:06.151597 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:25:06.483201 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m23:25:06.485999 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.494644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf75953a-0a4a-4f6a-ae60-edaa06294b19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc5910>]}
[0m23:25:06.495969 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m23:25:06.496227 [info ] [Thread-1 (]: 1 of 5 START test dbt_utils_unique_combination_of_columns_daily_prices_ticker__date  [RUN]
[0m23:25:06.496483 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3)
[0m23:25:06.496674 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m23:25:06.507560 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"
[0m23:25:06.508400 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m23:25:06.518877 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"
[0m23:25:06.519400 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  





with validation_errors as (

    select
        ticker, date
    from `market`.`daily_prices`
    group by ticker, date
    having count(*) > 1

)

select *
from validation_errors



  
  
    ) dbt_internal_test...
[0m23:25:06.548353 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m23:25:06.551001 [info ] [Thread-1 (]: 1 of 5 PASS dbt_utils_unique_combination_of_columns_daily_prices_ticker__date .. [[32mPASS[0m in 0.05s]
[0m23:25:06.551352 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3
[0m23:25:06.551578 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m23:25:06.551777 [info ] [Thread-1 (]: 2 of 5 START test not_null_daily_prices_date ................................... [RUN]
[0m23:25:06.552069 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.dbt_utils_unique_combination_of_columns_daily_prices_ticker__date.87713cbcc3, now test.qi_dbt_project.not_null_daily_prices_date.287ad299aa)
[0m23:25:06.552260 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m23:25:06.556307 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m23:25:06.557068 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m23:25:06.558643 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"
[0m23:25:06.559212 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_date.287ad299aa: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_date.287ad299aa"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select date
from `market`.`daily_prices`
where date is null



  
  
    ) dbt_internal_test...
[0m23:25:06.563030 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.564161 [info ] [Thread-1 (]: 2 of 5 PASS not_null_daily_prices_date ......................................... [[32mPASS[0m in 0.01s]
[0m23:25:06.564505 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_date.287ad299aa
[0m23:25:06.564727 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m23:25:06.564997 [info ] [Thread-1 (]: 3 of 5 START test not_null_daily_prices_ingested_at ............................ [RUN]
[0m23:25:06.565287 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_date.287ad299aa, now test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837)
[0m23:25:06.565508 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m23:25:06.567843 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m23:25:06.568549 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m23:25:06.571027 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"
[0m23:25:06.571482 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ingested_at
from `market`.`daily_prices`
where ingested_at is null



  
  
    ) dbt_internal_test...
[0m23:25:06.575251 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.576227 [info ] [Thread-1 (]: 3 of 5 PASS not_null_daily_prices_ingested_at .................................. [[32mPASS[0m in 0.01s]
[0m23:25:06.576550 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837
[0m23:25:06.576754 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m23:25:06.576977 [info ] [Thread-1 (]: 4 of 5 START test not_null_daily_prices_short_name ............................. [RUN]
[0m23:25:06.577253 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_ingested_at.4dbf84d837, now test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52)
[0m23:25:06.577458 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m23:25:06.579910 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m23:25:06.580624 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m23:25:06.582120 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"
[0m23:25:06.582574 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select short_name
from `market`.`daily_prices`
where short_name is null



  
  
    ) dbt_internal_test...
[0m23:25:06.586140 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.587169 [info ] [Thread-1 (]: 4 of 5 PASS not_null_daily_prices_short_name ................................... [[32mPASS[0m in 0.01s]
[0m23:25:06.587491 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52
[0m23:25:06.587710 [debug] [Thread-1 (]: Began running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m23:25:06.587911 [info ] [Thread-1 (]: 5 of 5 START test not_null_daily_prices_ticker ................................. [RUN]
[0m23:25:06.588126 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.qi_dbt_project.not_null_daily_prices_short_name.9e91e59f52, now test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1)
[0m23:25:06.588301 [debug] [Thread-1 (]: Began compiling node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m23:25:06.590753 [debug] [Thread-1 (]: Writing injected SQL for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m23:25:06.591284 [debug] [Thread-1 (]: Began executing node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m23:25:06.592883 [debug] [Thread-1 (]: Writing runtime sql for node "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"
[0m23:25:06.593269 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select ticker
from `market`.`daily_prices`
where ticker is null



  
  
    ) dbt_internal_test...
[0m23:25:06.596816 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:25:06.597873 [info ] [Thread-1 (]: 5 of 5 PASS not_null_daily_prices_ticker ....................................... [[32mPASS[0m in 0.01s]
[0m23:25:06.598206 [debug] [Thread-1 (]: Finished running node test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1
[0m23:25:06.598888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:25:06.599077 [debug] [MainThread]: Connection 'test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1' was left open.
[0m23:25:06.599241 [debug] [MainThread]: On test.qi_dbt_project.not_null_daily_prices_ticker.cbd48d58d1: Close
[0m23:25:06.599474 [info ] [MainThread]: 
[0m23:25:06.599645 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m23:25:06.600191 [debug] [MainThread]: Command end result
[0m23:25:06.617561 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:25:06.618558 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:25:06.622341 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m23:25:06.622586 [info ] [MainThread]: 
[0m23:25:06.622777 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:25:06.622934 [info ] [MainThread]: 
[0m23:25:06.623110 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m23:25:06.625625 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.8686088, "process_in_blocks": "0", "process_kernel_time": 0.206832, "process_mem_max_rss": "193904640", "process_out_blocks": "0", "process_user_time": 1.352156}
[0m23:25:06.625924 [debug] [MainThread]: Command `dbt test` succeeded at 23:25:06.625875 after 0.87 seconds
[0m23:25:06.626131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b24680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106789070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106980470>]}
[0m23:25:06.626324 [debug] [MainThread]: Flushing usage events
[0m23:25:07.073348 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:53:15.446266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc41970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da249b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da243b0>]}


============================== 23:53:15.449153 | f98943e9-a2af-4fb3-9c61-0a41ef60e0f7 ==============================
[0m23:53:15.449153 [info ] [MainThread]: Running with dbt=1.10.13
[0m23:53:15.449534 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'log_cache_events': 'False', 'quiet': 'False', 'debug': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'write_json': 'True', 'fail_fast': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'target_path': 'None', 'static_parser': 'True', 'empty': 'False', 'log_format': 'default', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_colors': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False'}
[0m23:53:15.547429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db61d00>]}
[0m23:53:15.577883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db76330>]}
[0m23:53:15.578859 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m23:53:15.651658 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m23:53:15.732025 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:53:15.732329 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:53:15.735872 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m23:53:15.757418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dec46b0>]}
[0m23:53:15.804802 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:53:15.806335 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:53:15.818093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df27a10>]}
[0m23:53:15.818407 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m23:53:15.818603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc8b830>]}
[0m23:53:15.819690 [info ] [MainThread]: 
[0m23:53:15.819901 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:53:15.820057 [info ] [MainThread]: 
[0m23:53:15.820325 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m23:53:15.823247 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m23:53:15.829267 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:53:16.162217 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m23:53:16.163976 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.174379 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m23:53:16.177923 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m23:53:16.180980 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.182138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a9e810>]}
[0m23:53:16.183619 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m23:53:16.183916 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m23:53:16.184180 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m23:53:16.184378 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m23:53:16.188208 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m23:53:16.188736 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m23:53:16.217949 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m23:53:16.226476 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m23:53:16.235631 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:53:16.238475 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.240754 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m23:53:16.241292 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m23:53:16.261439 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m23:53:16.264313 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m23:53:16.267243 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.280917 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m23:53:16.282563 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.284500 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099c3260>]}
[0m23:53:16.284872 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.10s]
[0m23:53:16.285189 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m23:53:16.285404 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m23:53:16.285631 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m23:53:16.285862 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m23:53:16.286047 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m23:53:16.287242 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m23:53:16.287791 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m23:53:16.289859 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m23:53:16.294201 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.295929 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:53:16.298531 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.299752 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m23:53:16.300235 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m23:53:16.317815 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m23:53:16.318662 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m23:53:16.321146 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.324075 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m23:53:16.325504 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.326443 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c853ef0>]}
[0m23:53:16.326889 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m23:53:16.327215 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m23:53:16.327452 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m23:53:16.327767 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m23:53:16.328032 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m23:53:16.328232 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m23:53:16.329507 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m23:53:16.329974 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m23:53:16.332042 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m23:53:16.336842 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.338658 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m23:53:16.341352 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.342587 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m23:53:16.343128 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m23:53:16.371734 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m23:53:16.372657 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m23:53:16.375475 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.377796 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m23:53:16.379402 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m23:53:16.380268 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f98943e9-a2af-4fb3-9c61-0a41ef60e0f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c853ef0>]}
[0m23:53:16.380638 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m23:53:16.380954 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m23:53:16.381645 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:53:16.381860 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m23:53:16.382050 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m23:53:16.382324 [info ] [MainThread]: 
[0m23:53:16.382524 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m23:53:16.383037 [debug] [MainThread]: Command end result
[0m23:53:16.401945 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m23:53:16.403143 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m23:53:16.406225 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m23:53:16.406408 [info ] [MainThread]: 
[0m23:53:16.406607 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:53:16.406761 [info ] [MainThread]: 
[0m23:53:16.406932 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m23:53:16.409864 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.99981904, "process_in_blocks": "0", "process_kernel_time": 0.215308, "process_mem_max_rss": "192118784", "process_out_blocks": "0", "process_user_time": 1.416586}
[0m23:53:16.410214 [debug] [MainThread]: Command `dbt run` succeeded at 23:53:16.410166 after 1.00 seconds
[0m23:53:16.410421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da249b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10daf4d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df1afc0>]}
[0m23:53:16.410618 [debug] [MainThread]: Flushing usage events
[0m23:53:16.889740 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:00:26.250174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111194560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e24830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e24140>]}


============================== 00:00:26.252703 | 368338c0-d95d-4820-896b-e931947b6c03 ==============================
[0m00:00:26.252703 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:00:26.253036 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'partial_parse': 'True', 'version_check': 'True', 'write_json': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_format': 'default', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_colors': 'True', 'empty': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'static_parser': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'no_print': 'None', 'indirect_selection': 'eager'}
[0m00:00:26.348838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e35580>]}
[0m00:00:26.382137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ef63f0>]}
[0m00:00:26.382755 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:00:26.452877 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:00:26.516513 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:00:26.516782 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:00:26.520114 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
[0m00:00:26.541383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11318fb00>]}
[0m00:00:26.591150 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:00:26.592505 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:00:26.600180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1138663c0>]}
[0m00:00:26.600447 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:00:26.600633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113516ff0>]}
[0m00:00:26.601806 [info ] [MainThread]: 
[0m00:00:26.602038 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:00:26.602204 [info ] [MainThread]: 
[0m00:00:26.602495 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:00:26.605610 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:00:26.611783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:26.936292 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:00:26.938046 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:26.946189 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:00:26.949871 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:00:26.952903 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:26.954315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075eba10>]}
[0m00:00:26.955722 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:00:26.956046 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:00:26.956317 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:00:26.956521 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:00:26.960369 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:00:26.960790 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:00:26.990986 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:00:27.001733 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:00:27.011007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:00:27.013682 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.016026 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:00:27.016590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:00:27.034442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:00:27.037344 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:00:27.040410 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.055449 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:00:27.057080 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.058978 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075836e0>]}
[0m00:00:27.059336 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.10s]
[0m00:00:27.059644 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:00:27.059860 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:00:27.060154 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:00:27.060426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:00:27.060637 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:00:27.061823 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:00:27.062325 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:00:27.064121 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:00:27.068292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.069971 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:00:27.072657 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.073905 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:00:27.074450 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:00:27.091194 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:00:27.092066 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:00:27.095065 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.098093 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:00:27.099864 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.100709 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d3ee40>]}
[0m00:00:27.101064 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m00:00:27.101361 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:00:27.101570 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:00:27.101785 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:00:27.102041 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:00:27.102250 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:00:27.103510 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:00:27.103990 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:00:27.105723 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:00:27.110103 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.111802 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:00:27.114300 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.115662 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:00:27.116272 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:00:27.144365 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:00:27.145278 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:00:27.148068 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.150590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:00:27.152286 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:00:27.153228 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '368338c0-d95d-4820-896b-e931947b6c03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d4c3e0>]}
[0m00:00:27.153623 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m00:00:27.153937 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:00:27.154574 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:00:27.154766 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:00:27.154941 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:00:27.155192 [info ] [MainThread]: 
[0m00:00:27.155374 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.55 seconds (0.55s).
[0m00:00:27.155897 [debug] [MainThread]: Command end result
[0m00:00:27.175013 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:00:27.176274 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:00:27.179520 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:00:27.179722 [info ] [MainThread]: 
[0m00:00:27.179931 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:00:27.180091 [info ] [MainThread]: 
[0m00:00:27.180271 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:00:27.182679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.9698614, "process_in_blocks": "0", "process_kernel_time": 0.210403, "process_mem_max_rss": "194363392", "process_out_blocks": "0", "process_user_time": 1.428072}
[0m00:00:27.182923 [debug] [MainThread]: Command `dbt run` succeeded at 00:00:27.182882 after 0.97 seconds
[0m00:00:27.183130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e246e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117cd8ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d2c8f0>]}
[0m00:00:27.183327 [debug] [MainThread]: Flushing usage events
[0m00:00:27.678131 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:06:57.805388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118dd0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120249e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120243e0>]}


============================== 00:06:57.808114 | d81008ba-9594-4583-8490-c36d8b3c6b9e ==============================
[0m00:06:57.808114 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:06:57.808473 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'use_experimental_parser': 'False', 'static_parser': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'target_path': 'None', 'log_format': 'default', 'log_cache_events': 'False', 'introspect': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'debug': 'False', 'empty': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs'}
[0m00:06:57.905150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120343b0>]}
[0m00:06:57.936914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fd00b0>]}
[0m00:06:57.937538 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:06:58.008262 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:06:58.071731 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:06:58.072005 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:06:58.075360 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
- models.qi_dbt_project.fundamentals
[0m00:06:58.097757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11238f410>]}
[0m00:06:58.146216 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:06:58.147514 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:06:58.155226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112625c10>]}
[0m00:06:58.155516 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:06:58.155695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112866480>]}
[0m00:06:58.156730 [info ] [MainThread]: 
[0m00:06:58.156945 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:06:58.157159 [info ] [MainThread]: 
[0m00:06:58.157433 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:06:58.160305 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:06:58.166182 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:06:58.506090 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:06:58.508001 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.516131 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:06:58.520076 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:06:58.523215 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.524562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f1b8f0>]}
[0m00:06:58.525905 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:06:58.526218 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:06:58.526475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:06:58.526676 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:06:58.530516 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:06:58.531050 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:06:58.560450 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:06:58.568513 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:06:58.577426 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:06:58.582598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.584838 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:06:58.585355 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:06:58.610326 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:06:58.613522 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:06:58.616330 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.630217 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:06:58.631987 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.633830 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dc33e0>]}
[0m00:06:58.634193 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.11s]
[0m00:06:58.634501 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:06:58.634718 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:06:58.635019 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:06:58.635295 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:06:58.635507 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:06:58.636738 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:06:58.637186 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:06:58.639027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:06:58.643962 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.645814 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:06:58.648891 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.650246 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:06:58.650789 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:06:58.666913 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:06:58.667757 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:06:58.670610 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.673562 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:06:58.675142 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.675989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122040050>]}
[0m00:06:58.676339 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m00:06:58.676639 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:06:58.676848 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:06:58.677076 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:06:58.677357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:06:58.677613 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:06:58.678878 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:06:58.679348 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:06:58.681149 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:06:58.685974 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.687756 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:06:58.690235 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.691548 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:06:58.692080 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:06:58.720687 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:06:58.721565 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:06:58.724223 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.726395 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:06:58.728225 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:06:58.729162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd81008ba-9594-4583-8490-c36d8b3c6b9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12200bdd0>]}
[0m00:06:58.729528 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m00:06:58.729839 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:06:58.730560 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:06:58.730734 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:06:58.730931 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:06:58.731200 [info ] [MainThread]: 
[0m00:06:58.731384 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m00:06:58.731833 [debug] [MainThread]: Command end result
[0m00:06:58.750435 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:06:58.751759 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:06:58.755491 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:06:58.755717 [info ] [MainThread]: 
[0m00:06:58.755921 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:06:58.756081 [info ] [MainThread]: 
[0m00:06:58.756257 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:06:58.758666 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.99306893, "process_in_blocks": "0", "process_kernel_time": 0.216167, "process_mem_max_rss": "193888256", "process_out_blocks": "0", "process_user_time": 1.431918}
[0m00:06:58.758925 [debug] [MainThread]: Command `dbt run` succeeded at 00:06:58.758881 after 0.99 seconds
[0m00:06:58.759119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d3560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1215a06e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120246b0>]}
[0m00:06:58.759308 [debug] [MainThread]: Flushing usage events
[0m00:06:59.227938 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:13:41.541570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107222d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074248c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074242c0>]}


============================== 00:13:41.544427 | 21e008d2-f266-4936-b5c4-eab818fcd6c4 ==============================
[0m00:13:41.544427 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:13:41.544785 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'static_parser': 'True', 'version_check': 'True', 'printer_width': '80', 'introspect': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'no_print': 'None', 'warn_error': 'None', 'partial_parse': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'target_path': 'None', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'fail_fast': 'False', 'write_json': 'True', 'empty': 'False'}
[0m00:13:41.638697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c71880>]}
[0m00:13:41.668910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074374a0>]}
[0m00:13:41.669433 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:13:41.738919 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:13:41.801613 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:13:41.801845 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:13:41.805101 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.meta
- models.qi_dbt_project.analytics
[0m00:13:41.826909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077639e0>]}
[0m00:13:41.876127 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:13:41.877438 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:13:41.885169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107927110>]}
[0m00:13:41.885446 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:13:41.885635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077606e0>]}
[0m00:13:41.886667 [info ] [MainThread]: 
[0m00:13:41.886871 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:13:41.887028 [info ] [MainThread]: 
[0m00:13:41.887303 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:13:41.890484 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:13:41.896887 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:13:42.228802 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:13:42.230720 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.238779 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:13:42.242423 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:13:42.245497 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.246717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2202f0>]}
[0m00:13:42.247919 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:13:42.248193 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:13:42.248434 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:13:42.248629 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:13:42.252404 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:13:42.252937 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:13:42.280965 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:13:42.288987 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:13:42.298436 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:13:42.301210 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.303481 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:13:42.304027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:13:42.321684 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:13:42.324498 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:13:42.327143 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.341417 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:13:42.343068 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.344909 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10749aa80>]}
[0m00:13:42.345267 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.10s]
[0m00:13:42.345564 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:13:42.345784 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:13:42.346014 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:13:42.346278 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:13:42.346504 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:13:42.347701 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:13:42.348169 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:13:42.349905 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:13:42.354871 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.356505 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:13:42.359042 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.360304 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:13:42.360913 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:13:42.376925 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:13:42.377802 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:13:42.380292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.383049 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:13:42.384647 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.385619 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da3e7b0>]}
[0m00:13:42.386003 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m00:13:42.386309 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:13:42.386514 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:13:42.386745 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:13:42.387117 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:13:42.387356 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:13:42.388658 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:13:42.389125 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:13:42.390984 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:13:42.395700 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.397431 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:13:42.399928 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.401132 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:13:42.401662 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:13:42.430793 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:13:42.431692 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:13:42.434668 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.437243 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:13:42.439126 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:13:42.440185 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21e008d2-f266-4936-b5c4-eab818fcd6c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da21820>]}
[0m00:13:42.440598 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m00:13:42.440936 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:13:42.441695 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:13:42.441882 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:13:42.442056 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:13:42.442318 [info ] [MainThread]: 
[0m00:13:42.442499 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m00:13:42.442949 [debug] [MainThread]: Command end result
[0m00:13:42.462321 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:13:42.463432 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:13:42.466957 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:13:42.467203 [info ] [MainThread]: 
[0m00:13:42.467410 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:13:42.467608 [info ] [MainThread]: 
[0m00:13:42.467815 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:13:42.470487 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.96795833, "process_in_blocks": "0", "process_kernel_time": 0.213082, "process_mem_max_rss": "192479232", "process_out_blocks": "0", "process_user_time": 1.419035}
[0m00:13:42.470834 [debug] [MainThread]: Command `dbt run` succeeded at 00:13:42.470786 after 0.97 seconds
[0m00:13:42.471067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107222cf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106514950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2663c0>]}
[0m00:13:42.471318 [debug] [MainThread]: Flushing usage events
[0m00:13:42.960012 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:17:49.110854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10701d820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105249b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105243b0>]}


============================== 00:17:49.113294 | e4345090-deaa-4772-b687-9e7df1366107 ==============================
[0m00:17:49.113294 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:17:49.113621 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'fail_fast': 'False', 'target_path': 'None', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'introspect': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'write_json': 'True', 'debug': 'False', 'version_check': 'True', 'empty': 'False', 'log_format': 'default', 'use_colors': 'True', 'static_parser': 'True', 'quiet': 'False', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'log_cache_events': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None'}
[0m00:17:49.203540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107d8d40>]}
[0m00:17:49.236913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107baf500>]}
[0m00:17:49.237666 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:17:49.313086 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:17:49.379198 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:17:49.379486 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:17:49.382945 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m00:17:49.405290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ac4200>]}
[0m00:17:49.454471 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:17:49.455753 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:17:49.465047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b25640>]}
[0m00:17:49.465391 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:17:49.465601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d66600>]}
[0m00:17:49.466767 [info ] [MainThread]: 
[0m00:17:49.467011 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:17:49.467172 [info ] [MainThread]: 
[0m00:17:49.467450 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:17:49.470479 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:17:49.476990 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:17:49.811407 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:17:49.813323 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.821270 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:17:49.825062 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:17:49.828698 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.829978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112018b60>]}
[0m00:17:49.831323 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:17:49.831609 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:17:49.831852 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:17:49.832047 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:17:49.835790 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:17:49.836325 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:17:49.869245 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:17:49.884642 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:17:49.898189 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:17:49.904199 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:17:49.907024 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:17:49.907668 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:17:49.926242 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:17:49.929268 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:17:49.932278 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.946189 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:17:49.948222 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.950156 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1038bf980>]}
[0m00:17:49.950537 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.12s]
[0m00:17:49.950852 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:17:49.951077 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:17:49.951308 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:17:49.951628 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:17:49.951840 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:17:49.953062 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:17:49.953527 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:17:49.955416 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:17:49.960350 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.962098 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:17:49.965011 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.966335 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:17:49.966873 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:17:49.983175 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:17:49.984008 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:17:49.986960 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.990189 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:17:49.991865 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:49.992796 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117452780>]}
[0m00:17:49.993175 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.04s]
[0m00:17:49.993487 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:17:49.993697 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:17:49.993923 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:17:49.994201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:17:49.994439 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:17:49.995684 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:17:49.996191 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:17:49.998027 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:17:50.002595 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:50.004388 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:17:50.007163 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:50.008422 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:17:50.009168 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:17:50.036854 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:17:50.037710 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:17:50.040288 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:50.042429 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:17:50.043834 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:17:50.044826 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4345090-deaa-4772-b687-9e7df1366107', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117421190>]}
[0m00:17:50.045191 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.05s]
[0m00:17:50.045495 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:17:50.046213 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:17:50.046440 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:17:50.046623 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:17:50.046888 [info ] [MainThread]: 
[0m00:17:50.047071 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m00:17:50.047542 [debug] [MainThread]: Command end result
[0m00:17:50.066153 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:17:50.067511 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:17:50.070870 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:17:50.071098 [info ] [MainThread]: 
[0m00:17:50.071304 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:17:50.071459 [info ] [MainThread]: 
[0m00:17:50.071628 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:17:50.074045 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.9989956, "process_in_blocks": "0", "process_kernel_time": 0.213801, "process_mem_max_rss": "194560000", "process_out_blocks": "0", "process_user_time": 1.419204}
[0m00:17:50.074297 [debug] [MainThread]: Command `dbt run` succeeded at 00:17:50.074255 after 1.00 seconds
[0m00:17:50.074495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105246b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117440b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117427380>]}
[0m00:17:50.074682 [debug] [MainThread]: Flushing usage events
[0m00:17:50.521460 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:19:43.441525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dbdb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c249b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c243b0>]}


============================== 00:19:43.443992 | 7d096020-5dbb-4f25-a301-b70ece42a6ee ==============================
[0m00:19:43.443992 [info ] [MainThread]: Running with dbt=1.10.13
[0m00:19:43.444337 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'log_cache_events': 'False', 'log_path': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/logs', 'empty': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'profiles_dir': '/Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project', 'quiet': 'False', 'no_print': 'None', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'invocation_command': 'dbt run --select market.weekly_prices market.monthly_prices market.quarterly_prices', 'printer_width': '80', 'partial_parse': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'version_check': 'True', 'debug': 'False'}
[0m00:19:43.538078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dbd700>]}
[0m00:19:43.569206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ad34a0>]}
[0m00:19:43.569750 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m00:19:43.642331 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m00:19:43.708545 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:19:43.708841 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:19:43.712681 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.qi_dbt_project.fundamentals
- models.qi_dbt_project.analytics
- models.qi_dbt_project.meta
[0m00:19:43.735159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e8e450>]}
[0m00:19:43.783838 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:19:43.785126 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:19:43.792823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111327260>]}
[0m00:19:43.793105 [info ] [MainThread]: Found 4 models, 14 data tests, 1 source, 603 macros
[0m00:19:43.793290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11136d1f0>]}
[0m00:19:43.794360 [info ] [MainThread]: 
[0m00:19:43.794596 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:19:43.794752 [info ] [MainThread]: 
[0m00:19:43.795016 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m00:19:43.797972 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m00:19:43.804184 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:19:44.165785 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m00:19:44.167736 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.176082 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__market)
[0m00:19:44.179855 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__market: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "connection_name": "list__market"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'market'
      

  ...
[0m00:19:44.183556 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.184867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111305190>]}
[0m00:19:44.186199 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.monthly_prices
[0m00:19:44.186507 [info ] [Thread-1 (]: 1 of 3 START sql table model `market`.`monthly_prices` ......................... [RUN]
[0m00:19:44.186765 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__market, now model.qi_dbt_project.monthly_prices)
[0m00:19:44.186964 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.monthly_prices
[0m00:19:44.190803 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.monthly_prices"
[0m00:19:44.191297 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.monthly_prices
[0m00:19:44.220851 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

            

    
        create table `market`.`monthly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
          )
        
        ...
[0m00:19:44.229921 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m00:19:44.239523 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

    select name, type from system.columns where table = 'monthly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:19:44.243742 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.246208 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.monthly_prices"
[0m00:19:44.246823 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */

  
    
    
    
        
         


        insert into `market`.`monthly_prices__dbt_backup`
        ("ticker", "short_name", "month_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real monthly aggregate: month_ending is last trading day of the month
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as month_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfMonth(date)
order by ticker, month_ending
  ...
[0m00:19:44.278258 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m00:19:44.281098 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
EXCHANGE TABLES `market`.`monthly_prices__dbt_backup` AND `market`.`monthly_prices` 
  
  ...
[0m00:19:44.284323 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.299440 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.monthly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.monthly_prices"} */
drop table if exists `market`.`monthly_prices__dbt_backup` 
  ...
[0m00:19:44.301720 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.303831 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052bf8c0>]}
[0m00:19:44.304257 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `market`.`monthly_prices` .................... [[32mOK[0m in 0.12s]
[0m00:19:44.304562 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.monthly_prices
[0m00:19:44.304787 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.quarterly_prices
[0m00:19:44.305008 [info ] [Thread-1 (]: 2 of 3 START sql table model `market`.`quarterly_prices` ....................... [RUN]
[0m00:19:44.305242 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.monthly_prices, now model.qi_dbt_project.quarterly_prices)
[0m00:19:44.305435 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.quarterly_prices
[0m00:19:44.306660 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.quarterly_prices"
[0m00:19:44.307214 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.quarterly_prices
[0m00:19:44.309303 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

            

    
        create table `market`.`quarterly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
          )
        
        ...
[0m00:19:44.314449 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.316081 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

    select name, type from system.columns where table = 'quarterly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:19:44.319093 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.320596 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.quarterly_prices"
[0m00:19:44.321183 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */

  
    
    
    
        
         


        insert into `market`.`quarterly_prices__dbt_backup`
        ("ticker", "short_name", "quarter_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real quarterly aggregate: quarter_ending is last trading day of the quarter
select
  ticker,
  argMax(short_name, date)        as short_name,
  max(date)                       as quarter_ending,
  argMin(open,  date)             as open,
  max(high)                       as high,
  min(low)                        as low,
  argMax(close, date)             as close,
  argMax(adj_close, date)         as adj_close,
  sum(volume)                     as volume,
  max(date)                       as source_max_date,
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toStartOfQuarter(date)
order by ticker, quarter_ending
  ...
[0m00:19:44.346041 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m00:19:44.346943 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
EXCHANGE TABLES `market`.`quarterly_prices__dbt_backup` AND `market`.`quarterly_prices` 
  
  ...
[0m00:19:44.349979 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.353063 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.quarterly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.quarterly_prices"} */
drop table if exists `market`.`quarterly_prices__dbt_backup` 
  ...
[0m00:19:44.354911 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.355784 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1207400b0>]}
[0m00:19:44.356125 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `market`.`quarterly_prices` .................. [[32mOK[0m in 0.05s]
[0m00:19:44.356424 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.quarterly_prices
[0m00:19:44.356630 [debug] [Thread-1 (]: Began running node model.qi_dbt_project.weekly_prices
[0m00:19:44.356848 [info ] [Thread-1 (]: 3 of 3 START sql table model `market`.`weekly_prices` .......................... [RUN]
[0m00:19:44.357064 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.qi_dbt_project.quarterly_prices, now model.qi_dbt_project.weekly_prices)
[0m00:19:44.357245 [debug] [Thread-1 (]: Began compiling node model.qi_dbt_project.weekly_prices
[0m00:19:44.358438 [debug] [Thread-1 (]: Writing injected SQL for node "model.qi_dbt_project.weekly_prices"
[0m00:19:44.358934 [debug] [Thread-1 (]: Began executing node model.qi_dbt_project.weekly_prices
[0m00:19:44.361002 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

            

    
        create table `market`.`weekly_prices__dbt_backup`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
          )
        
        ...
[0m00:19:44.366150 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.367954 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

    select name, type from system.columns where table = 'weekly_prices__dbt_backup'
    
      
        and database = 'market'
      
    
    order by position
  ...
[0m00:19:44.370681 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.371765 [debug] [Thread-1 (]: Writing runtime sql for node "model.qi_dbt_project.weekly_prices"
[0m00:19:44.372250 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */

  
    
    
    
        
         


        insert into `market`.`weekly_prices__dbt_backup`
        ("ticker", "short_name", "week_ending", "open", "high", "low", "close", "adj_close", "volume", "source_max_date", "built_at")-- Real weekly aggregate: ISO week groups; week_ending is the last trading day in that week
select
  ticker,
  argMax(short_name, date)        as short_name,       -- name as of last day in week
  max(date)                       as week_ending,      -- last trading day in ISO week
  argMin(open,  date)             as open,             -- first open in week
  max(high)                       as high,             -- highest high in week
  min(low)                        as low,              -- lowest low in week
  argMax(close, date)             as close,            -- last close in week
  argMax(adj_close, date)         as adj_close,        -- last adjusted close in week
  sum(volume)                     as volume,           -- total volume in week
  max(date)                       as source_max_date,  -- provenance
  now()                           as built_at
from market.daily_prices
group by
  ticker,
  toISOYear(date),
  toISOWeek(date)
order by ticker, week_ending
  ...
[0m00:19:44.409349 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m00:19:44.410177 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
EXCHANGE TABLES `market`.`weekly_prices__dbt_backup` AND `market`.`weekly_prices` 
  
  ...
[0m00:19:44.412734 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.414852 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.qi_dbt_project.weekly_prices: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "qi_dbt_project", "target_name": "dev", "node_id": "model.qi_dbt_project.weekly_prices"} */
drop table if exists `market`.`weekly_prices__dbt_backup` 
  ...
[0m00:19:44.416381 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m00:19:44.417210 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d096020-5dbb-4f25-a301-b70ece42a6ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120711160>]}
[0m00:19:44.417548 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `market`.`weekly_prices` ..................... [[32mOK[0m in 0.06s]
[0m00:19:44.417840 [debug] [Thread-1 (]: Finished running node model.qi_dbt_project.weekly_prices
[0m00:19:44.418472 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:19:44.418663 [debug] [MainThread]: Connection 'model.qi_dbt_project.weekly_prices' was left open.
[0m00:19:44.418836 [debug] [MainThread]: On model.qi_dbt_project.weekly_prices: Close
[0m00:19:44.419089 [info ] [MainThread]: 
[0m00:19:44.419268 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.62 seconds (0.62s).
[0m00:19:44.419730 [debug] [MainThread]: Command end result
[0m00:19:44.438828 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/manifest.json
[0m00:19:44.440179 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/semantic_manifest.json
[0m00:19:44.443371 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/deucalion/Developer/Python/Ademola/Family Office/qi/src/qi/dbt_project/target/run_results.json
[0m00:19:44.443570 [info ] [MainThread]: 
[0m00:19:44.443781 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:19:44.443941 [info ] [MainThread]: 
[0m00:19:44.444123 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m00:19:44.446716 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0411824, "process_in_blocks": "0", "process_kernel_time": 0.212729, "process_mem_max_rss": "192610304", "process_out_blocks": "0", "process_user_time": 1.402905}
[0m00:19:44.447019 [debug] [MainThread]: Command `dbt run` succeeded at 00:19:44.446973 after 1.04 seconds
[0m00:19:44.447241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e60320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117f6bf80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1201832c0>]}
[0m00:19:44.447449 [debug] [MainThread]: Flushing usage events
[0m00:19:44.911416 [debug] [MainThread]: An error was encountered while trying to flush usage events
